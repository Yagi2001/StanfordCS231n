{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdca1c",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f12280f",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab106c82",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721c3cb",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside `cs231n/classifiers/softmax.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d42765cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.363286\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88764e",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ *Fill this in* \n",
    "Our normalized scores at the start are 0.1 for almost all of them.Our loss function is -log(normalized true score) which is - log(0.1). The reason that all of scores are very close to 0.1 is : We choose our weights accordingly. Our weights at the start are very low values and they also have mean 0 and standart deviation 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c2626ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.366163 analytic: -0.366163, relative error: 3.978820e-08\n",
      "numerical: -1.529957 analytic: -1.529957, relative error: 3.499439e-08\n",
      "numerical: -0.947756 analytic: -0.947756, relative error: 3.744848e-08\n",
      "numerical: 1.086547 analytic: 1.086547, relative error: 7.501149e-08\n",
      "numerical: -0.281356 analytic: -0.281356, relative error: 8.769525e-08\n",
      "numerical: -3.576013 analytic: -3.576013, relative error: 1.294752e-09\n",
      "numerical: -0.083194 analytic: -0.083194, relative error: 1.587028e-07\n",
      "numerical: -0.664723 analytic: -0.664723, relative error: 6.423727e-08\n",
      "numerical: 0.314079 analytic: 0.314079, relative error: 5.439363e-08\n",
      "numerical: -3.945558 analytic: -3.945558, relative error: 2.144290e-10\n",
      "numerical: 1.592014 analytic: 1.592014, relative error: 1.119172e-08\n",
      "numerical: -1.244242 analytic: -1.244242, relative error: 6.257941e-08\n",
      "numerical: -1.652086 analytic: -1.652086, relative error: 4.291413e-08\n",
      "numerical: 0.139152 analytic: 0.139152, relative error: 2.138358e-07\n",
      "numerical: 0.154968 analytic: 0.154967, relative error: 1.308688e-07\n",
      "numerical: 1.498134 analytic: 1.498134, relative error: 1.888449e-08\n",
      "numerical: 1.571687 analytic: 1.571687, relative error: 2.926627e-08\n",
      "numerical: -5.260581 analytic: -5.260581, relative error: 1.025131e-09\n",
      "numerical: -1.480896 analytic: -1.480896, relative error: 4.588153e-08\n",
      "numerical: 0.589885 analytic: 0.589885, relative error: 4.008916e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "434e757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.363286e+00 computed in 0.050001s\n",
      "vectorized loss: 2.363286e+00 computed in 0.002009s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e5e374d",
   "metadata": {
    "tags": [
     "code"
    ],
    "test": "tuning"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 159.574085\n",
      "iteration 100 / 1500: loss 143.533618\n",
      "iteration 200 / 1500: loss 129.908926\n",
      "iteration 300 / 1500: loss 117.300106\n",
      "iteration 400 / 1500: loss 106.292249\n",
      "iteration 500 / 1500: loss 96.339053\n",
      "iteration 600 / 1500: loss 87.018164\n",
      "iteration 700 / 1500: loss 78.798316\n",
      "iteration 800 / 1500: loss 71.327721\n",
      "iteration 900 / 1500: loss 64.640742\n",
      "iteration 1000 / 1500: loss 58.749535\n",
      "iteration 1100 / 1500: loss 53.197294\n",
      "iteration 1200 / 1500: loss 48.219039\n",
      "iteration 1300 / 1500: loss 43.761329\n",
      "iteration 1400 / 1500: loss 39.822925\n",
      "iteration 0 / 1500: loss 67.883305\n",
      "iteration 100 / 1500: loss 64.166615\n",
      "iteration 200 / 1500: loss 61.217977\n",
      "iteration 300 / 1500: loss 58.963881\n",
      "iteration 400 / 1500: loss 56.488278\n",
      "iteration 500 / 1500: loss 53.994368\n",
      "iteration 600 / 1500: loss 51.693824\n",
      "iteration 700 / 1500: loss 49.396737\n",
      "iteration 800 / 1500: loss 47.700129\n",
      "iteration 900 / 1500: loss 46.127869\n",
      "iteration 1000 / 1500: loss 44.052936\n",
      "iteration 1100 / 1500: loss 42.165695\n",
      "iteration 1200 / 1500: loss 40.731095\n",
      "iteration 1300 / 1500: loss 39.030564\n",
      "iteration 1400 / 1500: loss 37.560813\n",
      "iteration 0 / 1500: loss 36.955234\n",
      "iteration 100 / 1500: loss 34.422945\n",
      "iteration 200 / 1500: loss 33.042176\n",
      "iteration 300 / 1500: loss 32.128971\n",
      "iteration 400 / 1500: loss 31.320408\n",
      "iteration 500 / 1500: loss 30.735363\n",
      "iteration 600 / 1500: loss 30.118574\n",
      "iteration 700 / 1500: loss 29.364556\n",
      "iteration 800 / 1500: loss 28.921634\n",
      "iteration 900 / 1500: loss 28.321215\n",
      "iteration 1000 / 1500: loss 27.534334\n",
      "iteration 1100 / 1500: loss 26.968395\n",
      "iteration 1200 / 1500: loss 26.554874\n",
      "iteration 1300 / 1500: loss 25.964365\n",
      "iteration 1400 / 1500: loss 25.425995\n",
      "iteration 0 / 1500: loss 311.248157\n",
      "iteration 100 / 1500: loss 253.863833\n",
      "iteration 200 / 1500: loss 207.803968\n",
      "iteration 300 / 1500: loss 169.689909\n",
      "iteration 400 / 1500: loss 139.313286\n",
      "iteration 500 / 1500: loss 114.258115\n",
      "iteration 600 / 1500: loss 93.950085\n",
      "iteration 700 / 1500: loss 77.203074\n",
      "iteration 800 / 1500: loss 63.341413\n",
      "iteration 900 / 1500: loss 52.217660\n",
      "iteration 1000 / 1500: loss 43.014474\n",
      "iteration 1100 / 1500: loss 35.531343\n",
      "iteration 1200 / 1500: loss 29.533170\n",
      "iteration 1300 / 1500: loss 24.360012\n",
      "iteration 1400 / 1500: loss 20.339724\n",
      "iteration 0 / 1500: loss 626.044645\n",
      "iteration 100 / 1500: loss 418.741301\n",
      "iteration 200 / 1500: loss 280.225360\n",
      "iteration 300 / 1500: loss 188.113136\n",
      "iteration 400 / 1500: loss 126.595438\n",
      "iteration 500 / 1500: loss 85.430833\n",
      "iteration 600 / 1500: loss 57.829385\n",
      "iteration 700 / 1500: loss 39.375495\n",
      "iteration 800 / 1500: loss 27.052334\n",
      "iteration 900 / 1500: loss 18.802518\n",
      "iteration 1000 / 1500: loss 13.245606\n",
      "iteration 1100 / 1500: loss 9.577190\n",
      "iteration 1200 / 1500: loss 7.100564\n",
      "iteration 1300 / 1500: loss 5.417503\n",
      "iteration 1400 / 1500: loss 4.275790\n",
      "iteration 0 / 1500: loss 1543.213780\n",
      "iteration 100 / 1500: loss 566.841751\n",
      "iteration 200 / 1500: loss 209.025094\n",
      "iteration 300 / 1500: loss 77.916435\n",
      "iteration 400 / 1500: loss 29.889583\n",
      "iteration 500 / 1500: loss 12.305380\n",
      "iteration 600 / 1500: loss 5.862755\n",
      "iteration 700 / 1500: loss 3.503197\n",
      "iteration 800 / 1500: loss 2.634295\n",
      "iteration 900 / 1500: loss 2.339116\n",
      "iteration 1000 / 1500: loss 2.196182\n",
      "iteration 1100 / 1500: loss 2.139522\n",
      "iteration 1200 / 1500: loss 2.154358\n",
      "iteration 1300 / 1500: loss 2.069705\n",
      "iteration 1400 / 1500: loss 2.115571\n",
      "iteration 0 / 1500: loss 3047.790462\n",
      "iteration 100 / 1500: loss 409.439216\n",
      "iteration 200 / 1500: loss 56.672496\n",
      "iteration 300 / 1500: loss 9.504370\n",
      "iteration 400 / 1500: loss 3.171411\n",
      "iteration 500 / 1500: loss 2.296359\n",
      "iteration 600 / 1500: loss 2.224632\n",
      "iteration 700 / 1500: loss 2.206896\n",
      "iteration 800 / 1500: loss 2.189885\n",
      "iteration 900 / 1500: loss 2.216364\n",
      "iteration 1000 / 1500: loss 2.210978\n",
      "iteration 1100 / 1500: loss 2.211972\n",
      "iteration 1200 / 1500: loss 2.187015\n",
      "iteration 1300 / 1500: loss 2.178347\n",
      "iteration 1400 / 1500: loss 2.177688\n",
      "iteration 0 / 1500: loss 6121.489916\n",
      "iteration 100 / 1500: loss 109.578004\n",
      "iteration 200 / 1500: loss 4.109006\n",
      "iteration 300 / 1500: loss 2.268032\n",
      "iteration 400 / 1500: loss 2.222153\n",
      "iteration 500 / 1500: loss 2.242011\n",
      "iteration 600 / 1500: loss 2.224781\n",
      "iteration 700 / 1500: loss 2.256883\n",
      "iteration 800 / 1500: loss 2.226828\n",
      "iteration 900 / 1500: loss 2.247379\n",
      "iteration 1000 / 1500: loss 2.221943\n",
      "iteration 1100 / 1500: loss 2.241382\n",
      "iteration 1200 / 1500: loss 2.236132\n",
      "iteration 1300 / 1500: loss 2.225918\n",
      "iteration 1400 / 1500: loss 2.220915\n",
      "iteration 0 / 1500: loss 159.634721\n",
      "iteration 100 / 1500: loss 129.240096\n",
      "iteration 200 / 1500: loss 105.515178\n",
      "iteration 300 / 1500: loss 86.585888\n",
      "iteration 400 / 1500: loss 70.969925\n",
      "iteration 500 / 1500: loss 58.289561\n",
      "iteration 600 / 1500: loss 47.966509\n",
      "iteration 700 / 1500: loss 39.614653\n",
      "iteration 800 / 1500: loss 32.883000\n",
      "iteration 900 / 1500: loss 27.035020\n",
      "iteration 1000 / 1500: loss 22.467624\n",
      "iteration 1100 / 1500: loss 18.771574\n",
      "iteration 1200 / 1500: loss 15.837187\n",
      "iteration 1300 / 1500: loss 13.137561\n",
      "iteration 1400 / 1500: loss 11.162515\n",
      "iteration 0 / 1500: loss 66.967813\n",
      "iteration 100 / 1500: loss 60.433211\n",
      "iteration 200 / 1500: loss 55.976869\n",
      "iteration 300 / 1500: loss 51.555554\n",
      "iteration 400 / 1500: loss 47.318224\n",
      "iteration 500 / 1500: loss 43.683507\n",
      "iteration 600 / 1500: loss 40.464511\n",
      "iteration 700 / 1500: loss 37.179863\n",
      "iteration 800 / 1500: loss 34.694031\n",
      "iteration 900 / 1500: loss 31.938880\n",
      "iteration 1000 / 1500: loss 29.678374\n",
      "iteration 1100 / 1500: loss 27.325913\n",
      "iteration 1200 / 1500: loss 25.434249\n",
      "iteration 1300 / 1500: loss 23.434155\n",
      "iteration 1400 / 1500: loss 21.922743\n",
      "iteration 0 / 1500: loss 37.191895\n",
      "iteration 100 / 1500: loss 33.373984\n",
      "iteration 200 / 1500: loss 31.842314\n",
      "iteration 300 / 1500: loss 30.312878\n",
      "iteration 400 / 1500: loss 28.854366\n",
      "iteration 500 / 1500: loss 27.678253\n",
      "iteration 600 / 1500: loss 26.479090\n",
      "iteration 700 / 1500: loss 25.667894\n",
      "iteration 800 / 1500: loss 24.348437\n",
      "iteration 900 / 1500: loss 23.672807\n",
      "iteration 1000 / 1500: loss 22.818301\n",
      "iteration 1100 / 1500: loss 21.868249\n",
      "iteration 1200 / 1500: loss 20.866986\n",
      "iteration 1300 / 1500: loss 20.132513\n",
      "iteration 1400 / 1500: loss 19.577747\n",
      "iteration 0 / 1500: loss 310.849542\n",
      "iteration 100 / 1500: loss 207.235957\n",
      "iteration 200 / 1500: loss 139.013393\n",
      "iteration 300 / 1500: loss 93.538833\n",
      "iteration 400 / 1500: loss 63.347574\n",
      "iteration 500 / 1500: loss 42.984282\n",
      "iteration 600 / 1500: loss 29.442365\n",
      "iteration 700 / 1500: loss 20.280705\n",
      "iteration 800 / 1500: loss 14.332632\n",
      "iteration 900 / 1500: loss 10.247084\n",
      "iteration 1000 / 1500: loss 7.448496\n",
      "iteration 1100 / 1500: loss 5.629881\n",
      "iteration 1200 / 1500: loss 4.502961\n",
      "iteration 1300 / 1500: loss 3.700596\n",
      "iteration 1400 / 1500: loss 3.202402\n",
      "iteration 0 / 1500: loss 620.009488\n",
      "iteration 100 / 1500: loss 278.073318\n",
      "iteration 200 / 1500: loss 125.505283\n",
      "iteration 300 / 1500: loss 57.313710\n",
      "iteration 400 / 1500: loss 26.864502\n",
      "iteration 500 / 1500: loss 13.156635\n",
      "iteration 600 / 1500: loss 6.936192\n",
      "iteration 700 / 1500: loss 4.278992\n",
      "iteration 800 / 1500: loss 3.051070\n",
      "iteration 900 / 1500: loss 2.459230\n",
      "iteration 1000 / 1500: loss 2.251318\n",
      "iteration 1100 / 1500: loss 2.121260\n",
      "iteration 1200 / 1500: loss 2.106886\n",
      "iteration 1300 / 1500: loss 2.092563\n",
      "iteration 1400 / 1500: loss 2.120882\n",
      "iteration 0 / 1500: loss 1539.446077\n",
      "iteration 100 / 1500: loss 207.166926\n",
      "iteration 200 / 1500: loss 29.502503\n",
      "iteration 300 / 1500: loss 5.865982\n",
      "iteration 400 / 1500: loss 2.640357\n",
      "iteration 500 / 1500: loss 2.192047\n",
      "iteration 600 / 1500: loss 2.147439\n",
      "iteration 700 / 1500: loss 2.153054\n",
      "iteration 800 / 1500: loss 2.095453\n",
      "iteration 900 / 1500: loss 2.137587\n",
      "iteration 1000 / 1500: loss 2.144948\n",
      "iteration 1100 / 1500: loss 2.137995\n",
      "iteration 1200 / 1500: loss 2.153934\n",
      "iteration 1300 / 1500: loss 2.152154\n",
      "iteration 1400 / 1500: loss 2.154187\n",
      "iteration 0 / 1500: loss 3064.079269\n",
      "iteration 100 / 1500: loss 55.849707\n",
      "iteration 200 / 1500: loss 3.119032\n",
      "iteration 300 / 1500: loss 2.219077\n",
      "iteration 400 / 1500: loss 2.194443\n",
      "iteration 500 / 1500: loss 2.228370\n",
      "iteration 600 / 1500: loss 2.204588\n",
      "iteration 700 / 1500: loss 2.175243\n",
      "iteration 800 / 1500: loss 2.212593\n",
      "iteration 900 / 1500: loss 2.186609\n",
      "iteration 1000 / 1500: loss 2.185564\n",
      "iteration 1100 / 1500: loss 2.195189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1200 / 1500: loss 2.229177\n",
      "iteration 1300 / 1500: loss 2.205414\n",
      "iteration 1400 / 1500: loss 2.219516\n",
      "iteration 0 / 1500: loss 6132.885745\n",
      "iteration 100 / 1500: loss 3.982132\n",
      "iteration 200 / 1500: loss 2.228975\n",
      "iteration 300 / 1500: loss 2.226924\n",
      "iteration 400 / 1500: loss 2.260043\n",
      "iteration 500 / 1500: loss 2.229704\n",
      "iteration 600 / 1500: loss 2.213731\n",
      "iteration 700 / 1500: loss 2.216932\n",
      "iteration 800 / 1500: loss 2.255077\n",
      "iteration 900 / 1500: loss 2.258606\n",
      "iteration 1000 / 1500: loss 2.229542\n",
      "iteration 1100 / 1500: loss 2.228376\n",
      "iteration 1200 / 1500: loss 2.251559\n",
      "iteration 1300 / 1500: loss 2.241277\n",
      "iteration 1400 / 1500: loss 2.224692\n",
      "iteration 0 / 1500: loss 159.398424\n",
      "iteration 100 / 1500: loss 105.588107\n",
      "iteration 200 / 1500: loss 70.873198\n",
      "iteration 300 / 1500: loss 48.038622\n",
      "iteration 400 / 1500: loss 32.653659\n",
      "iteration 500 / 1500: loss 22.415059\n",
      "iteration 600 / 1500: loss 15.711512\n",
      "iteration 700 / 1500: loss 11.192276\n",
      "iteration 800 / 1500: loss 8.094943\n",
      "iteration 900 / 1500: loss 6.130111\n",
      "iteration 1000 / 1500: loss 4.748861\n",
      "iteration 1100 / 1500: loss 3.646890\n",
      "iteration 1200 / 1500: loss 3.156732\n",
      "iteration 1300 / 1500: loss 2.725000\n",
      "iteration 1400 / 1500: loss 2.513941\n",
      "iteration 0 / 1500: loss 66.580271\n",
      "iteration 100 / 1500: loss 55.605853\n",
      "iteration 200 / 1500: loss 47.020754\n",
      "iteration 300 / 1500: loss 40.190450\n",
      "iteration 400 / 1500: loss 34.363072\n",
      "iteration 500 / 1500: loss 29.436215\n",
      "iteration 600 / 1500: loss 25.398663\n",
      "iteration 700 / 1500: loss 21.806556\n",
      "iteration 800 / 1500: loss 18.801792\n",
      "iteration 900 / 1500: loss 16.195475\n",
      "iteration 1000 / 1500: loss 13.968428\n",
      "iteration 1100 / 1500: loss 12.340336\n",
      "iteration 1200 / 1500: loss 10.580530\n",
      "iteration 1300 / 1500: loss 9.412326\n",
      "iteration 1400 / 1500: loss 8.316369\n",
      "iteration 0 / 1500: loss 36.427006\n",
      "iteration 100 / 1500: loss 31.584528\n",
      "iteration 200 / 1500: loss 29.046759\n",
      "iteration 300 / 1500: loss 26.501447\n",
      "iteration 400 / 1500: loss 24.113502\n",
      "iteration 500 / 1500: loss 22.656500\n",
      "iteration 600 / 1500: loss 20.793029\n",
      "iteration 700 / 1500: loss 19.396773\n",
      "iteration 800 / 1500: loss 18.045442\n",
      "iteration 900 / 1500: loss 16.777027\n",
      "iteration 1000 / 1500: loss 15.528145\n",
      "iteration 1100 / 1500: loss 14.426211\n",
      "iteration 1200 / 1500: loss 13.501598\n",
      "iteration 1300 / 1500: loss 12.441408\n",
      "iteration 1400 / 1500: loss 11.873457\n",
      "iteration 0 / 1500: loss 313.339616\n",
      "iteration 100 / 1500: loss 140.149816\n",
      "iteration 200 / 1500: loss 63.734764\n",
      "iteration 300 / 1500: loss 29.632751\n",
      "iteration 400 / 1500: loss 14.256960\n",
      "iteration 500 / 1500: loss 7.498724\n",
      "iteration 600 / 1500: loss 4.528739\n",
      "iteration 700 / 1500: loss 3.115020\n",
      "iteration 800 / 1500: loss 2.507557\n",
      "iteration 900 / 1500: loss 2.183748\n",
      "iteration 1000 / 1500: loss 2.052196\n",
      "iteration 1100 / 1500: loss 2.068188\n",
      "iteration 1200 / 1500: loss 2.052418\n",
      "iteration 1300 / 1500: loss 2.001511\n",
      "iteration 1400 / 1500: loss 2.067921\n",
      "iteration 0 / 1500: loss 624.657744\n",
      "iteration 100 / 1500: loss 126.070791\n",
      "iteration 200 / 1500: loss 26.823830\n",
      "iteration 300 / 1500: loss 6.982983\n",
      "iteration 400 / 1500: loss 3.063064\n",
      "iteration 500 / 1500: loss 2.258017\n",
      "iteration 600 / 1500: loss 2.132940\n",
      "iteration 700 / 1500: loss 2.105815\n",
      "iteration 800 / 1500: loss 2.099883\n",
      "iteration 900 / 1500: loss 2.030460\n",
      "iteration 1000 / 1500: loss 2.067521\n",
      "iteration 1100 / 1500: loss 2.128190\n",
      "iteration 1200 / 1500: loss 2.053063\n",
      "iteration 1300 / 1500: loss 2.028723\n",
      "iteration 1400 / 1500: loss 2.077545\n",
      "iteration 0 / 1500: loss 1535.118819\n",
      "iteration 100 / 1500: loss 28.934312\n",
      "iteration 200 / 1500: loss 2.560973\n",
      "iteration 300 / 1500: loss 2.159245\n",
      "iteration 400 / 1500: loss 2.154919\n",
      "iteration 500 / 1500: loss 2.154340\n",
      "iteration 600 / 1500: loss 2.112841\n",
      "iteration 700 / 1500: loss 2.098758\n",
      "iteration 800 / 1500: loss 2.100874\n",
      "iteration 900 / 1500: loss 2.152398\n",
      "iteration 1000 / 1500: loss 2.133111\n",
      "iteration 1100 / 1500: loss 2.178320\n",
      "iteration 1200 / 1500: loss 2.171427\n",
      "iteration 1300 / 1500: loss 2.166709\n",
      "iteration 1400 / 1500: loss 2.112939\n",
      "iteration 0 / 1500: loss 3087.688742\n",
      "iteration 100 / 1500: loss 3.078764\n",
      "iteration 200 / 1500: loss 2.182517\n",
      "iteration 300 / 1500: loss 2.171016\n",
      "iteration 400 / 1500: loss 2.191067\n",
      "iteration 500 / 1500: loss 2.186030\n",
      "iteration 600 / 1500: loss 2.217043\n",
      "iteration 700 / 1500: loss 2.188989\n",
      "iteration 800 / 1500: loss 2.176875\n",
      "iteration 900 / 1500: loss 2.193196\n",
      "iteration 1000 / 1500: loss 2.184983\n",
      "iteration 1100 / 1500: loss 2.171719\n",
      "iteration 1200 / 1500: loss 2.158892\n",
      "iteration 1300 / 1500: loss 2.209023\n",
      "iteration 1400 / 1500: loss 2.153173\n",
      "iteration 0 / 1500: loss 6136.667918\n",
      "iteration 100 / 1500: loss 2.239379\n",
      "iteration 200 / 1500: loss 2.238269\n",
      "iteration 300 / 1500: loss 2.266303\n",
      "iteration 400 / 1500: loss 2.251453\n",
      "iteration 500 / 1500: loss 2.215687\n",
      "iteration 600 / 1500: loss 2.234700\n",
      "iteration 700 / 1500: loss 2.236099\n",
      "iteration 800 / 1500: loss 2.232957\n",
      "iteration 900 / 1500: loss 2.228721\n",
      "iteration 1000 / 1500: loss 2.207261\n",
      "iteration 1100 / 1500: loss 2.219616\n",
      "iteration 1200 / 1500: loss 2.230019\n",
      "iteration 1300 / 1500: loss 2.250336\n",
      "iteration 1400 / 1500: loss 2.224101\n",
      "iteration 0 / 1500: loss 157.024414\n",
      "iteration 100 / 1500: loss 85.466563\n",
      "iteration 200 / 1500: loss 47.584774\n",
      "iteration 300 / 1500: loss 26.860611\n",
      "iteration 400 / 1500: loss 15.515790\n",
      "iteration 500 / 1500: loss 9.357002\n",
      "iteration 600 / 1500: loss 5.960920\n",
      "iteration 700 / 1500: loss 4.067450\n",
      "iteration 800 / 1500: loss 3.168276\n",
      "iteration 900 / 1500: loss 2.602830\n",
      "iteration 1000 / 1500: loss 2.371134\n",
      "iteration 1100 / 1500: loss 2.015097\n",
      "iteration 1200 / 1500: loss 2.027713\n",
      "iteration 1300 / 1500: loss 1.952355\n",
      "iteration 1400 / 1500: loss 1.966201\n",
      "iteration 0 / 1500: loss 65.865414\n",
      "iteration 100 / 1500: loss 50.725131\n",
      "iteration 200 / 1500: loss 39.806107\n",
      "iteration 300 / 1500: loss 31.653354\n",
      "iteration 400 / 1500: loss 25.128111\n",
      "iteration 500 / 1500: loss 20.257854\n",
      "iteration 600 / 1500: loss 16.223193\n",
      "iteration 700 / 1500: loss 13.089966\n",
      "iteration 800 / 1500: loss 10.581608\n",
      "iteration 900 / 1500: loss 8.677273\n",
      "iteration 1000 / 1500: loss 7.285554\n",
      "iteration 1100 / 1500: loss 6.084886\n",
      "iteration 1200 / 1500: loss 5.277336\n",
      "iteration 1300 / 1500: loss 4.595104\n",
      "iteration 1400 / 1500: loss 3.950646\n",
      "iteration 0 / 1500: loss 36.542798\n",
      "iteration 100 / 1500: loss 30.418367\n",
      "iteration 200 / 1500: loss 26.765970\n",
      "iteration 300 / 1500: loss 23.527130\n",
      "iteration 400 / 1500: loss 21.092733\n",
      "iteration 500 / 1500: loss 18.680056\n",
      "iteration 600 / 1500: loss 16.730423\n",
      "iteration 700 / 1500: loss 14.967532\n",
      "iteration 800 / 1500: loss 13.644847\n",
      "iteration 900 / 1500: loss 12.139585\n",
      "iteration 1000 / 1500: loss 10.907009\n",
      "iteration 1100 / 1500: loss 9.898044\n",
      "iteration 1200 / 1500: loss 8.946807\n",
      "iteration 1300 / 1500: loss 8.111415\n",
      "iteration 1400 / 1500: loss 7.566096\n",
      "iteration 0 / 1500: loss 311.631000\n",
      "iteration 100 / 1500: loss 93.814943\n",
      "iteration 200 / 1500: loss 29.390675\n",
      "iteration 300 / 1500: loss 10.228597\n",
      "iteration 400 / 1500: loss 4.435480\n",
      "iteration 500 / 1500: loss 2.667717\n",
      "iteration 600 / 1500: loss 2.199574\n",
      "iteration 700 / 1500: loss 2.131447\n",
      "iteration 800 / 1500: loss 1.982233\n",
      "iteration 900 / 1500: loss 2.044328\n",
      "iteration 1000 / 1500: loss 2.003048\n",
      "iteration 1100 / 1500: loss 1.950831\n",
      "iteration 1200 / 1500: loss 2.059501\n",
      "iteration 1300 / 1500: loss 1.997685\n",
      "iteration 1400 / 1500: loss 2.043291\n",
      "iteration 0 / 1500: loss 623.064127\n",
      "iteration 100 / 1500: loss 56.959938\n",
      "iteration 200 / 1500: loss 6.893321\n",
      "iteration 300 / 1500: loss 2.484643\n",
      "iteration 400 / 1500: loss 2.087134\n",
      "iteration 500 / 1500: loss 2.042273\n",
      "iteration 600 / 1500: loss 2.099042\n",
      "iteration 700 / 1500: loss 2.044159\n",
      "iteration 800 / 1500: loss 2.111401\n",
      "iteration 900 / 1500: loss 2.063658\n",
      "iteration 1000 / 1500: loss 2.087702\n",
      "iteration 1100 / 1500: loss 2.062653\n",
      "iteration 1200 / 1500: loss 2.038748\n",
      "iteration 1300 / 1500: loss 1.990139\n",
      "iteration 1400 / 1500: loss 2.077560\n",
      "iteration 0 / 1500: loss 1522.099032\n",
      "iteration 100 / 1500: loss 5.517239\n",
      "iteration 200 / 1500: loss 2.143007\n",
      "iteration 300 / 1500: loss 2.130904\n",
      "iteration 400 / 1500: loss 2.142073\n",
      "iteration 500 / 1500: loss 2.177959\n",
      "iteration 600 / 1500: loss 2.140032\n",
      "iteration 700 / 1500: loss 2.124575\n",
      "iteration 800 / 1500: loss 2.138842\n",
      "iteration 900 / 1500: loss 2.100680\n",
      "iteration 1000 / 1500: loss 2.127906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1100 / 1500: loss 2.158882\n",
      "iteration 1200 / 1500: loss 2.135517\n",
      "iteration 1300 / 1500: loss 2.181003\n",
      "iteration 1400 / 1500: loss 2.185853\n",
      "iteration 0 / 1500: loss 3038.483391\n",
      "iteration 100 / 1500: loss 2.193832\n",
      "iteration 200 / 1500: loss 2.217150\n",
      "iteration 300 / 1500: loss 2.220498\n",
      "iteration 400 / 1500: loss 2.174525\n",
      "iteration 500 / 1500: loss 2.175022\n",
      "iteration 600 / 1500: loss 2.210216\n",
      "iteration 700 / 1500: loss 2.175594\n",
      "iteration 800 / 1500: loss 2.217967\n",
      "iteration 900 / 1500: loss 2.231394\n",
      "iteration 1000 / 1500: loss 2.222154\n",
      "iteration 1100 / 1500: loss 2.219990\n",
      "iteration 1200 / 1500: loss 2.157599\n",
      "iteration 1300 / 1500: loss 2.166727\n",
      "iteration 1400 / 1500: loss 2.167244\n",
      "iteration 0 / 1500: loss 6161.719263\n",
      "iteration 100 / 1500: loss 2.238394\n",
      "iteration 200 / 1500: loss 2.244393\n",
      "iteration 300 / 1500: loss 2.242443\n",
      "iteration 400 / 1500: loss 2.230157\n",
      "iteration 500 / 1500: loss 2.217640\n",
      "iteration 600 / 1500: loss 2.215349\n",
      "iteration 700 / 1500: loss 2.252094\n",
      "iteration 800 / 1500: loss 2.251828\n",
      "iteration 900 / 1500: loss 2.243912\n",
      "iteration 1000 / 1500: loss 2.240712\n",
      "iteration 1100 / 1500: loss 2.238628\n",
      "iteration 1200 / 1500: loss 2.234358\n",
      "iteration 1300 / 1500: loss 2.232431\n",
      "iteration 1400 / 1500: loss 2.261462\n",
      "iteration 0 / 1500: loss 160.329770\n",
      "iteration 100 / 1500: loss 58.348761\n",
      "iteration 200 / 1500: loss 22.446021\n",
      "iteration 300 / 1500: loss 9.453204\n",
      "iteration 400 / 1500: loss 4.646782\n",
      "iteration 500 / 1500: loss 2.911389\n",
      "iteration 600 / 1500: loss 2.311924\n",
      "iteration 700 / 1500: loss 2.046470\n",
      "iteration 800 / 1500: loss 1.948146\n",
      "iteration 900 / 1500: loss 1.895741\n",
      "iteration 1000 / 1500: loss 2.002827\n",
      "iteration 1100 / 1500: loss 1.942463\n",
      "iteration 1200 / 1500: loss 2.020685\n",
      "iteration 1300 / 1500: loss 2.026220\n",
      "iteration 1400 / 1500: loss 1.951587\n",
      "iteration 0 / 1500: loss 67.583598\n",
      "iteration 100 / 1500: loss 43.490320\n",
      "iteration 200 / 1500: loss 29.211281\n",
      "iteration 300 / 1500: loss 20.124273\n",
      "iteration 400 / 1500: loss 13.890865\n",
      "iteration 500 / 1500: loss 10.035074\n",
      "iteration 600 / 1500: loss 7.170182\n",
      "iteration 700 / 1500: loss 5.574234\n",
      "iteration 800 / 1500: loss 4.277208\n",
      "iteration 900 / 1500: loss 3.492069\n",
      "iteration 1000 / 1500: loss 2.993536\n",
      "iteration 1100 / 1500: loss 2.564378\n",
      "iteration 1200 / 1500: loss 2.408850\n",
      "iteration 1300 / 1500: loss 2.147426\n",
      "iteration 1400 / 1500: loss 2.064771\n",
      "iteration 0 / 1500: loss 36.419000\n",
      "iteration 100 / 1500: loss 27.977464\n",
      "iteration 200 / 1500: loss 22.882729\n",
      "iteration 300 / 1500: loss 18.872944\n",
      "iteration 400 / 1500: loss 15.840253\n",
      "iteration 500 / 1500: loss 13.193992\n",
      "iteration 600 / 1500: loss 10.936211\n",
      "iteration 700 / 1500: loss 9.155600\n",
      "iteration 800 / 1500: loss 7.886286\n",
      "iteration 900 / 1500: loss 6.690100\n",
      "iteration 1000 / 1500: loss 5.716941\n",
      "iteration 1100 / 1500: loss 5.088253\n",
      "iteration 1200 / 1500: loss 4.492704\n",
      "iteration 1300 / 1500: loss 4.057374\n",
      "iteration 1400 / 1500: loss 3.641387\n",
      "iteration 0 / 1500: loss 308.634366\n",
      "iteration 100 / 1500: loss 42.458033\n",
      "iteration 200 / 1500: loss 7.304877\n",
      "iteration 300 / 1500: loss 2.690573\n",
      "iteration 400 / 1500: loss 2.028765\n",
      "iteration 500 / 1500: loss 1.975239\n",
      "iteration 600 / 1500: loss 2.025701\n",
      "iteration 700 / 1500: loss 1.992298\n",
      "iteration 800 / 1500: loss 2.018346\n",
      "iteration 900 / 1500: loss 1.970658\n",
      "iteration 1000 / 1500: loss 1.915624\n",
      "iteration 1100 / 1500: loss 1.978744\n",
      "iteration 1200 / 1500: loss 1.955174\n",
      "iteration 1300 / 1500: loss 1.977018\n",
      "iteration 1400 / 1500: loss 1.995501\n",
      "iteration 0 / 1500: loss 621.249438\n",
      "iteration 100 / 1500: loss 12.847267\n",
      "iteration 200 / 1500: loss 2.295288\n",
      "iteration 300 / 1500: loss 2.098715\n",
      "iteration 400 / 1500: loss 2.061808\n",
      "iteration 500 / 1500: loss 2.039460\n",
      "iteration 600 / 1500: loss 2.033367\n",
      "iteration 700 / 1500: loss 2.087942\n",
      "iteration 800 / 1500: loss 2.131479\n",
      "iteration 900 / 1500: loss 2.143987\n",
      "iteration 1000 / 1500: loss 2.074404\n",
      "iteration 1100 / 1500: loss 2.104360\n",
      "iteration 1200 / 1500: loss 2.093895\n",
      "iteration 1300 / 1500: loss 2.074671\n",
      "iteration 1400 / 1500: loss 2.078496\n",
      "iteration 0 / 1500: loss 1541.624191\n",
      "iteration 100 / 1500: loss 2.247476\n",
      "iteration 200 / 1500: loss 2.149299\n",
      "iteration 300 / 1500: loss 2.111797\n",
      "iteration 400 / 1500: loss 2.168687\n",
      "iteration 500 / 1500: loss 2.128625\n",
      "iteration 600 / 1500: loss 2.156397\n",
      "iteration 700 / 1500: loss 2.202487\n",
      "iteration 800 / 1500: loss 2.172349\n",
      "iteration 900 / 1500: loss 2.159743\n",
      "iteration 1000 / 1500: loss 2.163044\n",
      "iteration 1100 / 1500: loss 2.129008\n",
      "iteration 1200 / 1500: loss 2.200379\n",
      "iteration 1300 / 1500: loss 2.189704\n",
      "iteration 1400 / 1500: loss 2.168598\n",
      "iteration 0 / 1500: loss 3099.658017\n",
      "iteration 100 / 1500: loss 2.228136\n",
      "iteration 200 / 1500: loss 2.202720\n",
      "iteration 300 / 1500: loss 2.163080\n",
      "iteration 400 / 1500: loss 2.179411\n",
      "iteration 500 / 1500: loss 2.227162\n",
      "iteration 600 / 1500: loss 2.231435\n",
      "iteration 700 / 1500: loss 2.215803\n",
      "iteration 800 / 1500: loss 2.211535\n",
      "iteration 900 / 1500: loss 2.237063\n",
      "iteration 1000 / 1500: loss 2.217365\n",
      "iteration 1100 / 1500: loss 2.216098\n",
      "iteration 1200 / 1500: loss 2.186379\n",
      "iteration 1300 / 1500: loss 2.218811\n",
      "iteration 1400 / 1500: loss 2.181688\n",
      "iteration 0 / 1500: loss 6185.564067\n",
      "iteration 100 / 1500: loss 2.242103\n",
      "iteration 200 / 1500: loss 2.223338\n",
      "iteration 300 / 1500: loss 2.245046\n",
      "iteration 400 / 1500: loss 2.235745\n",
      "iteration 500 / 1500: loss 2.214486\n",
      "iteration 600 / 1500: loss 2.207868\n",
      "iteration 700 / 1500: loss 2.237085\n",
      "iteration 800 / 1500: loss 2.230361\n",
      "iteration 900 / 1500: loss 2.218167\n",
      "iteration 1000 / 1500: loss 2.253811\n",
      "iteration 1100 / 1500: loss 2.208013\n",
      "iteration 1200 / 1500: loss 2.236346\n",
      "iteration 1300 / 1500: loss 2.245332\n",
      "iteration 1400 / 1500: loss 2.226059\n",
      "iteration 0 / 1500: loss 161.338540\n",
      "iteration 100 / 1500: loss 158.045227\n",
      "iteration 200 / 1500: loss 154.825788\n",
      "iteration 300 / 1500: loss 151.749661\n",
      "iteration 400 / 1500: loss 148.414795\n",
      "iteration 500 / 1500: loss 145.354777\n",
      "iteration 600 / 1500: loss 142.197638\n",
      "iteration 700 / 1500: loss 139.552977\n",
      "iteration 800 / 1500: loss 136.621056\n",
      "iteration 900 / 1500: loss 133.939033\n",
      "iteration 1000 / 1500: loss 130.833780\n",
      "iteration 1100 / 1500: loss 128.453326\n",
      "iteration 1200 / 1500: loss 125.696325\n",
      "iteration 1300 / 1500: loss 123.338977\n",
      "iteration 1400 / 1500: loss 120.966461\n",
      "iteration 0 / 1500: loss 67.517029\n",
      "iteration 100 / 1500: loss 66.160597\n",
      "iteration 200 / 1500: loss 65.540211\n",
      "iteration 300 / 1500: loss 64.567855\n",
      "iteration 400 / 1500: loss 63.993279\n",
      "iteration 500 / 1500: loss 63.455784\n",
      "iteration 600 / 1500: loss 62.737685\n",
      "iteration 700 / 1500: loss 62.639235\n",
      "iteration 800 / 1500: loss 61.001762\n",
      "iteration 900 / 1500: loss 60.821455\n",
      "iteration 1000 / 1500: loss 60.094780\n",
      "iteration 1100 / 1500: loss 59.613216\n",
      "iteration 1200 / 1500: loss 59.044593\n",
      "iteration 1300 / 1500: loss 58.276316\n",
      "iteration 1400 / 1500: loss 57.794843\n",
      "iteration 0 / 1500: loss 36.267994\n",
      "iteration 100 / 1500: loss 35.533123\n",
      "iteration 200 / 1500: loss 35.006415\n",
      "iteration 300 / 1500: loss 34.801670\n",
      "iteration 400 / 1500: loss 34.455769\n",
      "iteration 500 / 1500: loss 34.578866\n",
      "iteration 600 / 1500: loss 34.056195\n",
      "iteration 700 / 1500: loss 33.705874\n",
      "iteration 800 / 1500: loss 33.607809\n",
      "iteration 900 / 1500: loss 32.980089\n",
      "iteration 1000 / 1500: loss 33.101486\n",
      "iteration 1100 / 1500: loss 33.370378\n",
      "iteration 1200 / 1500: loss 32.797767\n",
      "iteration 1300 / 1500: loss 32.771599\n",
      "iteration 1400 / 1500: loss 32.428664\n",
      "iteration 0 / 1500: loss 315.198609\n",
      "iteration 100 / 1500: loss 302.025270\n",
      "iteration 200 / 1500: loss 289.628015\n",
      "iteration 300 / 1500: loss 278.251159\n",
      "iteration 400 / 1500: loss 266.658349\n",
      "iteration 500 / 1500: loss 256.361461\n",
      "iteration 600 / 1500: loss 245.752249\n",
      "iteration 700 / 1500: loss 236.526204\n",
      "iteration 800 / 1500: loss 226.890973\n",
      "iteration 900 / 1500: loss 217.702051\n",
      "iteration 1000 / 1500: loss 209.473611\n",
      "iteration 1100 / 1500: loss 201.254687\n",
      "iteration 1200 / 1500: loss 193.331412\n",
      "iteration 1300 / 1500: loss 185.738246\n",
      "iteration 1400 / 1500: loss 178.309497\n",
      "iteration 0 / 1500: loss 624.407010\n",
      "iteration 100 / 1500: loss 576.407011\n",
      "iteration 200 / 1500: loss 532.103093\n",
      "iteration 300 / 1500: loss 490.731027\n",
      "iteration 400 / 1500: loss 453.160933\n",
      "iteration 500 / 1500: loss 418.451842\n",
      "iteration 600 / 1500: loss 385.826910\n",
      "iteration 700 / 1500: loss 356.364219\n",
      "iteration 800 / 1500: loss 329.127051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 900 / 1500: loss 303.988923\n",
      "iteration 1000 / 1500: loss 280.628304\n",
      "iteration 1100 / 1500: loss 259.055158\n",
      "iteration 1200 / 1500: loss 239.214147\n",
      "iteration 1300 / 1500: loss 220.966538\n",
      "iteration 1400 / 1500: loss 204.168242\n",
      "iteration 0 / 1500: loss 1548.903629\n",
      "iteration 100 / 1500: loss 1268.262212\n",
      "iteration 200 / 1500: loss 1037.844892\n",
      "iteration 300 / 1500: loss 849.662254\n",
      "iteration 400 / 1500: loss 695.923334\n",
      "iteration 500 / 1500: loss 569.894218\n",
      "iteration 600 / 1500: loss 466.781565\n",
      "iteration 700 / 1500: loss 382.353989\n",
      "iteration 800 / 1500: loss 313.061968\n",
      "iteration 900 / 1500: loss 256.601418\n",
      "iteration 1000 / 1500: loss 210.486024\n",
      "iteration 1100 / 1500: loss 172.669189\n",
      "iteration 1200 / 1500: loss 141.593571\n",
      "iteration 1300 / 1500: loss 116.267117\n",
      "iteration 1400 / 1500: loss 95.561146\n",
      "iteration 0 / 1500: loss 3094.314800\n",
      "iteration 100 / 1500: loss 2073.680933\n",
      "iteration 200 / 1500: loss 1389.471018\n",
      "iteration 300 / 1500: loss 931.408268\n",
      "iteration 400 / 1500: loss 624.484410\n",
      "iteration 500 / 1500: loss 418.981897\n",
      "iteration 600 / 1500: loss 281.390110\n",
      "iteration 700 / 1500: loss 189.145146\n",
      "iteration 800 / 1500: loss 127.517400\n",
      "iteration 900 / 1500: loss 86.044616\n",
      "iteration 1000 / 1500: loss 58.371062\n",
      "iteration 1100 / 1500: loss 39.816026\n",
      "iteration 1200 / 1500: loss 27.405143\n",
      "iteration 1300 / 1500: loss 19.074811\n",
      "iteration 1400 / 1500: loss 13.486784\n",
      "iteration 0 / 1500: loss 6147.931544\n",
      "iteration 100 / 1500: loss 2758.032636\n",
      "iteration 200 / 1500: loss 1238.063087\n",
      "iteration 300 / 1500: loss 556.327072\n",
      "iteration 400 / 1500: loss 250.613543\n",
      "iteration 500 / 1500: loss 113.583607\n",
      "iteration 600 / 1500: loss 52.179348\n",
      "iteration 700 / 1500: loss 24.619592\n",
      "iteration 800 / 1500: loss 12.269819\n",
      "iteration 900 / 1500: loss 6.754239\n",
      "iteration 1000 / 1500: loss 4.255079\n",
      "iteration 1100 / 1500: loss 3.127028\n",
      "iteration 1200 / 1500: loss 2.643891\n",
      "iteration 1300 / 1500: loss 2.433531\n",
      "iteration 1400 / 1500: loss 2.300815\n",
      "iteration 0 / 1500: loss 159.790877\n",
      "iteration 100 / 1500: loss 37.508595\n",
      "iteration 200 / 1500: loss 45.195290\n",
      "iteration 300 / 1500: loss 45.527083\n",
      "iteration 400 / 1500: loss 46.274417\n",
      "iteration 500 / 1500: loss 50.597454\n",
      "iteration 600 / 1500: loss 27.510321\n",
      "iteration 700 / 1500: loss 37.891084\n",
      "iteration 800 / 1500: loss 41.015878\n",
      "iteration 900 / 1500: loss 32.428238\n",
      "iteration 1000 / 1500: loss 27.657292\n",
      "iteration 1100 / 1500: loss 39.620748\n",
      "iteration 1200 / 1500: loss 53.958036\n",
      "iteration 1300 / 1500: loss 43.824487\n",
      "iteration 1400 / 1500: loss 49.558320\n",
      "iteration 0 / 1500: loss 66.344160\n",
      "iteration 100 / 1500: loss 19.935807\n",
      "iteration 200 / 1500: loss 17.433629\n",
      "iteration 300 / 1500: loss 35.105241\n",
      "iteration 400 / 1500: loss 22.735345\n",
      "iteration 500 / 1500: loss 31.450013\n",
      "iteration 600 / 1500: loss 21.709265\n",
      "iteration 700 / 1500: loss 28.048234\n",
      "iteration 800 / 1500: loss 28.110863\n",
      "iteration 900 / 1500: loss 33.170797\n",
      "iteration 1000 / 1500: loss 26.346444\n",
      "iteration 1100 / 1500: loss 28.230832\n",
      "iteration 1200 / 1500: loss 30.093968\n",
      "iteration 1300 / 1500: loss 35.727560\n",
      "iteration 1400 / 1500: loss 27.897159\n",
      "iteration 0 / 1500: loss 35.866932\n",
      "iteration 100 / 1500: loss 16.647557\n",
      "iteration 200 / 1500: loss 29.315430\n",
      "iteration 300 / 1500: loss 21.777070\n",
      "iteration 400 / 1500: loss 20.952454\n",
      "iteration 500 / 1500: loss 23.331845\n",
      "iteration 600 / 1500: loss 16.257733\n",
      "iteration 700 / 1500: loss 17.232397\n",
      "iteration 800 / 1500: loss 16.912695\n",
      "iteration 900 / 1500: loss 15.140173\n",
      "iteration 1000 / 1500: loss 16.936015\n",
      "iteration 1100 / 1500: loss 28.592581\n",
      "iteration 1200 / 1500: loss 20.861423\n",
      "iteration 1300 / 1500: loss 20.648773\n",
      "iteration 1400 / 1500: loss 15.535629\n",
      "iteration 0 / 1500: loss 316.678887\n",
      "iteration 100 / 1500: loss 86.784851\n",
      "iteration 200 / 1500: loss 85.335485\n",
      "iteration 300 / 1500: loss 88.900911\n",
      "iteration 400 / 1500: loss 79.150308\n",
      "iteration 500 / 1500: loss 66.432975\n",
      "iteration 600 / 1500: loss 86.097252\n",
      "iteration 700 / 1500: loss 78.465496\n",
      "iteration 800 / 1500: loss 82.533515\n",
      "iteration 900 / 1500: loss 77.231251\n",
      "iteration 1000 / 1500: loss 82.159753\n",
      "iteration 1100 / 1500: loss 74.350135\n",
      "iteration 1200 / 1500: loss 84.301485\n",
      "iteration 1300 / 1500: loss 81.098297\n",
      "iteration 1400 / 1500: loss 78.472827\n",
      "iteration 0 / 1500: loss 627.370833\n",
      "iteration 100 / 1500: loss inf\n",
      "iteration 200 / 1500: loss inf\n",
      "iteration 300 / 1500: loss inf\n",
      "iteration 400 / 1500: loss inf\n",
      "iteration 500 / 1500: loss inf\n",
      "iteration 600 / 1500: loss inf\n",
      "iteration 700 / 1500: loss inf\n",
      "iteration 800 / 1500: loss inf\n",
      "iteration 900 / 1500: loss inf\n",
      "iteration 1000 / 1500: loss inf\n",
      "iteration 1100 / 1500: loss inf\n",
      "iteration 1200 / 1500: loss inf\n",
      "iteration 1300 / 1500: loss inf\n",
      "iteration 1400 / 1500: loss inf\n",
      "iteration 0 / 1500: loss 1535.439327\n",
      "iteration 100 / 1500: loss inf\n",
      "iteration 200 / 1500: loss inf\n",
      "iteration 300 / 1500: loss inf\n",
      "iteration 400 / 1500: loss inf\n",
      "iteration 500 / 1500: loss inf\n",
      "iteration 600 / 1500: loss nan\n",
      "iteration 700 / 1500: loss nan\n",
      "iteration 800 / 1500: loss nan\n",
      "iteration 900 / 1500: loss nan\n",
      "iteration 1000 / 1500: loss nan\n",
      "iteration 1100 / 1500: loss nan\n",
      "iteration 1200 / 1500: loss nan\n",
      "iteration 1300 / 1500: loss nan\n",
      "iteration 1400 / 1500: loss nan\n",
      "iteration 0 / 1500: loss 3079.684508\n",
      "iteration 100 / 1500: loss inf\n",
      "iteration 200 / 1500: loss inf\n",
      "iteration 300 / 1500: loss inf\n",
      "iteration 400 / 1500: loss nan\n",
      "iteration 500 / 1500: loss nan\n",
      "iteration 600 / 1500: loss nan\n",
      "iteration 700 / 1500: loss nan\n",
      "iteration 800 / 1500: loss nan\n",
      "iteration 900 / 1500: loss nan\n",
      "iteration 1000 / 1500: loss nan\n",
      "iteration 1100 / 1500: loss nan\n",
      "iteration 1200 / 1500: loss nan\n",
      "iteration 1300 / 1500: loss nan\n",
      "iteration 1400 / 1500: loss nan\n",
      "iteration 0 / 1500: loss 6156.128959\n",
      "iteration 100 / 1500: loss inf\n",
      "iteration 200 / 1500: loss inf\n",
      "iteration 300 / 1500: loss nan\n",
      "iteration 400 / 1500: loss nan\n",
      "iteration 500 / 1500: loss nan\n",
      "iteration 600 / 1500: loss nan\n",
      "iteration 700 / 1500: loss nan\n",
      "iteration 800 / 1500: loss nan\n",
      "iteration 900 / 1500: loss nan\n",
      "iteration 1000 / 1500: loss nan\n",
      "iteration 1100 / 1500: loss nan\n",
      "iteration 1200 / 1500: loss nan\n",
      "iteration 1300 / 1500: loss nan\n",
      "iteration 1400 / 1500: loss nan\n",
      "iteration 0 / 1500: loss 159.339874\n",
      "iteration 100 / 1500: loss 22.375110\n",
      "iteration 200 / 1500: loss 4.707696\n",
      "iteration 300 / 1500: loss 2.310275\n",
      "iteration 400 / 1500: loss 1.993753\n",
      "iteration 500 / 1500: loss 1.967974\n",
      "iteration 600 / 1500: loss 1.973331\n",
      "iteration 700 / 1500: loss 1.909978\n",
      "iteration 800 / 1500: loss 2.039212\n",
      "iteration 900 / 1500: loss 1.897969\n",
      "iteration 1000 / 1500: loss 1.873404\n",
      "iteration 1100 / 1500: loss 1.987765\n",
      "iteration 1200 / 1500: loss 1.909422\n",
      "iteration 1300 / 1500: loss 1.950618\n",
      "iteration 1400 / 1500: loss 1.966952\n",
      "iteration 0 / 1500: loss 66.614373\n",
      "iteration 100 / 1500: loss 29.459702\n",
      "iteration 200 / 1500: loss 14.172071\n",
      "iteration 300 / 1500: loss 7.387658\n",
      "iteration 400 / 1500: loss 4.259574\n",
      "iteration 500 / 1500: loss 2.911702\n",
      "iteration 600 / 1500: loss 2.326405\n",
      "iteration 700 / 1500: loss 2.166785\n",
      "iteration 800 / 1500: loss 2.095632\n",
      "iteration 900 / 1500: loss 1.973157\n",
      "iteration 1000 / 1500: loss 2.058048\n",
      "iteration 1100 / 1500: loss 1.842315\n",
      "iteration 1200 / 1500: loss 1.845828\n",
      "iteration 1300 / 1500: loss 1.910615\n",
      "iteration 1400 / 1500: loss 1.896324\n",
      "iteration 0 / 1500: loss 36.130525\n",
      "iteration 100 / 1500: loss 23.062540\n",
      "iteration 200 / 1500: loss 15.785731\n",
      "iteration 300 / 1500: loss 10.964965\n",
      "iteration 400 / 1500: loss 7.804222\n",
      "iteration 500 / 1500: loss 5.904725\n",
      "iteration 600 / 1500: loss 4.554864\n",
      "iteration 700 / 1500: loss 3.649139\n",
      "iteration 800 / 1500: loss 2.902086\n",
      "iteration 900 / 1500: loss 2.680403\n",
      "iteration 1000 / 1500: loss 2.286754\n",
      "iteration 1100 / 1500: loss 2.185109\n",
      "iteration 1200 / 1500: loss 2.095693\n",
      "iteration 1300 / 1500: loss 2.058006\n",
      "iteration 1400 / 1500: loss 1.943407\n",
      "iteration 0 / 1500: loss 314.702108\n",
      "iteration 100 / 1500: loss 7.423877\n",
      "iteration 200 / 1500: loss 2.130302\n",
      "iteration 300 / 1500: loss 2.018031\n",
      "iteration 400 / 1500: loss 2.016657\n",
      "iteration 500 / 1500: loss 1.972678\n",
      "iteration 600 / 1500: loss 1.936611\n",
      "iteration 700 / 1500: loss 2.002976\n",
      "iteration 800 / 1500: loss 2.073207\n",
      "iteration 900 / 1500: loss 2.088312\n",
      "iteration 1000 / 1500: loss 2.013953\n",
      "iteration 1100 / 1500: loss 2.068252\n",
      "iteration 1200 / 1500: loss 2.042021\n",
      "iteration 1300 / 1500: loss 2.015601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1400 / 1500: loss 2.019295\n",
      "iteration 0 / 1500: loss 629.530415\n",
      "iteration 100 / 1500: loss 2.170018\n",
      "iteration 200 / 1500: loss 2.017793\n",
      "iteration 300 / 1500: loss 2.062930\n",
      "iteration 400 / 1500: loss 2.052564\n",
      "iteration 500 / 1500: loss 2.043022\n",
      "iteration 600 / 1500: loss 2.137267\n",
      "iteration 700 / 1500: loss 2.114947\n",
      "iteration 800 / 1500: loss 2.072504\n",
      "iteration 900 / 1500: loss 2.101176\n",
      "iteration 1000 / 1500: loss 2.077049\n",
      "iteration 1100 / 1500: loss 2.058723\n",
      "iteration 1200 / 1500: loss 2.075697\n",
      "iteration 1300 / 1500: loss 2.077431\n",
      "iteration 1400 / 1500: loss 2.055834\n",
      "iteration 0 / 1500: loss 1532.968818\n",
      "iteration 100 / 1500: loss 2.165115\n",
      "iteration 200 / 1500: loss 2.178253\n",
      "iteration 300 / 1500: loss 2.182346\n",
      "iteration 400 / 1500: loss 2.124980\n",
      "iteration 500 / 1500: loss 2.176743\n",
      "iteration 600 / 1500: loss 2.165101\n",
      "iteration 700 / 1500: loss 2.197223\n",
      "iteration 800 / 1500: loss 2.131638\n",
      "iteration 900 / 1500: loss 2.168259\n",
      "iteration 1000 / 1500: loss 2.132790\n",
      "iteration 1100 / 1500: loss 2.139085\n",
      "iteration 1200 / 1500: loss 2.111930\n",
      "iteration 1300 / 1500: loss 2.110137\n",
      "iteration 1400 / 1500: loss 2.119385\n",
      "iteration 0 / 1500: loss 3078.512289\n",
      "iteration 100 / 1500: loss 2.212819\n",
      "iteration 200 / 1500: loss 2.202146\n",
      "iteration 300 / 1500: loss 2.179639\n",
      "iteration 400 / 1500: loss 2.213982\n",
      "iteration 500 / 1500: loss 2.239771\n",
      "iteration 600 / 1500: loss 2.222151\n",
      "iteration 700 / 1500: loss 2.201602\n",
      "iteration 800 / 1500: loss 2.169000\n",
      "iteration 900 / 1500: loss 2.190822\n",
      "iteration 1000 / 1500: loss 2.255587\n",
      "iteration 1100 / 1500: loss 2.214129\n",
      "iteration 1200 / 1500: loss 2.207018\n",
      "iteration 1300 / 1500: loss 2.249355\n",
      "iteration 1400 / 1500: loss 2.216942\n",
      "iteration 0 / 1500: loss 6175.975859\n",
      "iteration 100 / 1500: loss 2.245366\n",
      "iteration 200 / 1500: loss 2.263685\n",
      "iteration 300 / 1500: loss 2.257276\n",
      "iteration 400 / 1500: loss 2.226962\n",
      "iteration 500 / 1500: loss 2.234818\n",
      "iteration 600 / 1500: loss 2.252946\n",
      "iteration 700 / 1500: loss 2.253909\n",
      "iteration 800 / 1500: loss 2.262139\n",
      "iteration 900 / 1500: loss 2.243411\n",
      "iteration 1000 / 1500: loss 2.239286\n",
      "iteration 1100 / 1500: loss 2.271759\n",
      "iteration 1200 / 1500: loss 2.245689\n",
      "iteration 1300 / 1500: loss 2.234773\n",
      "iteration 1400 / 1500: loss 2.249879\n",
      "iteration 0 / 1500: loss 159.590044\n",
      "iteration 100 / 1500: loss 4.696506\n",
      "iteration 200 / 1500: loss 2.046410\n",
      "iteration 300 / 1500: loss 1.986135\n",
      "iteration 400 / 1500: loss 2.099503\n",
      "iteration 500 / 1500: loss 1.888404\n",
      "iteration 600 / 1500: loss 1.990608\n",
      "iteration 700 / 1500: loss 1.888921\n",
      "iteration 800 / 1500: loss 2.003561\n",
      "iteration 900 / 1500: loss 2.041774\n",
      "iteration 1000 / 1500: loss 1.964129\n",
      "iteration 1100 / 1500: loss 1.881031\n",
      "iteration 1200 / 1500: loss 1.945178\n",
      "iteration 1300 / 1500: loss 1.949135\n",
      "iteration 1400 / 1500: loss 1.967636\n",
      "iteration 0 / 1500: loss 66.467119\n",
      "iteration 100 / 1500: loss 14.097540\n",
      "iteration 200 / 1500: loss 4.309724\n",
      "iteration 300 / 1500: loss 2.296333\n",
      "iteration 400 / 1500: loss 2.093605\n",
      "iteration 500 / 1500: loss 1.823021\n",
      "iteration 600 / 1500: loss 1.961670\n",
      "iteration 700 / 1500: loss 1.945770\n",
      "iteration 800 / 1500: loss 1.837599\n",
      "iteration 900 / 1500: loss 1.920392\n",
      "iteration 1000 / 1500: loss 1.975126\n",
      "iteration 1100 / 1500: loss 1.828530\n",
      "iteration 1200 / 1500: loss 1.956292\n",
      "iteration 1300 / 1500: loss 1.917107\n",
      "iteration 1400 / 1500: loss 1.881885\n",
      "iteration 0 / 1500: loss 36.947298\n",
      "iteration 100 / 1500: loss 15.577568\n",
      "iteration 200 / 1500: loss 7.882694\n",
      "iteration 300 / 1500: loss 4.427939\n",
      "iteration 400 / 1500: loss 3.063171\n",
      "iteration 500 / 1500: loss 2.425838\n",
      "iteration 600 / 1500: loss 2.076144\n",
      "iteration 700 / 1500: loss 1.856724\n",
      "iteration 800 / 1500: loss 1.897758\n",
      "iteration 900 / 1500: loss 1.882866\n",
      "iteration 1000 / 1500: loss 1.807371\n",
      "iteration 1100 / 1500: loss 1.802671\n",
      "iteration 1200 / 1500: loss 1.945565\n",
      "iteration 1300 / 1500: loss 1.879048\n",
      "iteration 1400 / 1500: loss 1.854146\n",
      "iteration 0 / 1500: loss 313.315452\n",
      "iteration 100 / 1500: loss 2.143949\n",
      "iteration 200 / 1500: loss 2.120896\n",
      "iteration 300 / 1500: loss 2.033093\n",
      "iteration 400 / 1500: loss 2.037120\n",
      "iteration 500 / 1500: loss 2.078216\n",
      "iteration 600 / 1500: loss 1.958711\n",
      "iteration 700 / 1500: loss 2.030316\n",
      "iteration 800 / 1500: loss 2.020042\n",
      "iteration 900 / 1500: loss 1.964766\n",
      "iteration 1000 / 1500: loss 1.996747\n",
      "iteration 1100 / 1500: loss 2.071109\n",
      "iteration 1200 / 1500: loss 2.049976\n",
      "iteration 1300 / 1500: loss 2.102490\n",
      "iteration 1400 / 1500: loss 2.057230\n",
      "iteration 0 / 1500: loss 607.213139\n",
      "iteration 100 / 1500: loss 2.072668\n",
      "iteration 200 / 1500: loss 2.103173\n",
      "iteration 300 / 1500: loss 2.071544\n",
      "iteration 400 / 1500: loss 2.036055\n",
      "iteration 500 / 1500: loss 2.083591\n",
      "iteration 600 / 1500: loss 2.076220\n",
      "iteration 700 / 1500: loss 2.112248\n",
      "iteration 800 / 1500: loss 2.121149\n",
      "iteration 900 / 1500: loss 2.119952\n",
      "iteration 1000 / 1500: loss 2.067388\n",
      "iteration 1100 / 1500: loss 2.104924\n",
      "iteration 1200 / 1500: loss 2.115832\n",
      "iteration 1300 / 1500: loss 1.935181\n",
      "iteration 1400 / 1500: loss 2.059422\n",
      "iteration 0 / 1500: loss 1550.140993\n",
      "iteration 100 / 1500: loss 2.171766\n",
      "iteration 200 / 1500: loss 2.149604\n",
      "iteration 300 / 1500: loss 2.176016\n",
      "iteration 400 / 1500: loss 2.151316\n",
      "iteration 500 / 1500: loss 2.165991\n",
      "iteration 600 / 1500: loss 2.144218\n",
      "iteration 700 / 1500: loss 2.177597\n",
      "iteration 800 / 1500: loss 2.154664\n",
      "iteration 900 / 1500: loss 2.182166\n",
      "iteration 1000 / 1500: loss 2.187062\n",
      "iteration 1100 / 1500: loss 2.092444\n",
      "iteration 1200 / 1500: loss 2.185198\n",
      "iteration 1300 / 1500: loss 2.169953\n",
      "iteration 1400 / 1500: loss 2.194878\n",
      "iteration 0 / 1500: loss 3067.147893\n",
      "iteration 100 / 1500: loss 2.215542\n",
      "iteration 200 / 1500: loss 2.245070\n",
      "iteration 300 / 1500: loss 2.171816\n",
      "iteration 400 / 1500: loss 2.198169\n",
      "iteration 500 / 1500: loss 2.239725\n",
      "iteration 600 / 1500: loss 2.312146\n",
      "iteration 700 / 1500: loss 2.220769\n",
      "iteration 800 / 1500: loss 2.226401\n",
      "iteration 900 / 1500: loss 2.205696\n",
      "iteration 1000 / 1500: loss 2.215705\n",
      "iteration 1100 / 1500: loss 2.233921\n",
      "iteration 1200 / 1500: loss 2.245027\n",
      "iteration 1300 / 1500: loss 2.224970\n",
      "iteration 1400 / 1500: loss 2.209781\n",
      "iteration 0 / 1500: loss 6142.067069\n",
      "iteration 100 / 1500: loss 2.263549\n",
      "iteration 200 / 1500: loss 2.294838\n",
      "iteration 300 / 1500: loss 2.332001\n",
      "iteration 400 / 1500: loss 2.270465\n",
      "iteration 500 / 1500: loss 2.309014\n",
      "iteration 600 / 1500: loss 2.286747\n",
      "iteration 700 / 1500: loss 2.281343\n",
      "iteration 800 / 1500: loss 2.307412\n",
      "iteration 900 / 1500: loss 2.313608\n",
      "iteration 1000 / 1500: loss 2.343506\n",
      "iteration 1100 / 1500: loss 2.272607\n",
      "iteration 1200 / 1500: loss 2.281736\n",
      "iteration 1300 / 1500: loss 2.316629\n",
      "iteration 1400 / 1500: loss 2.272968\n",
      "iteration 0 / 1500: loss 157.587410\n",
      "iteration 100 / 1500: loss 2.034397\n",
      "iteration 200 / 1500: loss 2.006513\n",
      "iteration 300 / 1500: loss 1.971359\n",
      "iteration 400 / 1500: loss 2.070698\n",
      "iteration 500 / 1500: loss 2.023562\n",
      "iteration 600 / 1500: loss 2.122216\n",
      "iteration 700 / 1500: loss 2.061548\n",
      "iteration 800 / 1500: loss 2.081913\n",
      "iteration 900 / 1500: loss 2.113760\n",
      "iteration 1000 / 1500: loss 1.976545\n",
      "iteration 1100 / 1500: loss 2.158982\n",
      "iteration 1200 / 1500: loss 2.020777\n",
      "iteration 1300 / 1500: loss 2.039717\n",
      "iteration 1400 / 1500: loss 2.011859\n",
      "iteration 0 / 1500: loss 67.418318\n",
      "iteration 100 / 1500: loss 4.269525\n",
      "iteration 200 / 1500: loss 1.958068\n",
      "iteration 300 / 1500: loss 1.986288\n",
      "iteration 400 / 1500: loss 1.956174\n",
      "iteration 500 / 1500: loss 1.933388\n",
      "iteration 600 / 1500: loss 1.896774\n",
      "iteration 700 / 1500: loss 1.943957\n",
      "iteration 800 / 1500: loss 1.961410\n",
      "iteration 900 / 1500: loss 1.989764\n",
      "iteration 1000 / 1500: loss 1.983225\n",
      "iteration 1100 / 1500: loss 1.977791\n",
      "iteration 1200 / 1500: loss 1.957653\n",
      "iteration 1300 / 1500: loss 1.946975\n",
      "iteration 1400 / 1500: loss 1.920831\n",
      "iteration 0 / 1500: loss 36.524172\n",
      "iteration 100 / 1500: loss 7.969492\n",
      "iteration 200 / 1500: loss 3.114405\n",
      "iteration 300 / 1500: loss 2.169776\n",
      "iteration 400 / 1500: loss 1.910928\n",
      "iteration 500 / 1500: loss 2.063269\n",
      "iteration 600 / 1500: loss 1.924019\n",
      "iteration 700 / 1500: loss 1.929774\n",
      "iteration 800 / 1500: loss 1.817727\n",
      "iteration 900 / 1500: loss 1.936858\n",
      "iteration 1000 / 1500: loss 2.057293\n",
      "iteration 1100 / 1500: loss 1.819814\n",
      "iteration 1200 / 1500: loss 1.976563\n",
      "iteration 1300 / 1500: loss 1.952629\n",
      "iteration 1400 / 1500: loss 1.956885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 309.535334\n",
      "iteration 100 / 1500: loss 2.167301\n",
      "iteration 200 / 1500: loss 2.103081\n",
      "iteration 300 / 1500: loss 2.060613\n",
      "iteration 400 / 1500: loss 2.098941\n",
      "iteration 500 / 1500: loss 2.020815\n",
      "iteration 600 / 1500: loss 2.064990\n",
      "iteration 700 / 1500: loss 2.245531\n",
      "iteration 800 / 1500: loss 2.073792\n",
      "iteration 900 / 1500: loss 2.134982\n",
      "iteration 1000 / 1500: loss 2.105705\n",
      "iteration 1100 / 1500: loss 2.021482\n",
      "iteration 1200 / 1500: loss 2.102590\n",
      "iteration 1300 / 1500: loss 2.030326\n",
      "iteration 1400 / 1500: loss 2.035250\n",
      "iteration 0 / 1500: loss 625.470276\n",
      "iteration 100 / 1500: loss 2.143294\n",
      "iteration 200 / 1500: loss 2.058926\n",
      "iteration 300 / 1500: loss 2.166476\n",
      "iteration 400 / 1500: loss 2.206883\n",
      "iteration 500 / 1500: loss 2.164744\n",
      "iteration 600 / 1500: loss 2.124886\n",
      "iteration 700 / 1500: loss 2.130074\n",
      "iteration 800 / 1500: loss 2.165789\n",
      "iteration 900 / 1500: loss 2.241791\n",
      "iteration 1000 / 1500: loss 2.130179\n",
      "iteration 1100 / 1500: loss 2.196421\n",
      "iteration 1200 / 1500: loss 2.155711\n",
      "iteration 1300 / 1500: loss 2.140182\n",
      "iteration 1400 / 1500: loss 2.237837\n",
      "iteration 0 / 1500: loss 1544.918197\n",
      "iteration 100 / 1500: loss 2.297538\n",
      "iteration 200 / 1500: loss 2.455512\n",
      "iteration 300 / 1500: loss 2.246096\n",
      "iteration 400 / 1500: loss 2.364725\n",
      "iteration 500 / 1500: loss 2.306116\n",
      "iteration 600 / 1500: loss 2.279855\n",
      "iteration 700 / 1500: loss 3.098209\n",
      "iteration 800 / 1500: loss 2.275076\n",
      "iteration 900 / 1500: loss 2.340588\n",
      "iteration 1000 / 1500: loss 2.433961\n",
      "iteration 1100 / 1500: loss 2.367895\n",
      "iteration 1200 / 1500: loss 2.322532\n",
      "iteration 1300 / 1500: loss 2.300959\n",
      "iteration 1400 / 1500: loss 2.251997\n",
      "iteration 0 / 1500: loss 3083.684507\n",
      "iteration 100 / 1500: loss 4.206260\n",
      "iteration 200 / 1500: loss 3.581651\n",
      "iteration 300 / 1500: loss 4.726701\n",
      "iteration 400 / 1500: loss 4.451370\n",
      "iteration 500 / 1500: loss 4.224932\n",
      "iteration 600 / 1500: loss 3.880272\n",
      "iteration 700 / 1500: loss 4.738213\n",
      "iteration 800 / 1500: loss 4.135492\n",
      "iteration 900 / 1500: loss 4.099727\n",
      "iteration 1000 / 1500: loss 4.207562\n",
      "iteration 1100 / 1500: loss 4.099218\n",
      "iteration 1200 / 1500: loss 4.709195\n",
      "iteration 1300 / 1500: loss 4.429144\n",
      "iteration 1400 / 1500: loss 3.963696\n",
      "iteration 0 / 1500: loss 6186.512029\n",
      "iteration 100 / 1500: loss 37.392134\n",
      "iteration 200 / 1500: loss 34.562667\n",
      "iteration 300 / 1500: loss 36.310927\n",
      "iteration 400 / 1500: loss 33.615299\n",
      "iteration 500 / 1500: loss 34.953217\n",
      "iteration 600 / 1500: loss 33.698433\n",
      "iteration 700 / 1500: loss 32.656098\n",
      "iteration 800 / 1500: loss 33.104750\n",
      "iteration 900 / 1500: loss 35.564467\n",
      "iteration 1000 / 1500: loss 36.284986\n",
      "iteration 1100 / 1500: loss 30.934955\n",
      "iteration 1200 / 1500: loss 32.516942\n",
      "iteration 1300 / 1500: loss 32.913956\n",
      "iteration 1400 / 1500: loss 31.204502\n",
      "iteration 0 / 1500: loss 159.279675\n",
      "iteration 100 / 1500: loss 3.524719\n",
      "iteration 200 / 1500: loss 2.781926\n",
      "iteration 300 / 1500: loss 2.548574\n",
      "iteration 400 / 1500: loss 3.520491\n",
      "iteration 500 / 1500: loss 3.880926\n",
      "iteration 600 / 1500: loss 3.498669\n",
      "iteration 700 / 1500: loss 3.412259\n",
      "iteration 800 / 1500: loss 3.829626\n",
      "iteration 900 / 1500: loss 3.527667\n",
      "iteration 1000 / 1500: loss 3.146268\n",
      "iteration 1100 / 1500: loss 3.319170\n",
      "iteration 1200 / 1500: loss 3.009076\n",
      "iteration 1300 / 1500: loss 2.617086\n",
      "iteration 1400 / 1500: loss 3.177019\n",
      "iteration 0 / 1500: loss 66.996995\n",
      "iteration 100 / 1500: loss 3.156638\n",
      "iteration 200 / 1500: loss 2.784515\n",
      "iteration 300 / 1500: loss 4.351236\n",
      "iteration 400 / 1500: loss 3.372609\n",
      "iteration 500 / 1500: loss 3.259549\n",
      "iteration 600 / 1500: loss 2.302369\n",
      "iteration 700 / 1500: loss 3.557614\n",
      "iteration 800 / 1500: loss 2.875655\n",
      "iteration 900 / 1500: loss 2.302927\n",
      "iteration 1000 / 1500: loss 3.708831\n",
      "iteration 1100 / 1500: loss 3.367518\n",
      "iteration 1200 / 1500: loss 3.790280\n",
      "iteration 1300 / 1500: loss 3.100532\n",
      "iteration 1400 / 1500: loss 2.480034\n",
      "iteration 0 / 1500: loss 36.480785\n",
      "iteration 100 / 1500: loss 4.340650\n",
      "iteration 200 / 1500: loss 2.670885\n",
      "iteration 300 / 1500: loss 2.280686\n",
      "iteration 400 / 1500: loss 2.457795\n",
      "iteration 500 / 1500: loss 3.091757\n",
      "iteration 600 / 1500: loss 2.765070\n",
      "iteration 700 / 1500: loss 3.018403\n",
      "iteration 800 / 1500: loss 2.916928\n",
      "iteration 900 / 1500: loss 2.728387\n",
      "iteration 1000 / 1500: loss 2.673182\n",
      "iteration 1100 / 1500: loss 2.356546\n",
      "iteration 1200 / 1500: loss 3.054654\n",
      "iteration 1300 / 1500: loss 2.264546\n",
      "iteration 1400 / 1500: loss 2.585259\n",
      "iteration 0 / 1500: loss 312.208375\n",
      "iteration 100 / 1500: loss 4.915799\n",
      "iteration 200 / 1500: loss 4.356533\n",
      "iteration 300 / 1500: loss 3.980674\n",
      "iteration 400 / 1500: loss 3.679077\n",
      "iteration 500 / 1500: loss 3.122168\n",
      "iteration 600 / 1500: loss 2.486007\n",
      "iteration 700 / 1500: loss 3.932289\n",
      "iteration 800 / 1500: loss 3.814899\n",
      "iteration 900 / 1500: loss 3.508730\n",
      "iteration 1000 / 1500: loss 3.931409\n",
      "iteration 1100 / 1500: loss 2.829445\n",
      "iteration 1200 / 1500: loss 3.221710\n",
      "iteration 1300 / 1500: loss 3.836032\n",
      "iteration 1400 / 1500: loss 3.031360\n",
      "iteration 0 / 1500: loss 620.199773\n",
      "iteration 100 / 1500: loss 4.738512\n",
      "iteration 200 / 1500: loss 5.759926\n",
      "iteration 300 / 1500: loss 3.799485\n",
      "iteration 400 / 1500: loss 5.517693\n",
      "iteration 500 / 1500: loss 4.299897\n",
      "iteration 600 / 1500: loss 4.531456\n",
      "iteration 700 / 1500: loss 5.114045\n",
      "iteration 800 / 1500: loss 3.726415\n",
      "iteration 900 / 1500: loss 5.430037\n",
      "iteration 1000 / 1500: loss 4.421716\n",
      "iteration 1100 / 1500: loss 4.420268\n",
      "iteration 1200 / 1500: loss 4.119027\n",
      "iteration 1300 / 1500: loss 4.126226\n",
      "iteration 1400 / 1500: loss 5.310797\n",
      "iteration 0 / 1500: loss 1560.402113\n",
      "iteration 100 / 1500: loss 9.038003\n",
      "iteration 200 / 1500: loss 8.576259\n",
      "iteration 300 / 1500: loss 8.922239\n",
      "iteration 400 / 1500: loss 8.242673\n",
      "iteration 500 / 1500: loss 10.340272\n",
      "iteration 600 / 1500: loss 8.833401\n",
      "iteration 700 / 1500: loss 9.576397\n",
      "iteration 800 / 1500: loss 7.260838\n",
      "iteration 900 / 1500: loss 9.824473\n",
      "iteration 1000 / 1500: loss 7.352836\n",
      "iteration 1100 / 1500: loss 9.047164\n",
      "iteration 1200 / 1500: loss 10.895448\n",
      "iteration 1300 / 1500: loss 9.346274\n",
      "iteration 1400 / 1500: loss 10.463569\n",
      "iteration 0 / 1500: loss 3095.502535\n",
      "iteration 100 / 1500: loss 70.747099\n",
      "iteration 200 / 1500: loss 64.233586\n",
      "iteration 300 / 1500: loss 67.752522\n",
      "iteration 400 / 1500: loss 66.761207\n",
      "iteration 500 / 1500: loss 66.760752\n",
      "iteration 600 / 1500: loss 70.670105\n",
      "iteration 700 / 1500: loss 73.310308\n",
      "iteration 800 / 1500: loss 70.177561\n",
      "iteration 900 / 1500: loss 68.392301\n",
      "iteration 1000 / 1500: loss 68.647929\n",
      "iteration 1100 / 1500: loss 68.719898\n",
      "iteration 1200 / 1500: loss 69.983913\n",
      "iteration 1300 / 1500: loss 66.098949\n",
      "iteration 1400 / 1500: loss 73.784103\n",
      "iteration 0 / 1500: loss 6097.867215\n",
      "iteration 100 / 1500: loss inf\n",
      "iteration 200 / 1500: loss inf\n",
      "iteration 300 / 1500: loss inf\n",
      "iteration 400 / 1500: loss inf\n",
      "iteration 500 / 1500: loss inf\n",
      "iteration 600 / 1500: loss inf\n",
      "iteration 700 / 1500: loss inf\n",
      "iteration 800 / 1500: loss inf\n",
      "iteration 900 / 1500: loss nan\n",
      "iteration 1000 / 1500: loss nan\n",
      "iteration 1100 / 1500: loss nan\n",
      "iteration 1200 / 1500: loss nan\n",
      "iteration 1300 / 1500: loss nan\n",
      "iteration 1400 / 1500: loss nan\n",
      "lr 1.000000e-08 reg 1.000000e+03 train accuracy: 0.143531 val accuracy: 0.163000\n",
      "lr 1.000000e-08 reg 2.000000e+03 train accuracy: 0.160245 val accuracy: 0.174000\n",
      "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.143878 val accuracy: 0.158000\n",
      "lr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.142306 val accuracy: 0.143000\n",
      "lr 1.000000e-08 reg 2.000000e+04 train accuracy: 0.177857 val accuracy: 0.184000\n",
      "lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.204633 val accuracy: 0.232000\n",
      "lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.270020 val accuracy: 0.281000\n",
      "lr 1.000000e-08 reg 2.000000e+05 train accuracy: 0.271816 val accuracy: 0.281000\n",
      "lr 5.000000e-08 reg 1.000000e+03 train accuracy: 0.218776 val accuracy: 0.221000\n",
      "lr 5.000000e-08 reg 2.000000e+03 train accuracy: 0.233163 val accuracy: 0.245000\n",
      "lr 5.000000e-08 reg 5.000000e+03 train accuracy: 0.253755 val accuracy: 0.258000\n",
      "lr 5.000000e-08 reg 1.000000e+04 train accuracy: 0.302816 val accuracy: 0.313000\n",
      "lr 5.000000e-08 reg 2.000000e+04 train accuracy: 0.327959 val accuracy: 0.347000\n",
      "lr 5.000000e-08 reg 5.000000e+04 train accuracy: 0.307510 val accuracy: 0.319000\n",
      "lr 5.000000e-08 reg 1.000000e+05 train accuracy: 0.284878 val accuracy: 0.303000\n",
      "lr 5.000000e-08 reg 2.000000e+05 train accuracy: 0.263837 val accuracy: 0.282000\n",
      "lr 1.000000e-07 reg 1.000000e+03 train accuracy: 0.267204 val accuracy: 0.268000\n",
      "lr 1.000000e-07 reg 2.000000e+03 train accuracy: 0.281510 val accuracy: 0.277000\n",
      "lr 1.000000e-07 reg 5.000000e+03 train accuracy: 0.328939 val accuracy: 0.337000\n",
      "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.353347 val accuracy: 0.356000\n",
      "lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.336510 val accuracy: 0.348000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.310673 val accuracy: 0.326000\n",
      "lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.293245 val accuracy: 0.307000\n",
      "lr 1.000000e-07 reg 2.000000e+05 train accuracy: 0.268347 val accuracy: 0.278000\n",
      "lr 2.000000e-07 reg 1.000000e+03 train accuracy: 0.317041 val accuracy: 0.332000\n",
      "lr 2.000000e-07 reg 2.000000e+03 train accuracy: 0.351041 val accuracy: 0.352000\n",
      "lr 2.000000e-07 reg 5.000000e+03 train accuracy: 0.371082 val accuracy: 0.380000\n",
      "lr 2.000000e-07 reg 1.000000e+04 train accuracy: 0.356102 val accuracy: 0.365000\n",
      "lr 2.000000e-07 reg 2.000000e+04 train accuracy: 0.340102 val accuracy: 0.352000\n",
      "lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.304163 val accuracy: 0.313000\n",
      "lr 2.000000e-07 reg 1.000000e+05 train accuracy: 0.277796 val accuracy: 0.289000\n",
      "lr 2.000000e-07 reg 2.000000e+05 train accuracy: 0.282898 val accuracy: 0.275000\n",
      "lr 3.000000e-07 reg 1.000000e+03 train accuracy: 0.352531 val accuracy: 0.349000\n",
      "lr 3.000000e-07 reg 2.000000e+03 train accuracy: 0.379041 val accuracy: 0.398000\n",
      "lr 3.000000e-07 reg 5.000000e+03 train accuracy: 0.373755 val accuracy: 0.391000\n",
      "lr 3.000000e-07 reg 1.000000e+04 train accuracy: 0.356776 val accuracy: 0.372000\n",
      "lr 3.000000e-07 reg 2.000000e+04 train accuracy: 0.327796 val accuracy: 0.348000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.309878 val accuracy: 0.323000\n",
      "lr 3.000000e-07 reg 1.000000e+05 train accuracy: 0.275143 val accuracy: 0.283000\n",
      "lr 3.000000e-07 reg 2.000000e+05 train accuracy: 0.269000 val accuracy: 0.278000\n",
      "lr 5.000000e-07 reg 1.000000e+03 train accuracy: 0.387265 val accuracy: 0.400000\n",
      "lr 5.000000e-07 reg 2.000000e+03 train accuracy: 0.393061 val accuracy: 0.392000\n",
      "lr 5.000000e-07 reg 5.000000e+03 train accuracy: 0.369612 val accuracy: 0.385000\n",
      "lr 5.000000e-07 reg 1.000000e+04 train accuracy: 0.353449 val accuracy: 0.373000\n",
      "lr 5.000000e-07 reg 2.000000e+04 train accuracy: 0.336020 val accuracy: 0.350000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.293959 val accuracy: 0.313000\n",
      "lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.285449 val accuracy: 0.306000\n",
      "lr 5.000000e-07 reg 2.000000e+05 train accuracy: 0.252184 val accuracy: 0.255000\n",
      "lr 1.000000e-06 reg 1.000000e+03 train accuracy: 0.401857 val accuracy: 0.401000\n",
      "lr 1.000000e-06 reg 2.000000e+03 train accuracy: 0.381367 val accuracy: 0.396000\n",
      "lr 1.000000e-06 reg 5.000000e+03 train accuracy: 0.355408 val accuracy: 0.362000\n",
      "lr 1.000000e-06 reg 1.000000e+04 train accuracy: 0.343020 val accuracy: 0.359000\n",
      "lr 1.000000e-06 reg 2.000000e+04 train accuracy: 0.327959 val accuracy: 0.350000\n",
      "lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.287816 val accuracy: 0.298000\n",
      "lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.295163 val accuracy: 0.300000\n",
      "lr 1.000000e-06 reg 2.000000e+05 train accuracy: 0.253388 val accuracy: 0.268000\n",
      "lr 2.000000e-06 reg 1.000000e+03 train accuracy: 0.396347 val accuracy: 0.380000\n",
      "lr 2.000000e-06 reg 2.000000e+03 train accuracy: 0.382061 val accuracy: 0.370000\n",
      "lr 2.000000e-06 reg 5.000000e+03 train accuracy: 0.343796 val accuracy: 0.346000\n",
      "lr 2.000000e-06 reg 1.000000e+04 train accuracy: 0.333102 val accuracy: 0.353000\n",
      "lr 2.000000e-06 reg 2.000000e+04 train accuracy: 0.307020 val accuracy: 0.311000\n",
      "lr 2.000000e-06 reg 5.000000e+04 train accuracy: 0.258898 val accuracy: 0.273000\n",
      "lr 2.000000e-06 reg 1.000000e+05 train accuracy: 0.242816 val accuracy: 0.253000\n",
      "lr 2.000000e-06 reg 2.000000e+05 train accuracy: 0.232531 val accuracy: 0.231000\n",
      "lr 4.000000e-06 reg 1.000000e+03 train accuracy: 0.379531 val accuracy: 0.385000\n",
      "lr 4.000000e-06 reg 2.000000e+03 train accuracy: 0.349469 val accuracy: 0.359000\n",
      "lr 4.000000e-06 reg 5.000000e+03 train accuracy: 0.316061 val accuracy: 0.320000\n",
      "lr 4.000000e-06 reg 1.000000e+04 train accuracy: 0.295041 val accuracy: 0.327000\n",
      "lr 4.000000e-06 reg 2.000000e+04 train accuracy: 0.280898 val accuracy: 0.297000\n",
      "lr 4.000000e-06 reg 5.000000e+04 train accuracy: 0.202592 val accuracy: 0.214000\n",
      "lr 4.000000e-06 reg 1.000000e+05 train accuracy: 0.120571 val accuracy: 0.117000\n",
      "lr 4.000000e-06 reg 2.000000e+05 train accuracy: 0.113898 val accuracy: 0.121000\n",
      "lr 8.000000e-06 reg 1.000000e+03 train accuracy: 0.283306 val accuracy: 0.287000\n",
      "lr 8.000000e-06 reg 2.000000e+03 train accuracy: 0.270429 val accuracy: 0.294000\n",
      "lr 8.000000e-06 reg 5.000000e+03 train accuracy: 0.251531 val accuracy: 0.249000\n",
      "lr 8.000000e-06 reg 1.000000e+04 train accuracy: 0.200571 val accuracy: 0.209000\n",
      "lr 8.000000e-06 reg 2.000000e+04 train accuracy: 0.182082 val accuracy: 0.164000\n",
      "lr 8.000000e-06 reg 5.000000e+04 train accuracy: 0.081571 val accuracy: 0.076000\n",
      "lr 8.000000e-06 reg 1.000000e+05 train accuracy: 0.095449 val accuracy: 0.091000\n",
      "lr 8.000000e-06 reg 2.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.000000e-05 reg 1.000000e+03 train accuracy: 0.191755 val accuracy: 0.183000\n",
      "lr 5.000000e-05 reg 2.000000e+03 train accuracy: 0.172041 val accuracy: 0.185000\n",
      "lr 5.000000e-05 reg 5.000000e+03 train accuracy: 0.135286 val accuracy: 0.148000\n",
      "lr 5.000000e-05 reg 1.000000e+04 train accuracy: 0.082735 val accuracy: 0.083000\n",
      "lr 5.000000e-05 reg 2.000000e+04 train accuracy: 0.096041 val accuracy: 0.082000\n",
      "lr 5.000000e-05 reg 5.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.000000e-05 reg 1.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 5.000000e-05 reg 2.000000e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "best validation accuracy achieved during cross-validation: 0.401000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "# Provided as a reference. You may or may not want to change these hyperparameters\n",
    "learning_rates = [0.5e-7,1e-7,2e-7,3e-7,5e-7,1e-8,5e-5,1e-6,2e-6,4e-6,8e-6]\n",
    "regularization_strengths = [5e3,2e3,1e3,1e4,2e4,5e4,1e5,2e5]\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "for learning_rt in learning_rates:\n",
    "    for reg_str in regularization_strengths:\n",
    "            softmax = Softmax()\n",
    "            loss_hist = softmax.train(X_train, y_train, learning_rate=learning_rt, reg=reg_str,\n",
    "                      num_iters=1500, verbose=True)\n",
    "            y_train_pred = softmax.predict(X_train)\n",
    "            training_accuracy = np.mean(y_train == y_train_pred)\n",
    "            y_val_pred = softmax.predict(X_val)\n",
    "            validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "            results[(learning_rt,reg_str)] = (training_accuracy,validation_accuracy)\n",
    "            if(validation_accuracy>best_val):\n",
    "                best_val = validation_accuracy\n",
    "                best_softmax = softmax\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb37cc6",
   "metadata": {
    "test": "test"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.380000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df501314",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n",
    "True because softmax is probability based. Therefore it will never give 0 loss even for true image. This is not the case with SVM. SVM just wants correct image score to be higher than other scores + delta \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ade33adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAFrCAYAAADVbFNIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADBtUlEQVR4nOz9d3hk15nfib8XhUIOhZxzbgANdE7syJwkBpHKGknWBGlm/Iy9E9azs1791mOP1+vxemcn2BMUrFGiSIliDk12k50zuhto5JxzAQWgABSA+/sD0PlcyGRrRiyKYun9PI8evay+devck+7F93vecy3btkVRFEVRFCWUCfugC6AoiqIoivJ+ow88iqIoiqKEPPrAoyiKoihKyKMPPIqiKIqihDz6wKMoiqIoSsijDzyKoiiKooQ8H9oHHsuyjliWNfBBl0NRFLAsq8eyrLve4fODlmW1BuNciqL8/FiW9Q3Lsv70gy7HB8GH9oFHUZQPD7Ztn7Jtu+KDLofyi0MfWJVfNvSBRwkZLMsK/6DLoPzz0XZTlA83H5Yx/Ev/wLPxV8K/sSzrlmVZ05Zlfd2yrKh3OO5/tSyr07Is38axjzr+7fOWZZ22LOs/b5yj27Ks+x3/nmhZ1j9YljVsWdagZVl/almW6xd1jco6lmXlWZb1Q8uyxi3LmrQs6y8tyyqxLOvNjf+esCzr25ZleRzf6bEs648sy7ohIvMfloEX4uz66fH60xb0O7WbZVmftSyrd6Ot/7cPsPzKT/HPHZuWZX1LRPJF5HnLsuYsy/rDD/QCfoWxLGubZVlXN+6N3xeRKMe/PWRZVoNlWV7Lss5alrXV8W/ZlmU9s9Hm3ZZl/UvHv33VsqynLcv6R8uyZkXk87/Qi/o5+aV/4Nng0yJyr4iUiEi5iPzJOxzTKSIHRSRRRP5/IvKPlmVlOf59j4i0ikiqiPwnEfkHy7KsjX/7poisiEipiGwTkXtE5EvBvwzl3dh4wHxBRHpFpFBEckTkeyJiicifiUi2iFSJSJ6IfPWnvv5JEXlQRDy2ba/8Ykqs3IZ/yngVcbTbxnF/IyKflfW2ThGR3Pe7oMrP5ucZm7Ztf1ZE+kTkYdu242zb/k+/8IIrYllWhIg8KyLfEpFkEfmBiDy+8W/bReRrIvKbsj7e/ruIPGdZVqRlWWEi8ryIXJf19r5TRH7Psqx7Haf/qIg8Levj99u/gMt579i2/Uv9PxHpEZHfcvz3A7L+cHNERAZu870GEfnoRvx5Eelw/FuMiNgikikiGSKyJCLRjn//pIic+KCv/VfpfyKyT0TGRST8Zxz3iIhc+6n+8cUPuvz6v03t8TPH60+3m4j8WxH5nuO/Y0VkWUTu+qCv6Vf9f+9xbGr7fbBtd0hEhkTEcnx2VkT+VNb/wPh3P3V8q4gclnWBoO+n/u3fiMjXN+KvisjbH/T1/XP/92GR//sdca+s/0WxCcuyPici/1rW/wIREYmTdTXnJ4z8JLBte2FD3ImT9adet4gMI/hI2E/9pvL+kycivfZPKTSWZaWLyF/IunoXL+ttM/1T39W2+uXiZ47Xdzgu2/nftm3PW5Y1+T6UTfnn817GpvLBki0ig/bGU8oGvRv/XyAiv2ZZ1u86/i1i4zurIpJtWZbX8W8uETnl+O8P3bz7YbG08hxxvqw/sRosyyoQkb8Tkd8RkRTbtj0i0ijrkuvPol/WFZ5U27Y9G/9LsG27OiglV/6p9ItI/juswfkzWVfjttq2nSAin5H/uV1tUX6ZuO14deBst2Hn9yzLipF1mV354Pl5x6aOyw+eYRHJcSzfEFkfkyLr7frvHfc9j23bMbZtf3fj37p/6t/ibdt+wHGeD137flgeeH7bsqxcy7KSReSPReT7P/XvsbJe+eMiIpZlfUFEav4pJ7Zte1hEXhORP7csK8GyrLCNxXiHg1d85Z/ARVkfnP/RsqzYjYWuB2T9L8c5EfFalpUjIn/wQRZS+Sfxs8brO/G0iDxkWdYdG+sO/k/58MxPoc7POzZHRaT4F1tU5ac4J+vrU//lRmLAYyKye+Pf/k5EfsuyrD3WOrGWZT1oWVa8rLf57EZiQbRlWS7Lsmosy9r1AV1HUPiwTCjfkfWHkq6N/23aNMm27Vsi8uey3rijIlIrImf+Gef/nKxLebdkXZJ9WkSybvsNJajYtr0qIg/L+sLxPhEZEJGPy/oC9O0iMiMiL4rIDz+oMir/ZG47Xt8J27abROS3N747LOvjUDcW/SXgPYzNPxORP9nIAPr9X1yJlZ9g2/ayiDwm6+tYp2W93X648W+XReTXReQvN/6tY+M4Z5vXi0i3iEyIyN/LelLQhxZrs7X3y4dlWT0i8iXbto9/0GVRFEVRFOXDyYdF4VEURVEURfm50QceRVEURVFCnl96S0tRFEVRFOW9ogqPoiiKoighz203HvzNF/4/I/8UN8ebz6d7+ZpvyG3i2N8hqcL3jUgTLy+yLYcrKcLEqzXDJs6/NmXiSzXRFPDivIkLMjnPdBmLxVNO3zBxVgF7DU73LG66nqkq9jFbSGCbnd0/3mli/8dvmbilf87EFsUQt5drXsrlGlbiJky8dxjlrDcj38TeKfblSq6tN3H1Dyhb5295TfzVh3/9n7KX0D+J/+0PvmAKtTKVbD7PSy0wcfyaz8S+tjgTL5VQ36OuXhPvbaGOW+tow8IC2j/8MvuVxdcsmLhrqc7E3uvUdVoeZYhf4zxWBJ+LiHQm0SjpW9myJf8Sdd8eTvVVrrBPVl+g3sT90mLiop07KF8XZfVE+vnhpmW+m5Nh4tj+mya24xgv/mT+rvi//5f/FJT2/PKf/K/mIjMKisznSa+Pc9BnaKfRsXQTuzI7TDxxlf5et5Zk4oZYznnfdIKJu5MY40vSbuKR6S+Y+EjgmyY+5eEF6XlhpSbO3M88ICJy3H/exGtzjPPYcY+Ja32XTXyihf54TGZNnOWm3P99jt/et5M+ces6Y63wriYTh03QTxs66k380I4uE0/G8d1/88SJoI3Nv/iDT5oCRqeaPVJlsXmLiXuX6OPROVdNnD9zp4m37eY6b14dNfFUJHPTgkUfKc6rNPHSWKGJm6ee5vxL95jYtZP+3h9+2sTLw/QFEZHc2cdMnOhhviz0t5l4PC/NxI1n3jbx9hXa7cpO+kLKGn2vapzvhi0PmvjNeNo/YZpr9qUxl+2M4X4x87bXxF98+Y2gtOfh//AnphF2x9IGPReor/QS9vpbLOAekj3KvNy/TFvGJjxr4igP7b3kpR5WbOohYo15+aqPY3Ys0Mcj8rkXxYzxeso74nI2Xc+5Isadt4N5bTCa9vh4B/PL1VskOKd8nHvCG0keEx95gznoViL3n+w05oXIl2mOhS9Thos3VrmGKX53yxTz8p8/9e13bEtVeBRFURRFCXn0gUdRFEVRlJDntpbW0TOxJu7IQ64fyUPWtJOQRHf5kcX67kYGj0NBFN8iUtaqYCt11CHffcEXY+KuHchXp9uQKEsXr5l4qRQJbbaPFyxH1SDxiYjEe7ieLT1eEw/lfcvE0f1cT1jWkokjlylHrYXl1jODLZOT/RI/lnCXCfM6KHfMJOcvHP2aiRcqD5g4MIzEGUxKej0m7o7FHgpLI06wkH4DAVTB+OiLJg6PZfPUnszrHHPHVhM3JCJ39joszbsz6HJpLuyqyBWk34VcXr00faXPxK6EzVLrYueMiWdu8v3LpeWUyUJqH/TdbeKVO5F8y05z3sghZNFiL7ZJgh/5d7oOK83Xx29ll9SaOO7CFROfTqC/BIvq7dgSV1uQrLMfGzPxlVPUb6qNVOy+RXtkFrMh+fGt9LuEHxFf8ayZ+EIZlkHKiMMKTW7kPLP0/ZlZxlBaPGW4/hYWpohIVvhBE0+nYBu5puibZ/JopxJHn7o+xzV7d3PewjA+d7+B7RWoRtbf2klfC09y8bvbGkw8PIUVF9eG5SBPSNBI6aVeb/mwLLYnMu/mRNFnzzTv4/jaEybub2Ju3h/LnOUvZFyPtzhsieuM8cjdHJNUjiU1MkJfK5nAFk5NxDJdGtu8AW+L1W3iHWsBE/simKtbx7AK0xO5/nGb2O7F0vNtpz+PTGE3l+z0mnj7Ga655xjjYm8/N6H285yz9R6stC9KcCi5yFyUuJXf2uXFFr8xyrwWE0+/S38di3ngI7TlJR/t/VCL18T+TzH/pj1H3fZWY83/1go24q0k7rPeK1iHmQebTTx6ybF+Q0RS02iP6cKTlPXmx018OpXvpNzHNZxppw3u3075zlczv8RO0Aezwz0m9u2lzZb6uG9mCeO3Yg996OJVx7KDd0EVHkVRFEVRQh594FEURVEUJeS5raXV4cKiSBlDEm6cQU4+OMUq7LML20y8JemsiW+ukl2QNYnk7B/FJokYQKbyF0Y5Pse2uCsG2XRkAbthZwpZUG/M8WLmLD+2mohI9ASS6PmFThMvbcXq2D+ARJg4RzzZTvaXN4njB73fNfFYxFET5yxSLyNhyK9zh5GHz3bsNbErFzm51nF8MPE7VOfcDuyFmCRk6pGcIyYuaCZ7aWiYrpJ4AGuwIhOp9doF7KN0R7ZE9hS2z8wiUqZ/HsvxbDe2X/UMFkp2LW1281rDpuspPnDIxJE9SNlzrUjosza/PezIftl2Fevz+iTP/asjXGdZSauJX4jAZi3uKjHxtB8rZ7yP/l9Zg1w84OI8waIxwWvihSoyat6epmxPcolyZdRj4uFIsrHi0ilbdiP1VpGH7TGTiCxf00Q9pIUjxQ9P05/uqaEfXIjDVspYpd/MRW9+Vd3WU9gAzQeQuKerGHfSw/cz85CyE+MZO6te5oKj7kuU4/5jJi7395h4YAaJfyAZ27LE+yCfR3H+xF0X5P1gnKlWvC3UxaV0+n9eI2NkhyMbK3GIcdARjpU6FkcHsJsYU4lj1H0ggwyq5Bm+m3aTeWosnLl2domxYk1iQ2Zkbs6IrfZx3kEPc/7VAEsRahsyTewv4viESOwVdyRZdFnHmc9jH6B8069RPvdCoYkrTmCtrI1hucS6GSNJK9RvsMidYHyttXD+mAIs7+xlPi/wMVf2Heox8bEVxk6pXW/i6XTssMBJ5qs2mzERk/umiV+eZWzuWOJ+OlzBnLncRQd8eR/jQEQk+zr3h8wi7Na5bMoxe55yn6xirG1N43483/KWifduwxpu76ZPPZ//iokDlbTr1luOzMLcQhOv+OlD0XGbrbh3QhUeRVEURVFCHn3gURRFURQl5LmtpTXjwfbZNo6NNVhK5sR0eBnH9yNHDfUgs255+A0TH3+BzI5t5VhXO+ewgJriyeTyDCMDdicix0UvsPL8R0XIgzXNyIAVqUh2IiKXYlkxfmd8vYn7Yr9t4pFJMkymBbl//0f2mHjq+adMnFxGBo51DSm/M/8OE28NI7tk4VuvmjjlQay+yinslltbN2ewBIvLLmTEB6uwI/repB3s1NdNvJxEvXZlIBfmdiMV30rDuomxeX5OXSNLw1dEv7Am2cTseArSaX4mMvPQEplSr/TSLw6Xkh0mIjLdTvl8EcjIn6ykn/z7cM61bZh2mFlAWrdW6cN7Suk/Iy1k8KTeyefbbiK5T21Djp71I/HmnyKOn+eYYFE/S1vOZiP1e19nI67jRdtNPHDXORNXvcK4iH6da+zbg8V4LR57y9WNfbK3AZtI7kIGX8l40cSvLe43cbmLdm3zkLmX0YD1JCIyXoyNM+Ph39wTlKlgFFm7R/iNDC/ZQrMLWCOvDdInlosYyyXdZFZ2JHL9kVFk7EwMcf11hXz3FYcdGEySYwr5j73YZlmDfO4v4DpjfNgMi2vMTVFRHhN3dTM37ShxbISZz9hsHsUmjB1jPAaiaIPVceam8CTmY4lm3ghLZT4WERmew/ocaaTd90Vy3qY16vtQJ/eL4TyydztXyNhLz+S+c7YNq3NXNOPrpovN/YpTacPuecq9lMqccmicDLxgEbnda2L3LPe+mXzmyokU2sDVz/HzjiUiEUuM07h99Anfi9y2Z45hVR4YYR5reQvbsszCFrRGCzl/iSMLexd1VXhpswWfksJxCbZjP794xtrkR7lvPjLI/evtdq4zznOviWu6aftYYR7ZctKRTVjM0o7VXu4/b+dz/QUx9IO992y2yd8JVXgURVEURQl59IFHURRFUZSQ57aWVtIU8u31gEOWbEHKDFxn06uiHLKO8ndgGXiXyeTZcojMn7V5JMoJhxRd0sMq78b4BhMn+B32gRspa6oRqfdEFpsPRQsSoohIeTNWR/c80qrvEbJrwqweE0fOUKakbuTF/lSkufJBpNuvTyG576jCDhx9heucuZf3dm3pJ7Oho51MmOURVp4Li+LfM6U2VtSlq8jdOfNscJVWg31x1kV9pwWwhsIs6uLyIeq7dpAstf6rvPtkaYiMl7zD2HgxP+Y6cw+QYdDeh922/2FsyPyXkV1FRDpW2NRuKY9z/Q/H+472BpBXZ1aweKZnyTpMrsXiaG3HTp2LQR7PbcBOG3ZhIVknsFwuFdHO0VW0Z94LWGDBIioKe27n22RCnKzEeotPwkp8oJWy/TiTdl2spq6yOqnD8UTOszOdY5r3Iy0nrNAPkkYdmy72c4ydSxabZWNn36oju1FEJOw6G6UFLjKOdtfQL67HV5l4YQiZfjaOuSA8Als5s546altlLihJod+MxB+n3H1YNzvdHzFxVyOyfKwH20Do1u8ZVzTjaLtFf0zwOrJqtvF5+nnsp4m9ZG+ldmN1VsSQnROIxv5tOoeNV1ZAfQWOMQ++dAJrZV8SNmnlJHb+za2fNfHSOPOgiIg00t+2xjC/vJpJ3dc5Nr08tYSlWdTK+L8vmvmobS+ZvCvu+0085WUsF+QVmngxh7orzCM7dMzPMRPZWL0in5BgEF7A2EkIMC6yOrj3jQ1j3UiNY27NpP2aB6n3jtNYSUcrzph4dZHzvJLLXLlawHXFzTF35eV4TByY5B6Y240lOVix+bFg2cLimvEyR7ibsNlifpN2uthBXP4g7R01wXKJoVSeIV7rZD6qPNpg4r2DfPfMVspUncvymuzFHhP7T5OZJkd/Xd4JVXgURVEURQl59IFHURRFUZSQ5/ZZWo5/HXMhX2U7NuKKewLZzWch759J9ph4x3E2GJwo+ZSJA96/MvGueiSuZod9MPdRpOjscZ7PEhaRK3MsZMNbq0i3Z68jLYqIHN5KpkJ4GrLb7GtYYiWHftfEax1c860oNk2K24J1d64Zuf9TC2TmzGQgD4/9IXLtwXNI6A3xlDu8BsnS76hHkS0SLCquU9bpNWRmVzG/tzaI3J2ShNTaNkt80JGNtO0bZOGsOTK/FtNY2T+Sy2p791OUIb8Ge+CZNaTcLy1hJf6wA0vDX4xELyJS1cy/DU/QJik92K/e3HoT20lI4luysfSOr9EmD5RgD1yepk/OnENeXfwj2iT5O8ixW1excnpnHFlHyVgxwSJpkHp82/FeqaEE7KCUQmyP0xewjKIisVJ3dxDPjWFLzKbTrqsLnDPf8a668C2Mj9Wnjpi4+9cYd8kuJPCBS2QW7TjosG1FZGUH7b+QiBXntBIde39KhMPdnHa8Y+pADH3w1IjDtoxhfC04bOuMbVgdaZeYa56bft7EJbvI/tiVjkUXTFJPYkeE7eXi/r6fzQDvvkVdPP/7bMq211FHg5XYb2PX6HfVPqyrHVWMg5ZFbMbsTubBmj4qeyaBcdC0E1stNdFhdVxzZO+IyMpR+kzbTd6DlOao++FeNgUd215v4q37vm7iG+HYXmNnKNO2Kcb4G6n0ne0rHhMXXmEMLpZgpa86Npctu+Wl0MFxtOTCDMsW7nFRD29HM9/NeijndDFtX/Gsw6os4Ls7exib4TnMj6ncBqVmjXn5x6XcWyKvMQ6WEpg3Dmdh4bov0FdufYLPRUQeP0Ef+W4d1tf2cHaybXqR+T4nk99YbCHjzhdDRpnteL/m/N4fm3hklnn8wlaWYOQNMbf+2wu0629sY64pTnlSfhaq8CiKoiiKEvLoA4+iKIqiKCHPbS0t7+RNEx/ei0z39fN87aOl2CE1bQ6Jewx9sM/lMfFdHRzfvP9xE89dYYW1qwI5fW8/8uPrz2Ar5NyH/LzkI5tsZAk57Wje5qwev2C/hb9JmeY/yyaByaNIpc0pZCpELpKZMz6E1FiW4TXxrCMDKfFZfnclEcvBn8gzZrKHurjheBdRXirnCSZnE7CrwguQtXdPPGbiKw9eNXGSF5lyKYKMpbUrHzPx0Ah2gr2C3Bl/AtnVcxhJtG0HmT3NfjJTPr2AVeKv5JzWc/UmXq5ClhcRuVWEbejtw5ZarMG+KZukrc71IYV+K4C8GpnHb4xfRX6fLUAizt7C9cS8jQT7Rjgye0lkIWVw2JI5OZvl/mBwM4UN0zJmkXWXU7Cbhy7S3wMjDSa2KyhzRyRtUL/fsbHdzd8w8V+k8N3KYupkfz9zwvl87MWyCMqW2sXx5bVsOtm6TD8TETk232PiC2O0zeu7OdfQ09g1lZlI8IOOd0Y1pFIX5RFsbpbg8OdvZTG/xE0zR9xKwuZMy0WKv3icceApoF0/z6uk3jMXcrHW7GzacHvZbhOnxjN+77vGtXUlOjaSHMeq3lX3nznmHPbRfA42kSsFWyq6ieUAETfIKFr+G+am03/FONh1iLkybZJ5V0TEf5V/i99OHzs25zFxm2MDQLvn+8ThzH+ZcVjGk4X0pdVUxnJxFnZH/DiZR91D2COpQ2QNzzuyd2eKz0uw8SRgCQ3nc9+YeQ5rMNGxcW4KLrrkxdO/6lYoZ+c0xzcUYbGG/5B2XTuC/ZnwA9rsjIvxnhFfaGLXbsbgfC/37rRvOTIRReTFnfSpaodN3JlBpmR4D95apZts2I5CzpvTwzgdT2M87vDSr8cTqYycrzk2TKxmXv6yo3jRS45NfcNfcJT6UXknVOFRFEVRFCXk0QceRVEURVFCnttaWmUjZKNcbEVCfCIF+WpgihXyXWscHxaBxD2ThyTcOoVc7TmPRdFdjITcM/WyifuHsYO2fILnsyk/El/+CN+NLmSjuev9m9+TcijjzynrkbtN/MANLIeIMK7H70IePxzPKvlBQfpevIQkHohFWo4qo2pXB5GN/SusbJdm5MtDNtkfxz3IxiIPSLDImXVkHcU4MiSWnjHx4dNIwkMubK+KXuTIZw9T9wdysZ/mLyFdH9+L3ZQRQE4us6iXkRmkzBcjsDSze8g6KS+iDN3zlEFEZMGxAebWZWTUW01kOsiQI1NlK7L7WTeyc1w4/eTqQbLxAjfJ5OuPQcq9Y4LdIEvvJ91g5lU2m6zqRZodjiuUYBPfyjW++SibJeZcIfspvIy+PLrqeL/VVezJ5oeow5ZLyMaRdbwDKGoNi6HUsUmYPcE11lTRrg8F6MsnUulPszY2iasBu01E5JlUsgBdB75k4opBJPG6AON0OtORgfUy9s6+O7G3n0+pN3GEizEYv4REP+lm/NbPkPnUueA18a4DWH3p04ybYHKsAguiYew5E0fGkW3TXMVmctGOTTtX/F4TD5dg+9+Y/C0Tj2ey+WWmm6zZXafo4yOZlCHiUeqi7xnmu8dyGUNtp7DerCxsMhGR+GLqNbwMK/LSt2lncbz6KKKffnW1m2zaxSradihwxMTLZdxH7uvk+J5RMkInShtM7BbmkUQ/7R/Zhq0WLGI6GVNr9Y7M4Fhsy8UylhGMjVI/WwX7fzqa5RzhR8k+XOvFxrmRz/x7MJf22DZBu1Yc5L4UM8zYD1yhzhdGvRyzn3KKiETEc+8fTKHR5hf5jaRVxnmPizGY2sY70rwxjMHyAa6zsRArNcxNe7xZx+eFSdwr+/voa/PzLLsZKuU543fknVGFR1EURVGUkEcfeBRFURRFCXlua2mt3I09lNuFjWHdRKZaOIJdMTXKO322hCFH1Uwjj16oRDaNTUJS63K8Uv5oOrLZkhd5zB5FTr3uxzKJHETWy8rjt3yJ2BMiIhfTDpg4/RUktfPZLPuOmX/NxJVVSHk/CuO8ScPId/EVyI6+CCyXqBXk/ugMJM6u8JMmTozBZvDO8e6ZJ2yyWYJJRhmSZ9FlJMLUSrJt2jMcu7tdRMpfTaUdtjuy3cYHKbdlYWlu73Wc54u0ed9x3rG1Vkv7B5rJ/GoRLJHUIiT61CnvpusJDCFfX1vhXG6L35649wcmnu/g/Srx8dgr/kWyP5afp49t3cbwGB1Aih88io2Ve5K+ut+xKdfpHdhAcTfoO8FiYO6jJr7jFhL90BTtupKJ1eVx0d+THO8dy5nHDp5Ooz5rvVgSOclcS+R1xkTMnR4Tr/Zi/76WgSWZtuIYvwNY4cvlbComIrIWRWZdTiMZOydjsZBiLcZ8XO+PuJ6jXMMFwQLKTmUDwykffWJ6HCt99yiWuaxgW+d/gbnM08HnL3jpv1+Q4HG5HSk/bYF3CXrXqLP9N+jjJ3dxDXYP4y7Rpt32xNMfXx2lTfpyOH4hGxt6KptlCKURZC/Nzjxi4hY34zErn+96p6gvEZGVCTaZTA5jfu1PYS6ITMaWLBvjvN5Y5pfUTuaX2VnOGbeEHT5MF5PkcGwW/0tYcSMl9LekipMmvlhPhm6wXluYVshYWLh8ycTXq8gOvK8N26gp44cmfibpIRNHhrHJY65jo774Aq4xPp3rKjpLnbR/GXs98Rrt3ZdPZlbmLSpufjvj+iO9tIWIyI+rsdDyWrHHXKWMu/A0MsTaE2i/XA/9sWWZeTBxH9dWfYuy/vcJngMejmJuXWtjDCYlM1buTaIML/WTGfhuqMKjKIqiKErIow88iqIoiqKEPLe1tOJeRaYcKEEWOxdH9sfBRa+JZyKRrOwmjgnsRMascWzaF91OpkxMItJtbAYWS1wYq9MtR5ZGYR3Ww7VJfjc7GVl++/DmzbDGbyB/NZXznS2r/2hiX44j62wGGbgojnKvlmFXuZKRERNbOedo6usmDvMiUedOUhcdfuTFkoAjI66Hev+cQ6J/r8wPktmwkMRK95YIbDlPFzZIfw52Qt00UubidWTHQR92YsCHBfZSLL9VeJLn6slxbImhJM5/YIK6OJlPxlXcVTJTztjImiIiVSVIssOz2C4FAbIeFs6R8dOW9KyJY/o4V80wm7tl3seQWEh1SOv9yNS9wx4T52aT8dL2Gu1fm49VEraIrB0sKrxkPDR0YytXzmNXtb5FX650vGNp4DJtmbeN9o7s57tXx9DQk2zkZ+vXqbeBSPrscs83TLxnDsn5rI2dUZjNO4Nq57BPRESaLOp3KYy6232ec83vfdvxBY5x30dfazuBdTV8jWNyfdgbK3lsVLc4xXici6ZfLz5Ddk2Ti7J+Mu79+RtxqovrrN3Bbw+msjSg+QT9/YjDxxktwqoe8TDn3bJ7TLzdsVndyZv0l74sNner7rjXxA05zGvecNomLonN8NIGnjZxmJ8yi4iczaHdU1OYz9ZG2Qww3WbO70hm3LlbmGsjDh81cdKs18SWm347MEBZlz20eU06VrUvg/Z3LXDM2Mrm9/MFg75+ljaU30/mUOILtMHkAebc6pufM3FHKfNp0nXqNOEY73aLDHC9qQPcoyIE290+y+deN/W8cA3r2F2HpZi9QHu9Hdj8nru9YY73sw0z7yTEMo6yp/j+/CjjqCiD+3dRFxZodzT3x4U+2rLCYZN5Hff1ziNkjZavsuTjeiSW3paMn710QBUeRVEURVFCHn3gURRFURQl5LmtpeW2yC6Kuwv5q/KlUybum0EiS1skKyqhGhk0ogvrIunLSIs3XueYgqx6E7/2Ip9XPIBcuyZIaJnf5jxRd3IZyUNIlG+GH950PakJZLOkdTism/1I7fmOTZ3W5pBEa6PJ8Lr2fX47IfGsiZMqqKOVQY7/htfDeYqQ5lI9yIC+VWTziAKnFXevBIvGLMp92E+Wxw6HtdRaRDmybmBrjEZ7TNw0iG0YM8oLhVofOmHisreQjfNmkeurC8kWukBigLS6HO/PGUemHLqDrIXd/cipIiLDL2OJTu5x2KMxhSb2LJPxtacb66qniLadjMaKi2iifNEFDSaOLaTu6iwyRwa7yS6bKqYfziyQaTSxRl8IFisHyCYsuYTE7T+CVelxvCcrcJYyT2c6MrbGkdC95VjGOStIy+fSyY7ZNlxo4oO+/2bim3uR319PoT9FNWNPFK0yNk85No0UEcl4nE0P3S9gY84U851FH5ZAoACZPv8G46gsjYwXTyTZLKVC5sl8JHK/LxJLJ7DCBpTDaw65PkB9eWOC/140EZGDBx42ceI8Fqi1jF03YTPublSykeDUMFJ+1v3YsJEvUi/NhbThsRQszYFuspQ6ssi08aeyQWp2BHUxNskY76jFqo+cJdNGRKR8kXm06wrjdq/VwzWcoG13L/POqYUysmDfmMQOi3NzTEEa1upQEksMluf4bsNHKfdoP1ZaxCXm7FhHRnCwyDpIOVNb6C9bf4d5Pfop7mvHd3Ev2tpBncRsY8zOuJhP5/rpB+lRbFI7HqBdCxbYmPRCLeMgpxi7aiyWdtnzNGU+uxsLS0RkqZe6jjhIpuDgOL8dv8ocOtXE/dTnoS9PZHH/db1Nm4XFsoTBs9ORPdtJFvNHBj2UOx7LbGaceeTKEBa+HJF3RBUeRVEURVFCHn3gURRFURQl5LmtpbVcgFy0chZZbDgV+fLQEhLUkgcZdLgUKTKQjaURfYrvzs5iV6QlIUXWHXPIzNXIz9YwZYjIRDafWiWToc6DtNZ7FUlQRKTsEBsTjT+OlD/W6THxQDzSd24i19AVQTkKvsJ5Y/NZkd/wPJLw8iRy8qdikPXaprGoAgts7hXneLFM7DakvGCS3M2mdI3TvGMqNgF7Z3gIeTwiimw5awrLKC3e0W2qqMfcG3eZOKcEKbd1kt/NCifrLDKPz6Ni2aAqep7zh5EEJREPODwwEVmOwoK4/y2yIaYz2NQrOYt2G3VsYhaXznXGZ3INBbeQl9fOkFF25feQf+POYRtNbkeaTZ7CJmyIQdZ9oh2bReT3JRhEzWGzBGrJzojqQY6ezWDcDe3nWrbb2JZvXak3ccFlMkeW7kdyf6CPjKBoD/XW3kf8o4wvm/j+18+YeCHaa+LjyUj61Vuwf0VEFlqQ4FcO0C8G5xzZP24k6/YZ5qbANTpJfIXDGq3i/UljXmTwkTZsn7Ia5ouFFo7PT6OvtAtjZTyDuenTEjyu5dKPFprINMtx068vrtC2R3y0vzyAVeD+j445qxQ70fMjD+fx0569e/ibtziFsTLSjh00XMF3I7OxPgov0Z6jlYwhEZHzV7HQyiuYz24UYrO6U1m68Ox5+kOmi/6T62PJRHwibb54kWubKqHNM5ZZVpHUxVzjXmowcVc+1xM96tggNUh4xslk8+YyZ209wXU963C5iy7Qrwt3cH+c699q4thp2jUjnfvsWhH9eu1Vxs0rFmVIGWU+XfZz/nCH5f1WJfNVdCb1KSLSs+Z4X5UjUTJ3H/Pv/DRjau9e+nIL3UhiLe7xUbX8htvmPYpFL2DhthZxz7m5wnw0KNh7+w8wTqdep2++G6rwKIqiKIoS8ugDj6IoiqIoIc9tLa2oKCSlZTfy2pccNtZlh3UTyGSToZhuLJoEG/nxooWNtT8eeXjyCpbGZBkSffSbnHMmAol+3I+8mzSHrTTikFIj6pDpREQCfmTztTlWmBcu8xvFE2SgxWeQ5TXcxu9NubBMxgf5jaQVbJzOPDKcRlY4pmM/9tajL5Bd83Yt9fXxRKRPke0SLJLmkJ3j99Em19awJooHqb/wzCMmXllF/szIQCoe6iajKrcC2bFzGC1z2kff8dxPllrNC/tM3F2FHBsnSPQxydiQA+1sgCciUhxAEp/YyjX0pJDBE32VzIXIe8k2SLzFm3OGJihTfnmhiV8rob990o/0fbmEussccbR/PpZI6otYY+d3kYG0OW/w56fRkfnmcmwEeiSJcTTqYlzkXeO9Sn66u8SmUT891YyJdJvras3Gupi7Sj+tjcUC+cIcWvcFx7wxmovdvLWb8dcZ2Gwl9I/QN3OKsVwGsxhTdzvGbGAGq8tdReZI+jYk+7Y2xlfMGm2z7MjMkljHe9cexz6qmaYPFV1gLKdfIvtIHpegMX7D8f6hAPOrOLJTqo4yBu1B2q37ecbItkfoCztPML3/4EEyk6KWqd/dl5hfOiKwLqK38M6w6REutCSKMswWOd7D1oydKyKyN8uxsWk8/aEikXYYvUxf3T+LRWcXYnc0OFyKgViWNOwdxIZ/co4++dfLjLVH246beOq+XzNxzABZgJXW5mUPwSAlmXvIxCB96h+uY4JuHWSOj4uhf/VGk/WZlcLcemmETT7jO8g8zYjm/ptk81v3CnNj+4RjCUY897HFYcZT6SSfX/Zv3ngwr5n5uyiV+1f+Reb4Dj/9IiHHY2I7hXEaOc88shagr91KZZlH6vx/N/HuVd499tZAoYmn4tg4szuN82+zne/O/Iq8E6rwKIqiKIoS8ugDj6IoiqIoIc/ts7QOfMbEWReRi14dd0jc23hm2tOIbD6ecreJWzLIXiqwsau6llm1HbYHmXW6HR2zezcyePQCx0SMI8HtqOeYriKk+JKrDmlYRBb3s7q92GGJ9ccjnXWkcD0Tw2QFbKvhXM1XyF6qX0RCv+l4B1B2LHL6gf6XTBx3AVtlsQJZOumtHhPPRpPtJCix75nlbUjF4X5sucx55PSOZrLUEpu/Z+ItX0FyjnoZuyaQThuu3UTi3OVIrpkIw65IDrBZWXjJMyau3/PrJl74B/pRwOs1cZK9OXstphh5NSea9iyNfcTE/i1Ixw9f4BrOhCHx1/tp5+m7kI53BciMaL9Juy2sIRe74+mrb5+iLmLrOT5noEeCTXw2dkLxmsM+7Xe8MyiXcp4ooo0PDyFZH5kjg+z7buyNoXE2Nlz18FvplU+ZePkSlpZ/lb6cGOsxceQ5ZPPUHIeltUYfEhGJTqQ/TqWQebKnE3uzI8B05XoUC7ThZfpXxTQdb24FmzMsjPbIfoJMkKHXyBBJdGONnWzEPr33MGPimfNs+He/BI+jjg1MT7ZSr3FhjszEOvpavPM9gX2052wM2U5/U48d+GAv2U5NWVgcLWu0T64X62JYaPPoKKynxQTOM5BKe2RFbl4+MJxMmyxeZNytRVCXI5dpq+UYbMbYEoc9EvsFE6fOcQ86FbnHxJcdls3RPO4vDY8yr6efZYx0D3LNUzVcZ7BYmeE+1RVOP7rjIPeB8GKPiTuuUD/7fkTGYW4W2YExa7Rr+BB12B/NRpARo2Rivl2KjbgygeW3No3tleSjnIt3Mtfd+dLm99zdCqM94mOZX/oSGaf527BSb41gE1c1ODbtTMOKSkyl7Vu7sLesZSzj3mLmhPhk7i3bHe9pm/0v3NPm9v1s/UYVHkVRFEVRQh594FEURVEUJeS5raV1uoGN8YrDkDUT5pAT03qRxfy9yGgFrY6NxLKRtVLvQ2YfnEYSczUj6fpKeP37gWEk5ytTSJFpuaSanBzxmHhXsiM7Jm+zXLn7ZqGJA7FIeNMTrNqPcrzTqbyHDZSu55JRVFbIc2KM15EJ4tgEKvwkkvsPqpHT63Op8rgx3olS+mtIsbbDMgwm8z1Ybh11SJMzbby/pYTXTclWH++fec6LDZBch4R8p9/xHqdWMid6qz5u4ofm2LSvp5t6j1jwmLiljyyPgnLqqyiD9uh9m/OLiETjokhyIpZWc+ePTJywgv34RgTXGWthd9Rk04fbT5OdMxLG58cmsVZO5NEvwguoi8xk+mTy94j77maTzGAx7Sebbjaz0MRv2l4TV89iMxTFIg/3ZDoyk1o+auIdFWRU9TVxXTkZ9MeZXMe7dFzYBKtNZMek+Mjw8a1iYY77Kc/iCL8lIlIyy/xyap75wlfDmC8ZY4wsj9AG1dnU9eBZ2jWtCuk//BydZabOMdZctPGMB2szLPtZEzee4/z3l7HZWjBZmqGf70tljFxxbKpXnurIpCmhvrfGe03s+x7Wx6EdSP8N4a+aeGEF22D7dtpwPMyx8eAi82jxKLbMeLcjQzG8x8RrNdi5IiK9OYy1HdVsaHnBR5li67FORrLJ3nrsEtb1eNIFE19NcLwzbMZjYl8SZboZRWbTjucOmTguleO9+5mnq15mXgsWfQmUJ2vk6yZeCnzRxN2XuLdWZHE/uTyFZdibd5LvxjBmEyLIvuxZo28uPsC8eeAK84PPUSfZPvpNx6LXxIHvYIv25m/eRDK3lrGztsTY2REoNPEbz57mmEe5f+eFk0E4O0WfmE3hflrjbzDxeCzvZhy2e0ycUk6/cSUyH8XuxvJdWOG9cO+GKjyKoiiKooQ8+sCjKIqiKErIc1tLa7+F3JnoyJDqvANJUNawRgqSWG19KYGMAruRFdb5x5FHY/xIU1ceQEIvnmcjuNcaOU+x7TGx/y7KkDmKffbWZWyse3IaNl1PVAHWyuINNskrqDhq4ukpNnWKKEfuLPQgHUa0kHU2kMX1H32Z95eMO+T03WlIedcGkOaWO3mPj7+PVe6Xt5IJ8mtynwSL2DRsjcgw7IXcPVxP22uO9CrHO5qsW8SeBOyIeMGK8MaQFTLb9w0Tu/OwAVJ81G9fJNJn5XVHFlQENkZkDF00KcqxYZyI7InHfzsTgRVVEumhfAVsVjbR/n0TR+XTbicHsEfW0rDx7EayE2aS6QueJYekfI1Ms95u7L2COMf7fXo3b8oWDJIdWTq+GOTr4hz6S9JNpOnhQ5R/bZDMQnFkPCSs0mdbDjNmV0+S5RFHE8uwi0xMa9mxSekMG1P63di2Wzto15YyxoSISIpjY8uCAOMiL9axsVoi2Xs32/mN2ruwEC5X8hsz1xnv+8uxc2OW6Gs1y9gkExMOj9Rh47X2fsrEvgnmxGByaxrbMy+T6/e2YLc/n8q4y3zWa+LTyVi9lXuxA8fDmDtTtzLvxs1hV/WEM36vLPL37z1dnOdakaM9IjkmEO94/1LS5g1Sq05Qf41eMoOS3VhXeWWMzbYAG4EOZ7Kp5qVcjt9PM8t4ITZNbQ2W2UA7bTV4F/0l7mXm1+V0ynPJsammIzf2PRE1xn3g7QB9aseK18SPFmAfvoIDLKPbGBdht7BrIkvpp43XKHP8R+gTScMMzvYLWGAF6Xx+IoK6WhDm5Tt3Mb9XzzjGgYgMeJkXZjuwLs/u47yJWcw7FQOOcTrEfba/hHlkOo6lKsccGyaGuR3zSBTWa5jPsenoMPf+MBflGUikT8i73DdV4VEURVEUJeTRBx5FURRFUUKe21paA6ms3LYd2TW5+cj1ywEk3q5FJP2si0jUqwXIoxN+NkDrr0COqhnAxvHmsLo+I4LV3xOC1Lb4IhkVaY4NkHIy/9rE50qf2HQ9cRfqTZyY9LSJ14RN1qKjkFlXC5FswxvZ5M4dhb23NIhU+mw51sW+ecp3mf2WJJCN/RCTROaPuwQLYecl7Bb5kgSN+DU2Xhyced7Ea2+zQdedW5CTOzKRymMWkE4jx2nnoRg2ZPRuccixiWyalTSH1NixhnCc08H5lxKQgROTkOI7He+9iYxH+hQRedWDFly2Um/ihRUyVUZfQQfvPIB1WVyMxTM1ymZf2ydph4lRshH76sk2iHuO7JLqz5GFlB1B5kWuB/vwJZ/HxA9LcEiJ4F1Fa6tk4KwNsDnbyXJHllYHfS2ikL5po6zL65cZs0e7kcSLCrArGq2rJq4sR5a+6nC5i6eQpcdSPkLZ8hpMfKDBs+l6FvZjT/py6Rd9o9gvl6K55pR22qDi4gP8XgQWY7GbjdgWS2i/mjUsyckJrLE4R0bQRCRyf04+ts+JcKyFz0vw8C1h47ctMKfcUcOYvXyKObg8DKtnfhLrY81hFS6Ps0xgeIJ63JrCOZte4druZd9BuVSKBbjLYTfG1/JbJ5uJPeHUu4jI/iP1Jk76sWMzyAKsu4Uh2rkkjPZcXKJM5eeZj1LuoYAtFxm/yzGcs6aHMgy7PCb2JTOPXJt7zMS7U7A9g0VTAm1Zl8I8WBJB+50cZhnGYhX3x93zLC+IiMPOTb+Ddr3SxIbAA/O/b+KaAeboG8ews1N+zG3+U4e5p7dO0a4DF7mPu3dszrgbOo3dVXqYTMGhBubjwgOM+ZvjjgxMxzi68zx9tvVRyjGwheusO895Wj5LRvfVDvrvti7sT5fPkUHa5Fjy8C4TrSo8iqIoiqKEPPrAoyiKoihKyKMPPIqiKIqihDy3XcOTPoOX3JPC2paSc6QATxzA6x/twW998CBrMqbC8eVGm3j5YKAQn7jB8ehVOkF6+/0P4r3++BZv0lwYZzfd+mTWbDRM4Zlm9G5OIR0tIr3uRgupqfcss2YmYZb1ScNzrHUICDvMpt/iPNd/k1S7/B+Tuj5QzzHVO/l8/C3WAGQksMbCimXtyOl4PNNg4g7HB50bZ0fLmlJ82Te8tElKLz5zzAC+un8H3n3mq+xkXPRJ6q69nzVZ847dPcd9rGEKf8Dx8tTvka4+lU1naD5J25Rn4+mKiJQtU08v5eKDH11ibc+wY1fsukt41hFtB0zcU8cxV5+lr9btc7wMd4E+uVjgeInliGPxyiXa8M17jpi42LEzc7AYS8K7nkomlb5gjrUNRY6Nxu+7gU/+wk3WGFhrXMsXt7K+7pkAfviEkH66OMnLVd3Pvm3iGseLJBMTmDd8M6TBtpbRP8Zt+pmISMoUqc8DYfSL4uU/MvH+sP/DxNesR008GMv6nBkX63Zsx9YYtbmsaZhx0387KmhvzwpzVmoy/XS5p8fE9W9yDfKkBI2qdkeK7zhrHVqWWfcRcLzssTeOPhWbVm/isTjWy6Svsh6kMZl2u75AXeR8kjHR9Rp9OZYNf2VqhblyyZH6LFnMiYVXmddERFZiWD80+wle4Dv5PPPi0jTnWnK8F/jwFO1wbS/3i+c6mS/3VjDvShe/fSrAOqz43kdMvOaif24L43enPJtTsINBehi7CJfM0pZXx6n3ayusLbyvhHa9Ns7nYY5jPn6ZdWcRftbO/WEj7f3sQebAT7WzPuqpu5i7oxwv461e7jGxP5G2LJp0rCEVkbnd3PtzB5nj6sNZ69PqSD8vOEc6ecsfU9fdDbRNdAfz7z4P4/dmGPclaeYef7iP9Xv9jjbLzKB+R8epo3dDFR5FURRFUUIefeBRFEVRFCXkua2lJY6Xi1W5SV1+LQ3rapePlOPuu7GTvn+OZ6ljQ45dkROOmPhWNGncKbPI8r5VXiTacYodE20bie9YGrLZM5OkuI2UIGtlvEy6roiItRMp+xNRyPffDPeYuNJDSt3+AFLuos3vBXZjv9SMk6Y7X0IKXv8IUmPkD5Eaw9zIu5YLy6h7ldjdy66oQWUCqXhnLpJ9vyMNNnYACXLC0TuKS7HlpPFBE15+jG0DhnpeNvHyK0iQaUXIpVXR2Cl+i5Tg5WPsyOv3IVNmPog0Htm82eq7NkhbFWYj/bct0Je2Zr1o4hFHenHkTdJRjzVhy1p5pNwfnyLFO38QqyjFT/+/sIoWH16HbRTRRr0sH/RIsGmbx1Ze7KfN4tL5PPsM9XhuFtk4zWE3D93kmNOC5ZmUQqpv2CLpwL4xtnAYcbycUtzI9ZVtDsm5jnEzE8X5IxIYiyIid/uQx5/OZ5z7vD8w8cE5PLrpHHZebQ8nZXcpC2sspx/53XWN/PtnV+krW/fS97N9tOv1FfpETS5bLxR9jv4RTNaSSf2/tpW28gl2hzuVOWX4beadsgO0Q+45bJ/xWNokebnBxHWTbM9wMYw2WYktNHHVJC9inIrEIg5YvGy2/C229pg/iFUiIjIRQ91Hn8W+eLiQ7Rq+uY35srwRq6u9n7nASviYiWsGWWIwnIINH5HOvSk7BStnMoq5xj3HMbNXHFsrfAK7PVgspzFPnbMpc24e94Enr1MPy63EdxXTZn0l9M0uH/FAGeP3BQvL2HUcy6i7GMt4d/RhEycUf8PEMQWUs6/BsWNz2ebHguJ55umz0Yzb1CTug5VL95o47gvM2ZXP0h7DBczLAyvMp2/cdLwU+BAWZv5F2mZiD2Niewz15W+jD1UvcL9+N1ThURRFURQl5NEHHkVRFEVRQp7bWlpTq8iGS4M9Jo7/TWRwuUUmxI4Br4kno5DyorcjPzdPIHfFDJLx0NOO1ZOZjnQ979ildsRhK6WXcp6UF5BA74si6+JiCtKtiEh/BOc6N0O5S868QjyKtH7lN8jSKbnId+1RypGQgV03m0V9HbZJc1i7OmjityORF+uErKMsF3V09g/enyytsC3YHbMXsRNnkpFaEwuxI/KvUL5LyVxzzSrZb2FdrOAPi0VOd/06kmXm4ndMHHOSHXVffostqHcEsCIHi7wmXr2EpB+VSpuLiBTn8Rvtgkyd5ifz5O0f0DcyHe83TNpKHfubsevemv2WiUtHPSbuSWfXZX8OGTKzL7NDbHIyfWdnJnJsVS9ZhMEixbFFclQJsrG3Fek+ymLH8msOC+DOgR4TbztGnZ45z/GJV7A8z9a9buKqROptoZ1+k+/IKElzkbFhjyB7++OwajMtzi8i8qqbF5pmPVXPbxSSLfZfS7nmvFgsyb5o5pqyfvpg/Thy93eXuM47Kjh+oZO5piviGybe2YUl25jId5vnsMwwd947b+1i3ioYx44on2WH9w6H+5KZhq0c5kxGLWc5wFwa86trDSuuL5odct3DLEMo2MJ1drXxu9XxzGUDWf9o4vmjPSa+b5LyiIj0u8kQG8/EcvurceyY7Z1kWs0Xcf2yym97G5lf3Nn0q3sdmZ8/WHRYjja7SGfGY/G4erExF0rpk92XHTbIFyQoJPUxHvf2P2Ji/73USfIO+mDbdeb+qQbso9hULPix+8jKzL/wNRN7oz9nYjvXkbk3wz26a5L7292RjI+L32b+7E3BFt7r6OMiIg1DzKcZB8mIW1llWciLo2RUFU7QNoUx2MRVSw5LspprrsmkbVoquP5eH/PmQ23cZ19KxcJ/fJr26xp8zlHq35N3QhUeRVEURVFCHn3gURRFURQl5LmtpWWPIIvNHuXZKH0Z6dsjjlXYU8hiySnIj7cWsE9mvcjaeyORoCJKHS/ra8AmaKpC7iqb4nM5hSSWl8b5e24hd50pxMIREbnzAtJcQRi/58lGpm/diozY28e50krIIuhJQY6/dytWTNRFjm+PQx5Oq0KWLZvFxvHFUP0tbcj1R0dZkS44QO+ZBBvbIMORFSYLXENgBen7qofyZY0gMzfFsIlZ3wybVB30Yuksjxw38UQjMuVEPXW3O5b2LEJ9lkAvWV03H0DK3HsGa1BEZDKRPlDo2PgqyrFJZscfI9+XP0X7NLxEn+ktxjbrd7zIrrsM2+SJK8i8F6p6TJz2WcaFN4tx4brksFweYXPGYOXfLV+jb9fm0mZdGWTHBPxkmR3yUFf9vdhPU16srsQI+virkYUm3lNMHRY3cwXJE1gDYzPUm8tNZlz3NN9NCZBRcnoQa0NEZFskdXTI8RLe5xxtGdaNJ5m2xhi5q5R+6o1Csr+USafKIslFFhaQ3NdWuOaVdr67loyt5Kg68W1xnCiI1E6SjXZ2gheu+tIpa47FnDK5FRtHFrAWp9z1Jo5zzMc1PubRy1uwreNTuf70H2APTC/x3f5DJ00cs8RvRWQy3i9e33wrKXHTVuE+7KpDsyxdCNQxXiZm2Kj0cS9W3L+vZFxHNPP5WCLXc2il0MSdFssQEh1W2oSLsZ88yXkaJulrwaI4jQy/jhTucZaPDKzmVvp7RipliM7HZlrIZBlBRAP3pZxF7mNXHBl0ObNkNCfPUg/D+7Hs3Sdpp8xPct+rOU39/EPu5myn7fP0tcgq5vLJJiyqOzLYbPF8BfN6xCWWlTQmMO8krdB+p9vJCHw0mfH1fYsXXDfsYJ7du0JG4LfCvCYOL8CGfjdU4VEURVEUJeTRBx5FURRFUUKe21pac46Nj6pueU3cHWCzqskoNiLKS0KCGxjBoimKRe7Kn+X4wUKkrNRu7LMZQb4rX0COa3VkiBSy+Fs6y1kt3mxhz9wfiZwuIpK1TNZRUw5S+datZGqsdPN5YofHxHMOG+NeCznyfC+WzvI0x9xdgXV1ow3ptz4eSfjmTSTOoio2yTq/zPX/rgSPfMfGbVOxSOWRjneZSBw2hXcFiTAv3mPiQADb5GPpXOfp68ii4YnYXhOfxsba+wMk21s29eLdwvmtCw45/RTtEXDzuyIiA+ewcnbsx3foGWETreq/Ql4dc7wDK3ob5Vu8wuaZBa/TZxbz7zLxko3lUDBC+79F8oTUXWejy8bdvOupzCJTLFiMVyNr958jnq9kjBRnMgbtKT6/u4yNBP+xnX6wO50Nve4uIR700h6DPvrHULgjGyOdcTA8Rb9JSUT27u+jzuti/nrT9ZQW95j47VjskAPXyApZLGow8XgY2TjjSUwGfhd1sXX5UyZ2eemnGSXYALccm6vWXK438dyTPzRx9PjnTZzwzT+n0Mc4/3tleZEsp0jHuLinCyt1NBXrNW0Qe+BVNxbER/O5tjfHmAvPlxaauPw17OzJKsbUWjIbG6YlO96d14E1NDbNWInppw1qPdS7iEjfKn0+e572vBLOcSkr9KWOAOP8hB/L4sAa839CGe38diz29vI0fS9zinK73sbWKSjFPvOlsCmoP6FQgs1EDJbhlgjs+QvhtFlRh9fE3hqOmet1vL+vlTqp7qZtDhXSV5ZXeZ+d7OP4rknGbP41+tPYBPNh/3l+15NCPVfU8VsiIsVd1PWlC476TaAfnbD5/DBdUEbu5d7iiXZsBBrNvSI+leUSfz9PlmlqFH0ldZw27nRjGd7Zhm3dHlsvPwtVeBRFURRFCXn0gUdRFEVRlJDntpZWXBsy0sJO5PG0BuTxsAewsZLXkDEj7yD7Y36S46fSybrJRq2WH0d6TFx2is9XspDEfc1ItKOF50yc6kaaq7lGRkAgHWtDROS7u7A9ti6xqdFME/JaSRHZNZGODaFio0iXOu7tMfGBW2yeFRZFHS28TdUWbsPGGh9DpovehSSYNsB15kUjTQaTsXpH1lUSbXLSYcuNxyOFLt6BVN44y/WXzmN3vNzG51Hx1LfPj0yZPcGK/MkjZOckdyJN5sSzadYPa8kc2REgW+aNKs+m67nTT2ZHv5/3qWWGk4Xxwn4+d0/Q5qmX6CfDSZx3rRYb11VI9kTbzAMmXlgk+ykykk3ZereRwfBgKnU0u+jo6EEicZa2KXVsGDfbgW3b4kgo2uLIJjx5iz54qRKZPbmB/huxA1l+qhspek/qERN3HaQeul5E0o7Npc4TY70m9g/yHi5vDPUmIjITT3u457i2uV2800vCHZJ4FxlfR3KxQHodNqddi9wf58ZKDWu7m9h90cRpx7iGUy8yZpMHnqEMd2wud7CYXMRKjd6O7W8NkY3XOslmqVER2ExlYY7sxW7G1JbtLD0YPIetfNWRiXp4iTlhyc98t9JKdlR2Ot/d49hULjUTe+t6+ObN6iLaOO78Cr+XsJuMnxEvm3l+YZ627a2hLyQwFciZWvpw3HeZa3IeYP53hWHZ2HHMza3f4Roqchy2TBkWSrBYbafQ51Oph/FWfrc2BS/cdZPx61riXhQ7yxgceYR6+94C99ys5580cZ5jY11xY8leWMHS2nU3/bevm01WR9NZdrL7+Obs5he7qeuv3Muc29WOdZ3leMfexQr6ZvnLjn5RRR/vC9DvCmZ4x9aeAvq+P4NNeq89R584ms01dK44MsL8zF/vhio8iqIoiqKEPPrAoyiKoihKyHNbS2syGxlwspcNx7ZFODaMO4lu3liEnNrYyjtwypuR8rp3kpkU38nK8JocNjAc243Et+xjxXjhXqyepSUyjlbDkOCitpIJ0lOGvC8iUhntyOrpxa6ITKQapt7k92KTsHqsSKS5zzheytTt6zFxzDCS3exR5NeeCay+igdOmtj/CqvtL65x/Skr1GMwyW31mPhf5/Osm9hAZkDdZcc7bQrYnDF+nqX3iclk1x2M4B1WnckcnxzBO3oWXqPNpRprYbIc79Lfy6ZZW8pOmrhjir6QGr+5Xhq2U9+5P8A2Ov0V2ioVh1Jcs5xrLQWbLW4VOf3GMnbMRx0JEFMPUEeDPQ57r4Tsn7ku5Ogr1ViGlZGb3+kWDCI7yUw84+Pacw56TJzRwHX5+hgjq2VssLe/BestfAT5PTcMy6ggG6n4qRzeB1QsDSY+XIvl92ozVlfLCjbMQ32034WkzX9rJdxAHh+Pp53Gh7i26TSsq4V47GB3EzL4wp38Rst1Mj+3Z2MPXLBpy+xx5oS0W2QBFWdjOdh7vSZOdbz/L5gsZNCXD59mbmtJYPO1Q9XYjyfGmJvD4u43cVIk89qNS5wzpxiLKvGSx8Txe2iHpBzqd3HZa+KhFayxoZ3YG0fmj5k4EONIVxQRy8UYzHZsOBd16SETz2XxjqezbzNHlN5JOYbPMQcnxVHumCjKNHWCTKCSCOy9QYt7U+RONjycHD9i4toh5t1gUbxKfxyJwqov3XnexDmOjRkbxxz29yzjJcWxaedcOmO59iXuJ4MPs5nsWw3cH+eKGbN1jvvpyknmq9R0rMDYAPPydJljU1oRyUg7aOITf8cYyfxtjns2jOs5WsfvPd1/j4mPRHP9rtV6E4dV05f7hrHbYx1jLaecc05knTBx+jx1sTrmWAsjT8o7oQqPoiiKoighjz7wKIqiKIoS8tze0orB3qlexcZq8SNrXVxiM6wHJ8nMmctmc7PsWuSyiUSkzsuLhSYuufyyifdb2GcDOUjU0/1kZmUuIKFeqEMmzfYggxVecbxvRkR6y/E3ot0O2XiGa6vsR1rv+igSYfow12zXIiP2j2Pp7IgmKyC5CQkybAmbaOIqUmNkMnJc0jJWXEFPg7wfTOVyPU8MkY3VXYu0aa1gV/mWqb+0VVbSn5gjo6w6jXOOX6Eel1yc33JkKnT0ITOX95HVNP7YWRPbp1idX+7inJcCjhduiciDS1hozfXYptG3kIjHF5CI6x2viJmZwe5YLmHV/75wJPupLWTwJL9Ovxiqov27HJt67a6hj8zG8mPu+M3vpgkG0WG0zfxObJ8dPfS11hIyUDInkP39Cdgb9V6OGXUxPpaLyFIavMJ17ZunfmK3Yo31RvG3U/EidRJdTb21Rp80sS3MDyIivjHGwnYX55rPYF646wrnvfEv+W33S0j/1vkbJn40jWyRS+3MI9uLOOdwCv3gmVr6464G7PDri2ywNxNB3QWTrMkeE19KJQtnpRfrMiuWMqVOfIIv76ef3pwnQ6g64DHx6gz2w2AxNl7EEJmLr8+xEeCD4XzX53hHUeckSxWaopn746axcEVEFrbRJ+OH+O2UFTZYjbzBxo3Tu8kqGhpgDo+to0zJPfSR4kSviftS6MPLXbyHbGr6RyYO7Dli4tICzp/7MnNIsJiNKTRxyiz2S9h8vYlP9WOxplYy/2Yl0R+XHJmLq6Oc8+ansM49Vx3vQtvKmGqc4V754DDzoW+Fcd1dwDy29yRZWl3VzO8iIhk3uMeVxPFMEB9LBu1oQo+Jc2fov/c9ipUY1kmfiE0gw89dypwS5sbaHOrB3qqcZhyMCs8QV2Yo66EerufdUIVHURRFUZSQRx94FEVRFEUJeW5raW2J9pp49BqrzTPTsW5yY8m0akhEcl7x8l1fMjZOwizZPgupSM6t9iMmDlvGDhlNZMX7tnmsruVx5K6SHyBl1Zcg8d1wSMMiInWjyHl9sfxG9Hkk3vEjyIWlC0jIMYeQ2t7q5zkxIZl3tIwN8XuXo8lyyZtFjqtfJYuiOYDUmJ/EKvSo+ZvyfrDoRYJ+KAsL6Udd2AN91//RxBnb2Ihsfhm5tGKGTJ3eCuyqUuF6wgqor9EUzpPZh5R5NUC2zIG2QhPP5SKztw7w3YcX2ahMRORGJJLvPJcm2eOU1c5BUr7m5vPUk1hgmV4yPto+y3nKbiDZvrKVH6jtou+UOjLzIosc775p4n1bq+NeTopb955ItRiPCUOU81Y042JyBbn3bBFjs+Qlhv1QAVkwYRH0u/QANoQVg+QeWUQbn+jh/Mnl2A0ZeXeaeO4WWSHJPYyzrHjHZnkiMn6QsWnNYK3Fl5O9tzBLNkfLOWyJGPYylaiSQhMPOja8K4pgXPdMY6tOC+0a9lKPiS+WMyZiV2nXG9HBz+oREQlkc96JUWzYdB/9v3GG+uvzUK9Jfq4zMMb8F1/Kd2evcp2V+WTsRfv53fRYNgWdOkz/mjvFOQ9H0d9HtrIJXdQY9Ssi0nuLPpYRTdZVght7MCUTG6tjhn7bcsgxNlv4bpLPY+LXH3BswvgUtnfMVsayp4/7RYWLc670N/C7uWyQG6zBOfMW9nHrQe4J21Lo87mx1NdaO0s+hjKx5wbzmR8rxlmC8foa94r9z3FviXoE6/nxUubfUxNHTLw9hz60p5T7b/g0FvnKAucXEUn7PGN7xENZ+0fJviso5zp7hplrKk7S7xYrGL8jZZQv0ELWa2IOmVZRjdjTLcW033TLvSauDqOum+/52Ru8qsKjKIqiKErIow88iqIoiqKEPLe1tCaWkMiya5CQwx3KUfo08lfvtRjH8UjiWxuOm/g7d3pMnHmS1dbxJUja7jEkyi3tyOb9Hla2LyXyrBZ1jMyiqVGsmsjJbZuupyMVe+wTQ6w2v1GCxDvbhHw9nEmmVfxN5E5vl2PVekKhiZscmTPliUh8Vjj2VlPhEX5rjN/1/Teu2fskkmAwGUtBHj4xiIwYfZ12WDiK/Tg2xPWXRvdQvjTk2IrYr5k4EP15E/v3YQemnEA2X62jPT0/dlhU0dhTgxXUb7TFu5ROn2KjMhGR8kNIrfP9lGmqGJsx8g02QPTmktk38giZAQOXsGUPv4jUenG+h7LudWRg5bHh2vVe+nmBo8+Pl9OPSjqx/YLFuQzKXx+NTbggjNM0L2Nh1zxS9nw58vj1/pMmTul0vKPGpg8+sES/PjnPtTwYzvU2OazKlUlsgrU+NteM/YjXxEvjZPuIiITZfH/ARyZU1gWslUv5SPDpE1hrsWWcN6aV48NHqIvoWqT/1TGuIb4QqTxnG2026HA6wlOwdEomN7+fL1hMz2AVlFRgmaalUpB4x7uLfLNMwunzXHNLjpeT+rGGw8MOmLgzjHM25zM+KhybqzY9x/zlrmAT1apcLOL5cTI37RvMcSIiBS6WPTQfYq52naHd62Jp59U47h1ZXQ4LcYV5Kjwdi8fzI86fmEBcmtFjYl8U1798g/ZvnWIeSI8nOzZY+A5T/rR+Mpejkj9t4t5V+ntVNRZrOMlVklfIhpKF09hH2Q77z+uw/yqTuL/Zgj2ZNc/x/ihsyLkbzLk3RxxLKrZh54qIjL6KLZV0kN9btsgoS/HSfxvHyNgbPeawpSK5x981RHuPJL1k4uOOe05MPffoXb3MTcVbqbtmx/KauJeeotCf+g/yTqjCoyiKoihKyKMPPIqiKIqihDy3tbS2DiMDjg0if7lq+PwpF7LhnVVIsT6f18TfLEAGS+1Glp3axXcRx0Rimsg6Ob8V2+LJZqS/02msxq8dIbukIY53IW1P7dl0PdHdlOnNBMeGhi3EmXe+aeLVWc617H/dxJ69PCdeXcZmuTOCzJz4/8IVPX03tkxdHtJvWjZSY9oTZMK8amOfBJNFHxliS7VkOYzEIHO6h5BF06uRRb85Sft/arDQxHFv0YWurGKZHeh1bBLnYWO02CtYWmtJPSa+nEC2kDMzZa75tIkT7nRstiYib/mxvrZvvdvEC83/zcR2Nlk+FVVc55lIsiGO5tEP0xwyeKkj9WveS5nSb9Dfio9Rj+0jWGO7FzjPqSepU5E8CQYPrCCbtzVRp533YzM91kl/HOolk7Ejg35wdw32TqdNFoUrCZvkeDgb8u0ZISXqxCLjYLwESzHjHG1/bzxtdLIXWX53FxaLiMhAAeN8LR3bYzIGeXxmkeytDBf1mNpOvYdlYRNPJDKmOkfJkBmv4zz7TpF11B3N/HWmBDm97gJtmZ/GOYNJRhyZbc0v0bbno5DstxUxjorqmV8ax7mGPcnMWf4+xmZPLHHfPLbtPY7LcQ3xzrfq3L818cv2H3NMN2M8NumkiaMjN28k2f4xbIeaAWzNsCWs+x96sTUykliu0DKFHb59lXhqJ2Mt9y3aeeow78V77YrDDg3n/KsJ9KOIBSzdzkHKGSzihU38Blep4IiWFyhbB1ZXRgFtNhRPG0T0YklfT+Ja0srITKo5xfzmw/GVzhnG+6OL1GHTDH18fis2d8JKoYn39mNDiYg0llJ315e4Vy7lsvwhcazBxGvRjPOVdN6xlea4t5TFMf+mzDCflkUw7oZvMP+OjWGZJdZibcogFqu/Env23VCFR1EURVGUkEcfeBRFURRFCXlua2mNu5GpI+9h5fbFXuTU3ZFI/e5eZCd7G1Js1oDHxMMupOWcWL572JEd9VIixxSNI2udmEYOXTjAO1Dmu7G6EuZ439JbCZs3N6vyIBsvxmOVxCyyQVVsGOcdbiIjo7yMTKO0KLKALjVRpq4Cjik4igRZXsd5hq9Tp8PLyHcjU1hdRenUSzAp9SIDD8x4TTw2xgr9R6ueMPG/u8D13N3syNjaRZvM7cFO8HhPmvi6n6y2nngskfSZBhMXDtD9Zv1k1HgWsRC8H2Flf3qj0xoS8aZijz596j+Z+BN5/PZcIu/iiQ3wG1/oxAY6nsu1uX1YJdVzyN3/Xyn23hcrkXVfeRWrb+8+junNQQZePOvYyCtIjkh3Gde+K4esk4korIHMbGTtwTQsw7Jx+uzVaWTtxVjG+Ew39l9CL5b0he20t3uQY468/jDnqaFOGkfI8JkcZd5oSuO7IiIz6Yz/CC+flwwjm9spjo0Rix0ZeiuUe3ABK66oFmss/jlsn52J9Kl5x8amfZE9Jr7/ZcbgjUK8gkUf74IS+W0JFmfGyWTd0c81b/l9LCTr6sdMfHn4vIkLx2lDfxsZZZbFXHMsGity3GFJb8nBfjiz+E0Tr1V/xsR3d2Kh5PRgKz1XxVz5Udn8Lq3Yb2DrnFplro30YKfl3mIwZM8x7pJTabcJh5U8/wZjNuFz/F7OIvNRbCt93rsT62rnNP2/yyLDL203tm+wcLvJOspNP2LiKzZ9LfDoPSYe7HDcE930394t3E+LX6Dem+IYawtxzNF9jdxnPJHYfG/GkHFXHMtyiaRexoTP4vheD78lIhLhZn7ccY7MsbHEkybeGUY7nY5nvlgax7pbyeCZYKSdzWuv7mD85v8tfWLlTvqKp4OxH+hnicg9U9xDbyZtfgfYO6EKj6IoiqIoIY8+8CiKoiiKEvLc1tKa8ZJFFPU8K8w9hz9l4gU/8tLy4osmDlxDLssoR2bP8iO/dt9AKvt6DL/1sIVcbe9gk6zZaH5r4Az2xJUysi4enuKYuCWkYRGRnklku6VqsgpWp5A74xMpa/kjVM/LA9gV1VOsEr+rg3J0RZC9tuBnZfx4O9kV+UPIwB25XPPdFtc5P3BQ3g9OlGEv7G9G1h0oQ/r983PYOP+qGRn8a39Km7RcRjqcnsOu2ivUy/dSyM55fAlL59zDbCSW9G3eqzaUxPmnD9FHov4KyXL6ATLzRERi+mirh9Ox4lKLyABYHnNkvOXT/h3TyP13RnH9U+n0yeE52vMxDxu9DVzi+ssrHRvRFXENEe2U7W4fUm6wsEd5l1LPEmVwz9Ifz5fS/webkdk9EfTlzLlCE8+XUO9lO6mr1Aak9XifYwPDNKRye5RxN9FBHXqKsSfrosig8aVt/lurYI3xEnUDiXuxmEyV0Sl+O64J26OrjIyv+GHk+Oh+LLSeHUjlQ91nTFxbRF1Mj3KdIzsp98EF6rp9fHOmYLD4UicW+MtH6EfFjVg3sTlYQ7V9zFk5dU+beGjscRNHTjoytgbI3ps/xrX1dmOzJEU+xHlexiZt244Vfv4e7JdHJ5hPWiexeUVEsh31t72HOg7kcm3JhZzruQXOdccc9uaswwYRj5fvTmNjXQ/QV8OqsR8LZpm/zwaYa+cTGRcTrdivX5HgkBrJkofWMu6JHouMyKKbbKSXmMjc7y/H2gz4v2jiacd7qBImOGf8EMs5iiuIXROMp4VRlmysJTveAxlFxlZrAn0l0rt5ng2b59+sPLKVd4Yxh373LOdNfoJxV97HfXZxkuUFXh/zlKsBG6+nnvaYXmN+2XG/18RX/Bzj83CP8q1uzhR8J1ThURRFURQl5NEHHkVRFEVRQp7bWlruQWQn7yFkuu2LvFtnYhVpcakAicwzxLPUuU7srapYpGh3DscX3EKKHKxGHg9rQ+pc3MZK/jBBdts2wG8dz3nGxBF+JFoRke0uJHWJPGnCm16kxvE15PiVk4Um/lg275k5voIs23WQrIi2Jcr3+Byy+aKLjdi8cWRdVGeeMvH0ItZQwTiSXTCpcLg7Y6uUO2Ur3eD+QbJwriZRX3uO0z6rW5C7fSv7Tdx2AYnzkznYWANryLGZ01h69iEydVbSC0286y3aYPxJr4m76+iPIiK1uXy/yEU/GexHKg+Lx+6ZSsfWiFrAfltKQRa1fuTYjKsWmX5ogrrIOUy7xY2RtTDTic0wnYzN6s9ic6xjEpz3aq2N0B4DGc+b2D1Sb+LVftpyx2GsxJkRJP2ZZmzFGD/ZOBNr9NMYhxTd20o9TOz0mrjAseHnfBmZku2DvG/JPU67bHeTXSIiIo3YJj2VtIGvB2skvWiXiZsT6IOp6dg1UYuOrKZ4Nlj0jpGN5F/B8rx6kfno0N30j/5+r4mnZsj6K9/b4Cj0JyVYNFeQ5VKdxHw57LArIyY8HF/JEoOuzi+ZuCoSS6+v0pHZkkwfT+7hd2/lkblavIJ15+mkrgs6mWtX/Wwk97KXNqgedm4dK9LswvYN3Md4jjqLRe0uwEKsvsF4aVyjvivuajDxldd4N+JCJPNXwTJ9si8Ve2twiPEoefSLtkGyfyrauZ5gEdHCeD86jHV1eTvz4NuDvDSrYBdjeSGZ9r6zi6UQ18KxHkcW6Xer9a+a2OWYc9zpbMSalY29NX2Td4e9mv4DE1eU0efC3mROFxHxlbLMYWqBeSTxFH2qvpjrSZ5hLo5JY3wNdvPuxAIPc2jiimOD407aRpLJuIuL5Zhd0Vh3bTb3gPKkzRsmvhOq8CiKoiiKEvLoA4+iKIqiKCHPbS2tyWRWT6eGI0W+snLMxDUFyNdzXciDk1uQOHcsI1dXNiJX33RI6J21yM/b+snSGIkg2+W7F7F6Ht+CRNnSjtzlzy808R3zmzfDWplms663z1KO5Fik/7gkr4nnm9g06c01x0aKMQ45Pu4xEyY4jm9M4r0eh1eRBMdvUNalVKTesRg2g7vuZlO5YBII8HvZLurv5bNkCawMkI00W0yb56xhUd1fh+W48sMGE7sLkZCXRpBvo/ycM30A66N2L7J5Yg+S7dA03dITgex9xyWHRC0ikW7k2ehF7NF4x0Z0rgBy94XrXzPxR1LINOxzvENp6VOOzS0F6dQ/iYQ+48j8Guzm88hd2CZ2MXWUNb95A8xgUNBDm03mY8VcKKNOchOwIs70cC3VEditrmNkB9nTjLX0v0Ue79tPm0Xvxs6VJv5emo35kYn9Xdh2MVFklNjx2Fvlb3JOEZG/LMeuiOpHyt5vYb/1Db9m4uQMPk+7iWTvKyKzY7gTizknho3O3Be5hos7yCCqWMMOWc2ib3pSqesL54m//GUJGgtdjiy3EuyFmjXmmp4V2urojyn3zTKWGERMM0/1pmIB55Wy2WLRJebR2FU2PL25wljJO4C1MHeZ9ztJMWPo8RmyG1v9nF9EJHmKdwxe+06hiaO2sAQi8TzZqCdmyMwqzuN+Md5GG5ZWOt6H1se4u3CTJQNHHqR9+gux92aGuc774plT5u/jniBynwSDqWTGY+Y+5tyMdvp4nGNzzuWbzD8tAY7JKscmmkvH5pvuxWI+cpZ6P1PInHtfKVmyA+fpT4G76OMFP+Tz/T3cuwcHTm66nmmLfhG+0mPiBMe9uWWKe9bwLTbnnH+UDMrdjdhvgyNsTGknY6XGepinsico67UJ5rXpODY2TMpn2YpfaNd3QxUeRVEURVFCHn3gURRFURQl5LFs2/7ZRymKoiiKonyIUYVHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXn0gUdRFEVRlJBHH3gURVEURQl59IFHURRFUZSQRx94FEVRFEUJefSBR1EURVGUkEcfeBRFURRFCXlC5oHHsqxvWJb1px90OZR/HpZlVViWdc2yLJ9lWf/ygy6P8k/Hsqwey7Lu+qDLofzisCzrq5Zl/eNt/r3Jsqwjv7gSKR8ElmXZlmWVftDl+OcS/kEXQPmV5w9F5KRt29s+6IIoivLesG27+oMug7KOZVk9IvIl27aPf9Bl+WUhZBQe5UNLgYg0vdM/WJbl+gWXRfkFY1mW/tGlKL9gflXH3Yf2gceyrG2WZV3dsEK+LyJRjn/7dcuyOizLmrIs6znLsrId/3aPZVmtlmXNWJb115ZlvWVZ1pc+kIv4FceyrDdF5KiI/KVlWXOWZX3Hsqy/sSzrJcuy5kXkqGVZVZZlnbQsy7shl3/E8f0Uy7Ketyxr1rKsS5Zl/allWac/sAv61aTesqwbG+Pp+5ZlRYn8zDFoW5b125ZltYtIu7XO/2NZ1tjGeW5YllWzcWykZVn/2bKsPsuyRi3L+m+WZUV/QNf6K4VlWX9kWdbgxhzbalnWnRv/FGFZ1v/Y+LzJsqydju8Ym3PD/np6o1/4Nubrug/kYn7FsCzrWyKSLyLPb8ytf7gx7v6FZVl9IvKmZVlHLMsa+KnvOdvPZVnWH1uW1bnRflcsy8p7h9+6w7Ksfsuyjv5CLu498KF84LEsK0JEnhWRb4lIsoj8QEQe3/i3YyLyZyLypIhkiUiviHxv499SReRpEfk3IpIiIq0isv8XW3rlJ9i2fUxETonI79i2HSciyyLyKRH59yISLyIXROR5EXlNRNJF5HdF5NuWZVVsnOKvRGReRDJF5Nc2/qf8YnlSRO4TkSIR2Soin7/dGHTwiIjsEZEtInKPiBwSkXIR8YjIx0VkcuO4/2vj83oRKRWRHBH5t+/TtSgbbIyx3xGRXbZtx4vIvSLSs/HPH5H19vSIyHMi8pe3OdVHZX1+ThaR74jIs5Zlud+fUis/wbbtz4pIn4g8vDG3PrXxT4dFpErW2/Nn8a9F5JMi8oCIJIjIF0VkwXmAZVn3ish3ReRx27ZPBKf07x8fygceEdkrIm4R+a+2bQds235aRC5t/NunReRrtm1ftW17SdYfbvZZllUo6w3XZNv2D23bXhGRvxCRkV988ZXb8GPbts/Ytr0m6ze5OBH5j7ZtL9u2/aaIvCAin9ywux4Xkf/Dtu0F27Zvicg3P7BS/+ryF7ZtD9m2PSXrD6f1cvsx+BP+zLbtKdu2/SISkPUH3EoRsWzbbrZte9iyLEtEfl1E/tXGsT4R+Q8i8olf2NX96rIqIpEissWyLLdt2z22bXdu/Ntp27Zfsm17Vdb/6LydanPFtu2nbdsOiMh/kXUlfu/7WnLldnzVtu35jXH3s/iSiPyJbdut9jrXbduedPz7EyLytyLygG3bF9+X0gaZD+sDT7aIDNq2bTs+63X8209isW17Ttb/WszZ+Ld+x7/ZIrJJ0lM+cPodcbaI9G88/PyEXllvyzRZX3Tf/y7fVX4xOP9gWJD1B9TbjcGf4ByHb8q6SvBXIjJqWdbfWpaVIOttHCMiVzYsTa+IvLLxufI+Ytt2h4j8noh8VUTGLMv6nsOW/Ok2j7rNmhBnO6/J+nyb/S7HKu8//5w5Mk9EOm/z778nIk/Ztn3zPZXoF8iH9YFnWERyNv4C/An5G/8/JOsLYUVExLKsWFm3rwY3vpfr+DfL+d/KLwXOh9ghEcmzLMvZT/NlvS3HRWRFNrff/+QvKx8ItxuDP8HZzmLb9l/Ytr1DRKpl3cL6AxGZEBG/iFTbtu3Z+F/ihkSvvM/Ytv0d27bvkPW2tGXdXvznYsbkxjjOlfX+obz/2D/js3lZ/4NCREySiPOPiX4RKbnN+Z8QkUcsy/q991DGXygf1geec7J+s/uXlmWFW5b1mIjs3vi374jIFyzLqrcsK1LWJfALtm33iMiLIlJrWdYjG3+R/Lasr/9Qfjm5IOuD8g8ty3Jb6/t7PCwi39uQ038oIl+1LCvGsqxKEfncB1ZSxcntxuD/hGVZuyzL2rOxtmNeRBZFZHVDEfg7Efl/LMtK3zg2Z2PdgPI+Yq3vj3Vso/0WZf3Bc/XnONUOy7Ie25hvf09ElkTkfPBKqtyGUREpvs2/t8m6Ovfgxtj7E1m3MX/C34vIv7Msq2wjsWCrZVkpjn8fEpE7Zf0+/JVgF/794EP5wGPb9rKIPCYinxeRaVlf5PjDjX97Q0T+dxF5RtYVnRLZ8Pxt256Q9afS/yTrEvsWEbks64NQ+SVjo50/IiL3y/pf+38tIp+zbbtl45DfEZFEWZfYvyXri+e0LT9gbjcG34UEWX+wmZZ1K2xSRP7zxr/9kYh0iMh5y7JmReS4iFS800mUoBIpIv9R1sfdiKwnDfzxz3GeH8v6/DwtIp8Vkcc21vMo7z9/JiJ/smEFf+yn/9G27RkR+YqsP9gMyvofG84lHv9F1hc7vyYisyLyDyIS/VPn6JP1h54/sj4E2c7W5mUwv1psSKwDIvLpD8MKc+X2WJb1f4lIpm3bmq2lKB8wlmV9VURKbdv+zAddFkUR+ZAqPO8Fy7LutSzLsyHV/rGIWKIS64cSy7IqN2RWy7Ks3SLyL0TkRx90uRRFUZRfPn4Vd1vcJ+trDCJE5JaIPPJPTNFTfvmIl3UbK1tExkTkz2VdQlcURVGUTfxKW1qKoiiKovxq8CtnaSmKoiiK8quHPvAoiqIoihLy3HYNz+N/9rvG70qI95jPCy6x+eKkt97EC8mXTBw9hVWW/QjHe/p2c3x7rIlHq66YOM3FXnI7zs+YuOHwrImj/KUmzvWzn9mz7nLKGT+26XrsiAQT3/MSn1/L8Jh4taXFxC88VG/i/OuFJt4S9YKJZ6PZPNYVxxYGcyNcW2YM57T9bGXRFcaWBoV5XM9I92UT//m3n3JurvieePqpL5tG6bpEOWbciSZOS+4ycXgk5b4RKDNx7kKliZcTOKbkRrKJOw7wovPx1zi+qJ5n7LThRRM3+kmSS9nxpIkXm142sWdus/26ehf7zzU10e5ls14T+0Zpk/w99Ifjbwyb+K78FRP3xnMNK54IE1ctbTXx+RI2mj34Glmcw+58Ew8lcn47iTL/9f/xzaC059/95e+Zyri0xjv7akrMBscy+CxjrfgQbdzXwPtVreoqE5f189L6+QuMu1PH6Cvbxby7VXrCaXvvIq9HqglQP/PL8SYeX6EfrD64uS1jpy+YOP4cW4csO69nhDLVWHeb+NY8OQf3rqWb+GThLhMf7Txu4ptbaddKH7/V5+b6p2IZm+m5oyb2/GONib/y3+8I2tj8t1/9z6ZCcnZxDV032Afu2Cq797+QVmRi6xJLEPfUMiZaV9mhYTCZfp2YwWa75f3036yhbSbuyWoz8egyfSTQT3mK9vDdyNfM/nUiIvLK47xy6WgD49yfRXvW9Jj3Pcsz40dMPFfMd0t7mHek+nkTdsQxj+yIYOPmch/jfYDuKTHp9MPpwWUTr26nCf+XTx8LSnv+xQvXTFuevcybGFLiuX9V93B/mHxizsRx3T5O1M8WcWEWc9TNcG7bKVHzJs4Urit5mrluOYldAPqz6deBPurEjuTSV9Iop4iIP5FyLHJrkuxU2t/v2P91KpsJr7aWdnr2VdrmY/nM65E3qYvVBGL/dc659Fn6ePIUc33HCPWVGNVj4j/57JPv2Jaq8CiKoiiKEvLcVuF56DJ/2V2q46+rRC8vGJ9OZJfwOxKzTLxUyOuPXriFelExc9XEKYUoLikn+As68SP8FTG3kyfk0WT+eols7OCYWP7CTVlD7ambpjwiIqfzefKMquEB0IrliTb9oVoTF8zyV+uXmjnv66k8eS4WHTRxWdMtyhr+ImUNZJg4IwrlY9XFXzJjUzwtxwl/4QWT6Zs8GU87ymcv7CBepk2yXHeaeNLLX2mZLtpkspC6iCg7YOL8pTMmzo7lL/65OeK4HNpjRwd7yU3N8pds2Dh//birKKeISNoi30+ZedrEE6Wca22VvxDzpviL8tMl/KXeFpNq4pI8fru4q9DEMzbX/6TNX6ndn+Gvn5gh3myRs9xt4oVVzh8srsXTNoW9/AX3xtlpEx/L48+xgdYeE8/P0scHszg+3V3A8f4pE8+2o4iMlF8z8VQ4f1l3FtDe9W/SJwazPCau6H/KxBeaUA1ERCamURe2R7xi4sQFR/+aI47MO2fiyjj+yn39Bu2dE/NtE19P3mni2Mk+E58aauA8GZTJHkMemM1kvvNHOt+OETwOuOibDY3UcXPiQyZ2D7DnW2IKbT5ResjEc2H/r4mXYvaYOMKLArM0yVwz284cd2MHc/zaEApceTjXfMOLOpR9jjk+OXvzXpAxPxinfAncZiYjuBcUZNI/o66hmqff7aEcSW+YOM+h3qR2cW/qCOfazmVwPXk5/G7GJHNteTbKhvfNdgr96WMSDCYaUcmrSqkja4H7wDnHW+UOdOJujA5zz2qYIt5a96qJqwc9Ju4LMDanF/ndsSIUQPsmc9fCDBrHVAbKZdZNzlNaRywi0rzAeFnuY44YH2WOOFxQbeLjZ/n88lX6TkU2/atvgfl3soY22998j4k78v6G7357i4lP3cE8cs9QvYmHan72K/ZU4VEURVEUJeTRBx5FURRFUUKe21pax/dgGWxpQcpMyms08doK8ui85w4TR/mQr35XsCWiZpDpLmUg9U9/CrtqegF5N96DJLhlCsnOWkV2W41Hlh+fZKHieEzDpus5YHO5p2uR0frO8rnP4rfz+1jEeKGQRZ/n+7Cl0mKQlpOXekw8VM+1eS+zMHJxgPMnfBSpMC6MRa5d85utuGDh3kUbbm9G/hvOxopZnKcurkR6TJxWzuKwvhXk58Wbh00870Uezh6lrXzl2JUTcSye3HKRvtP7gGNho/8JfrcMm6EnZvP+kK2XWCSfmbTPxHXT9LcX07EmLizz4t/KLPpnrp9y9AXo812ZtPm0Hxsr7E0WA1fvRJZva8OKPOywHBaSN71+JijER1HXPY4F25H7kH5Pz2ON5MViOSyUUCdZg0jRb/QgRZfH0E8rPVx74hI2VmSAhZTWDJbUdOKi4xjqZ6EISX/RzZgVEdl+5XUTX01ABt8dTp32pGOzDDvs5tIRj4nrI2+Y+IbFOM37MX1fPo/dstZEWbuLsMaWOxmDnh5szuUj78++ZRHTWAVLNSx+P9D4AxOH73zExPOprSbe/gb9NywTKyMxZ8LE0xHMR5E5HBMdxt+8TWHMtfEDtHls2adMfKiK373RgTU0VX9z0/VE76Yup5tYiJodwFp6PgKbsfcIFvCWAfpzspdlAiNrWDDhu7Euz97kt7b0Mq+lC75R7xr9IrKAevHcQV0Ei9kq5tP+fuy2u5cpm5XLQvtTo4ydsETaw7Ipc/go82ZzJvfKkS7Kf2cf9dzqpf3SXLRTyTRt3LPCHHJ4knvUzW9zXxIReWg3yxwuHKT9o9qYU052ca68GcoXk8V8sTTAvDw6yvxYvItx2tKJnb17B/ecmXzm612Z2GFL11lS0PMCy2XkcZa5OFGFR1EURVGUkEcfeBRFURRFCXlua2ntzENG2zWMjXUiF3k0+VadiQN2g4mnVpCszrmxCbYdRTrLXiA7qmcAqe3Lq6zMf6n3oyYOK+P4wruRu8oakCiXI1nxnlSwWX5eaEFGvy+O/Qie30HWSlY4kp09jBToc8jjn0lBsuudRf7zzWFLBfKRNesTKMfpNuol6hwS/3wR8mt5MtZCMPGfRIL0jXM9/vxmE68VkQmT7nrTxIknyWqLvucPTPxKxdsm/lLrdRP3bWFPiIhWrI/wWx4TX7qLfVnejsE2qBlHxh5LQK5P8lFfIiKZu/jvtKvYFK8L8mdUMZLvwjKy+9BEoYlzE5Fj7QX2r8ieJOvs0CI20Hg2312dpO9l3kGffPMcFsWWEfp2sIicwEpMfYKMpbBx+k5pJP26t5v6WU7A9hp/45SJE1MfMHFOIeccG+UaI0ppyyi/x8TxPq59NY8+keLHtojs2W7iujDGqYhIbB5TUVqSw1atvMvE0Y1YmK5p+u+tHNo1cpAsj9klZH1vPJZJ7EX2p7lYRD0+PoSFnbuDbMLLL2BvRX8i+PakiMh3YugjxYv0+bkIR6bVNeaX9haPiVeW2cMozIPEHz9HVtO2sNf47lX6eFwE/bSyE0tkuebTJi5Z5Jq7c/kb2Q7nc69FtqqISO4C+x4lOTKqbhUx5o/Oe038gwSs1fR+rKuUafpzII1suf4T2CPV6cxN2+9hz7fYH1KeG3eRTbzrFWzSlyqdVtyDEgxir9E369KxZxfrmR8LTmClSgb3x6J4rNfpAFZdWy73rpwmMt3S55mj2x17fy0sM8ajE2iba+1ke3XuZxmA5/MsEUlqZO4WEWl/mrE9dsBr4kN5XOfYBPfTyKIGE09so49UTjMvj+UyplJPYp/P7KK+rkXSV+JH+V2rh/40nUlfycnxyM9CFR5FURRFUUIefeBRFEVRFCXkua2lVRdAInsugNVRtoKlk1PIKuzpKVakDyUji9VFI81JL8eMWkhTB1PJKGmbR8aO2YX8vHoRWTosC1uttQ3bYrGclfDh5zZvke3J4HpeLeZ63I3Ir4Fxx1bmiUjC07FIqC0W9t598dge3v1kiHW195j4zDByX80WzjkRw/bts/0OO2yMsgWTvdlsGHirFgttpIU6iwpHWo8KYzV8ZHWPiadSydJ64jLS7JVi7IvoBtpzJhxLZCmV6y8qI+vqi5eQ2SNtbL/nVsmsqnJjvYmITA0iTTft8pr4jlH62NklbMlohwUzvc+RadfDdRb1cD2jBdg9XZdp/+kK7IGxWGTXim5skJo9bJLY2MlGWcFi3I88XHqd+rInsU+9edR7RxtZTWW1XGNpBpZO/Bo204tr2BuVs47XhMxi1SaHOTIOx9/it4YYB3npZLpVFD1j4rcmsF5ERMpWKd9EFhJ84tv4Eh0z1HX0YcZLwuvYIUsj3zPxwVr6td9hUY0UHjHxg4tkhbgvOrJRlrn+Ow7SZ5tWTzpK/agEi9QU+n/hDOP0ej5tO3od62PfEnPw9c+xCWVmq9fE8zeJb6XSH0/7sA1y9zC/ls5x/s65HhNfnsU6do1TR4nRWB2TjswnEZEpL/P/sWnGeXoq1szTY3yeX4CtPJiH9T7teOXEY8lsNtszTL/YlfZbJp49hb01kEqmaMEL9JErUczxKzexeILFdou57wdrWDrbL3MfuLizx8RF3Xze18Z3O/ZjARcNcA/1WthzrVu4hR/q4NrnVrD2ZsKxyeJrKc9HHP0g9SrtNzOz+b6ZWUnW3GgB5f5WI/NCRSYbv04NYLlZpxjns1HY4blz2M1Ts7RNqpslJUN9js0yt/Fb5Y7XWySNM1aey2W5zLuhCo+iKIqiKCGPPvAoiqIoihLy3NbSmnwd26PAkXUzMoGU+XoJq6SlyyFZuchqSRlhxXhYguOdXEXYYd7rZJTcmYZsOhiB1Ok/hNRZOoDMvFSPbJ7egQQc17v5vTfNeXtNHO7YJDDGV2ji+xPIuvr7E8jGRx17ATYVs/Hc9TyOyVhkFf4DUVgFfQEyATobkOa2zGPpZe2lXuw4MieCyXeSyf7Ic5RjZbcjYyCMckyOcT1dcY5yn2J1f3cJNsjuMDJ7+otp26EYrr+wBdl1YRSJ2uV458x8OP1uxxDWRdjQ5uyBxa3YVXLZY8JTNWTbFLVjg2RkckxvK9Lx2EtfMLHni0i7gVE2B5u7jz4cNeR4w/QIFtLAMv1fFrHfKjyPSLBZdGHv9i4xFnKb6ahDFpkXx2qwEhYaGSOd+cjdWSN8d+8q7RTmcli7Qp+1zjDuXFFYJofSsUZiHVZVayOS80K+463QIjIxS5+PTqFf5CdTpohJLGB3B79xM5z+tS+D37iRj+XW3Ey573V938SJmWRB5e5gw7+cCdp+LJZM1PTjDtn8ExI0YpMYX99sZQzeFUkfz09lLHQWYEW5XqWvJSczdi4eoQ1Lu1gC8EQc53+hk3F6OB2rfnoOO8WbSLZubgTW28os8+uu5s2bgl5MwzqZ3c3mobPDjk3/drMJYeogNs3KAGWKq8VavNzPPSWh4G9NvHqV9gyvwh4qdtiSl++kr2Zext68L4n+GSy6HZZkeTJjbfKS43p3NJjYNcd9af4YNk78ZaylqDavicOP0jbb+vF3Jt1YSWH9zEXXkhgHBT7arzqLc3Ys3mfi9AjeiycicnGeflTZyiaJNy85lq2UM367Emn7pUXml4Uy2rjIxT3Ut5/6aniJe0vONuZWXzdlWBLqZT7Ab5WdcWTcfYXrcaIKj6IoiqIoIY8+8CiKoiiKEvLc1tK6+nFkyugbrBIvt5Al44awbpKKfmzimWik6Ck/G8kVR7Dif6STFfKj2x8y8eoYlkHymUITr5Uh415ZRgbbXfCiiVvnP2niLhcSsIhI0iLfCX8GC6VmCems8xgyaMqdyGjnHO/GssZYAR81iMw+PI0t54nAJloaQAbflcIGexeepC5qWpEdPRbXH0zy2o6Z2K5jNXx2FLbk7DBZUdEeNqsbfJHPVw8hfUdZZOS8fpOMl6Jt1FHdOHbQTCbXORdDe/ZdRLovdkiiKxlYmt5cyiMiku7F+nSVN5h4qxsLojCH63xjmOO3xDg2ynqUftLXTV+d9NA+cStYKJFLSKcl4fSpxioyD9zNZKxd8FLuYLkgNeH8rZIYhWw8/CTWzbZxsv1uxHBdN22yLh4cwPbqP0L5kzqRjRfnHO8Ia2d8DFfRfv0XkdBvpnN8VQTZbRO/wZyw662GTdezKPSLfe2Mne/G0QYVEWRdTUR6TVztQU63ZnmfTnIR1s0fjGCHn14jq7PTQuJv8TI2Y3Lo72OXGY9jd2A5/KEEj4hOyurJpf+/6mUOfigO+803jL2zFk2Wy9zat02cGU0fXBhnM8iyhM+YuPdmA9/dwbsQx6PpL3eu0m7hg4wbv5t4MI3yiIhkNHBrOZfIO6G2J9KePZcd734q5f15dV7s5pNnafOaMK4zaRwr/Xwl7VnVR3sOxtWb2OOibdt8zPezfvods+N7w9fLnJBRVMjnO/h8zsv9tHGVLOG7rmI9P5WGTVwVzziaHeGeM7eFsZbdxn05sorf6hxhnGassQTDH471P/Up7gEJT7HBo4jIcBHzQlYjfapiL/PalSuO91H+Bm1c/Co2XsQVaviVBDbLTNvJMbHlHhMXdGEH+rMYd1dmyJ5ddGHhJj20+f7wTqjCoyiKoihKyKMPPIqiKIqihDy3tbQK2pH657KQl874He8x6UBCPBuLJLolHyuhaA3JeXGZ8xR03G/ilCWyTooKWTmf/BWypm69iV2VH81mbpe+x6r+6CQk7Y/nb3730qCbzdFW9iPHTm5HNnU/g4VSmYE10vwGknhmDnZYjI11cz2Z7y4NFJo4vNaROeNik7CEN5ERl1bJJpocIStG2FPrPRPYdtLEM+eR7CMXsSNWDtE+289wze6jvLNldgvX0/oacmniVjZhvHKC89x9kPP7XWRIzAwhr644VvC3zSCnuxLZhM7dgPQrIpLnY2OxwH5smgE3fbLfS/bLRAbdvXCCjIZLabThZEaPiXeHc/0Jjqyrlrl6E3dVe0ycPeGl3D20rXsbNlOwaB8hgy6vAEk4zk0/er0XmyR+P9L3ffVkQZ1u42+evEaspKg5pOLmYj7PciRXRUbQT1PTsc8Sk6l/awqrsua//MjE0RVke4iIBFyM+bOryOaVYV7KVMw1Jzcz5gsqGfPn446Y2HeOLJL+W9TFVCXWc3ozfa3CabecwW7PeQTrpeQlyiOfl6BhtWBBPOJibL4SYK4ZtLEWRnyMo3sdG3tO+dlUbz6K8RUubOb6oy1YRjvW6BeBMLJzMq99xMSLW6mLyEO0m+8sFsKccB4Rkdgy7h2587TVSiZjYV8V95GxQTpWfjH96uFkrNX4CNr51Vu89y1vgX6xKsxN15OwTYou0ifd6dynPLWbM3mDwgPMd82OjKKEHrLdrETGaVk2Y+3FZOzMrTfJwDp+i6wjl0VWWqWXvum3scPaE6gHuwzberCJedmaoA6ts8xX3jeoZxGRvPvJsvtBAvfQx6LYsNUXQT3u62E+PbVC1tW2Aofdnso1h3dxzNkVrNeSQ9RXRxjLCPZcwto9X8a4jmjjWeHdUIVHURRFUZSQRx94FEVRFEUJeW5raUWPIv1dnWSjp/07sA9mIpFWrSgktYCFNNfZ22Pi6i42eYvajVQ6FcbK+RYv9tba/0AST7FY7T+2ijUUlcyq7ahqNg/7xvDmzbAqZ5H5btxH1tV2R0aK6xBS2+IEkmuxsMr/tWHeJ1RcjUQY2/kprmcNiW+lEGlyNp2sgLiblGd16KyJz8SSjfCbEjyixx8xcdPH/quJ68+TaedwiWT6bjIJBv8HG3eVW7wf5f4FVvq3xyFF789gVX1H85SJF6uJ669hxUyGe0ycloyMf9ZLvdTevTnrzjeMNZE6g6UytUabrMRSjv1xtEl3BLKzPU0fPlLOJmDN8Vgi2TeQThPGuf4OP3bCsu2oo/vpe7uu0SeDRZ1jM7ieETJkLp+mjnbuPGLiyXba8ruJ2HllCWR81InHxAspfL7g2Wri6SHGSl80fflQDXJycT/W7huTZGZszfoNE7e4GLMiIsUBOt6Nq1ho8an0EYnF3iwv4zcaTtD2pXG069gW7NauFGyPWh9tMz6H5Rnp4nfteEZe6TDZh0np2JzBZHgvbdIayzXvnfSauMthMx5xZCLe3EZ/X7xImyyMc51RjvcZ/loD1zmRzBw8PUk25a4t1NfpDMbZlus9Jq6KY/5qWDmx6XpiVrDlcuYLTdx3neyqqSWPiWePMOY7YhmnFybJcD2U8GUT31XNPWJ4jvPcXME2+Xg/Wba39tBHoi+QZboQQZZpsHBHc+/bdeukiU8lkYl2NJt7y5lv0U89+Sy1KKxFj2jPosy1y4z96BksregA97T5TDILD1ykbgfuIVM1rZX57cSSY2PGSvqWiMjkOGPtzhnH8o8sbKbRLfTf0i6u4XAx4/xyBEseYoU+vrb89yau2otleusU83J6A88HE7V8nvwdrDjPvs0b074TqvAoiqIoihLy6AOPoiiKoighz20trcYYpNyPzfHui+eWkNTmh1idvyO+x8Rd6UjLiwtsKjj++z808crfYg1Mb0VOTRkjY2fNS3ZMewmrv8NcSNFVlsPCGMMyeayLLAUREW85suDqCTZ1SohFCkucQUK92IxF112P9Jsb9zsmjo5ARhyJRgYuSaWswyOOTbhmycY4cAn5OXs/kt1jI8iUwSTMYTXc387K+IVYsnaK0wpN/MMRMifK89ncq8FCKr4jQPvHXvGa+EIRsm5WCrZSehN1MbmLei+Jo17807RN2dpLJl7tJHNERGT7GPV3PBWptiYPeX1tkGyIpm4st9k0+lhKD9L8eAbWlWuC7IamLmzc2hRstvgIjpnPJEOmfZi+49nieN9ckHhlBAtpVyHW893FZFh0OuzG5E4k5MeKufYLjtd/tcY4NmZM9pi4/kaPiXPKsJX2LGA9dPTRV64UYIHk+/mtbsfmhyW36B8iIqPZ1F12KrZE6Rx957k+rmckE1tmd3qhiX3x2G+Rty4RlyKzjxfz24udlOlcNfOFFUYf7+qhfr1RWDIYFO+drnHap64F+2ksnTJFFzBOj8VzzMrVe0w8nkb7e6aYU6/E0bZX01428dT4oyZecDE2Y12U5645ssMS9zuycocLTVw5T+aMiEjaAcp3bcpR1ku0z+okyxXSR5ibOsPJ0nt8lnnxWj8b295VS738gyMj7P7EQyYeeoP5Yf4amWl7t5M1/MKpNyj0x+6WYJDcSP+a9mGZ1c1g255Jp75K3Bw/v/vvTOxr95i4dI575aSf8sc4lpEkjjNHJzuWBdxKxnrK72Xen+ni853HuI+tpDAXi4gc8nFPvJX+gonHmrHqtziy6a6kMhdkejjvVDH9Vy5j45X6uYc0DjFfzB3BZivJ474+2EjfTNjBvDE8z1z8bqjCoyiKoihKyKMPPIqiKIqihDy3tbTispB1L60gZXqbkLJ2RzSYeCqDrIDwFeS1mkfZMG7ku2TBjGU6MkquY3VNjzhec38/WRGVb1CGpc89b+LZCc7pJyFKLm9hkyQRkcg1pNK5ABlfW1Mp661ovhOW48gE6zpi4mw3suPMBbIRYjLJBBiORYqN2Ir8Wj/KCvieAq+Js/LZGGy+EPkumExlITtOxuNlRPoLTXw2jLp4cIDV8BNJbMqWYpOZ9EwOcuRdkcjSaVH0hYiLyLeJDltxHqVbzjve57XLjV2xM4Cc6tu2ubu+PYkltnuNzbhGJ+mfYZ1IpLF59OfKAFkSLZ+qN3H8KTbAG5ijDYsC/FYgFgssc5njA5eR0L1J2AlLvs3ZZcHg7lhk7TgX/etsNZu8FV6nP+5OoAxvCrZdcSkycPogfbk3Env26BJZiRM3yY45X8Y1zqZib913ibrtjCK2Eyjn+OGGTddTdQvpvy0TybowjayQT6cyLkbSqPfFedo1bOxrJo7cgo3jnaw3cfyPkdnjqx0bh7qxkhOXvCZ25/CusqTAg/J+EFGJLT96HUs2bPReE48UYDXMTpLJmVNBWxX3Yo+07WJJgjXzaRNXRNN3JpaxD8fCyUTNTKTer8TQjyI76QsrM6+Z2LbIwBEReeoVxxj2MeYnKrGG0xzvuVtwbGK5a4DvdlRzzZGCxfFiF/PXY11kAk5nk7GYXYiFEmZh+70yyFioX+XagkXmMtd1KfGoiXOmsAbTHJNf2gRlXunnPVat7YyDohQsrYUeNnx01TDntFZxfEwS9Twaznw1O9xj4pIsjg/YtFHW2uYNe09HYpPGTXCfmilnjm+NoJ2qGmibGev3uIZeMr2rV5kLUuooR8OQ18T7O7AAp/LoH4mRzBWjidSjqx8LW+Qz8k6owqMoiqIoSsijDzyKoiiKooQ8t7W0Ep5lBX/3nXhFd4Qh2Y2kIycXNiKPv7YXqa3sb7GcclKQSsursKjax5Hy4h7mt6ZakehL9hJfvoj8XL4VOTjekY0wF8FGgCIia4PYJvdnIeW+fhYJz3VHg4kf70M2/lYYv1HsQr69vhspf9XPbx8qRXKfuYQE2ZiAPH4kFXm4+yqy3hzOk8iTEjQiJlmhv6Xr2yZ+8QDvRMlsYnV/fAXyeEMbsmtpPNLy3kmux+4kE2Y1k34xF3/OxK2pyNV1biwz3xxW2qibzKzWyMdM/MjZZzddT3/5duIirK+ZdiTc6hKPiRMmkLgvpJNJtPgq0ulCFvZbTBrtticayfZUAv28uZ9rKPbR5xcTyTSLqtr8nqFgMBRLXaeFITlXv4KcPP84mYyXRutNHH8G+XrPKtfiXebvn9EfIPsf30PWhcf7uInD47ARtw0x1q6lYZnZq8jesw30p2hH/YiI9C7TL3JXyeQ5O0cWSnUh49Saxiq7dhOr4Fi24z1vDpl+IpqxX3AnfTN8JzZeyVP0cZ8HKz06hmny7Rn6ezCxuzjv3DwbgRbdw3uM+lsYI23ZjJG5aDIRS6KxYfNXGe8rM8j9Mx2cxyole6muF3uneYH5cbGDTNkDH8eSH77B0oOMDDJ3RUTq5vl+Vxp1uctNW40F2Bxv9Tr96q1UbOjfXmYyPBXF/JoYRvsP5jaYOOoi1s/rVWRdfWSFrMbxJH63a5X7UbB4czv9NNPRN2cLsdozR3g3Yd+TtPfuCeqtejvzSccMywUittMnIoZov7AoxrI9/48mrv0O46l1J/eZyPJCEw+8hWVfdu/m7Oa8N3pMfNVDVmPmBHNQQRwZdxWRtNm1uW+YuMexLCZxiXpvnKWO8nq4htkUsrsvzfyfJp7Jor/nOt4pF2URvxuq8CiKoiiKEvLoA4+iKIqiKCHPbS2tlY9dMHFiFzLd+SQ2A6tYQEbyDmKNPOwlk8d6EvvJ3eI18a0+ZOyYaOTUpTFWto8Uc/7WZx3v7jlI0aNfQCrriOI81S8jUYuI5O9Gmm8dJ1NhpZhzpVxEXvwfNd81cepAkok7s5FH8+KQC7tvIv3OCRJh6wIS375ryLs9kaykL7mTTdXWfPxWMBnNxbppdpGBlnSLOp6Lxn56e9jLMcvIiH0XsDvWHNlL/jrssPxpJMuGBFbYe85jd/SUIIOW7qOPpJ7C3rzsou5Ob6/fdD3LKXwndoJ3P9k0j7z5IP1w7TL1HdlPdk52JMfM+thU8NAMtstxR39On6McO63TJo7YwbgYfx3peMnit4JFXyRWaphN/505irUQ7uh3Q+MeE+98kHFwaZF315TOPGPi8qWPmXg1Fjt3azKZOUUDbELoj8FWG9mGdN/yTTKiYrOwKjKisEVFRPod75grbMfemdmJDfbaKRo2co0xb+dgmT/bwwahKYcYm8kFnGdkhGykshNYYGtxSPTxk2yMdjmLflozgmUUTApiqLPurY53VL1MVlzRNtptzfd7JrYc7+rztfE37EI7WW2x+dTXZA5z+UIc82V8LHZCsYvr33qw3sSjo2SQ9U5i7Wf1MJeLiGzZ7/xbmvvIlSGuM2OGeS5+J1ZJIofLwAuODWnrsG86Uujns6vUV9Vh6iJlHMv7matcW+k9jj4Zj+0bLJK+zfw4kUNWU3bpiyYeCbCJatV5rPNz2WQdjVvMObtT6MuTo9zXYlKxy9euYltWZmPxv/UF+k3ZLBlOXkcG684C6sH7Ys+m6xnJZWlHwjbs4IRZ7Le53gYTv7CVsfaxJizj8Xn6RFsdZVpJwqrcLmxwfCrnba7HxTafCeP0tWEv82x2rnMtyDujCo+iKIqiKCGPPvAoiqIoihLy3NbSyngdK6KknpXU+9zIun+zD5m5ahALYG0FGbzveY6fPkgWSWkT0mJkPplfEXnIj6kubIuxo8isIz5W2nuiyTrYgWMkJ32bN1BqWuRcW1qRQQeLkcGzZzmXFCID++ZZub48iXWxEo4MXrkFabI/DMtsaZHjUz6FFJt1Cvl1tB+ZrrcMiS+YrC2TMZMb3un43Gvi/FXK3W7xnpLuCcqUVoydkkKimQzGIy++fo662xuObTKxz7EZZACptL8RiTOQS3+xHJv8LU3T5iIiM6eRf3NrkGrXCpA2fX+OzXb4t7G0Xlxis7ZIDxl16WePmLgx87yJwyuRZq+sIR2nLtabeH7BkfGShy23FostESzqIjz8RxuWS3YhvzV1iLHma6cecpbZzO7yi0jZdvq/MPGa4z1c4RMOm6SCzAnvEPNDeB59YqadDLiZWrJLKiYc1l432T4iIlVuyr2US18YHSEzs+5fcQ0nvurIRstAQg+LYPwm3OAaXJlcsz8ee/apZcZgsbvexOmpOSa+I4q5aXYr1xNM8hoYSIMPMo8UCtefOoV9POLHHknrYq6dnScbrTqXJQYr42RUpSTS3y90sylsxxEyFCtfxbo420W/roi9z8RFe5gTbo05dnwVEf8oY/OuMpYojA+w4evSTuy0VccctLzMPL3y6BkTu6sYg2mXmAvqu8lGe22KcpfOcB/Jj+C9Udc6sWLzrc1WXDBo9nBbzQhgtSe8SL37C6jTy8vMj9mjjLXeGubQ7lnHZp4TtKs7i3GXHM31xt6BNRTWRb+J8dF/XXv5vPttyla8hToUEUk74zVxXjy/3fM079Va2kt23NF5bLbja7Rl3nbaz7fWY+J9LYzfyS3MrVUtLH/YUsT1T04w7wTysUhbn+P5QP53eUdU4VEURVEUJeTRBx5FURRFUUKe21pai5/Axnr7OFkbkTdZ/X9fD5t7lSReMfHfp2P13O9Gxjw5gDWUt4B9MjKO7RMxgcze7NgMLXcKCbW0HmktrR7pb2iNlefNO7EVRES2LWEnTe6n3EUW0uqZA8hxqYvE1S42rbt0ENl4q2NTwZ5EpOWkReyj+iIyUiaHsdlmWEgv1T7Ok7iGTBdMqtOo17ZK6i/59A9M3CLYI/4INn2byqPdxhztGdnnyGDJoDu11vH5aDxZC5GxWAUy7ti0MRo5MisCGfRsLLZS1jVkeRGRokKsj8pmsqtu7qafZN9Bv4ofYrPF6HzqYuxtJNK0OmwQawB7ZKyDzb7S4riePB91NFuG/RA+9bSJPbuDb1FGhSNNx4YhTc8ImS+L3yCLYrdDKu+sJyvv3u1YD30lZGll99dzzi5HhoiFjP12zv0mzglDlo/Ofc7Emauc59oo4ybrTtpFRORSG/2rwLrDxBOLtH/u3yK71zzksKu/Sf2eL8T2itzjsOtuIZsnzdOW/oPUUcwglpt7jbFc7uV33TvZzC6YeAvJyJn2YtcVRDPX2jaZcGlx2M1hy8zTqWl8/mwm1nDhGPNi1VPMR8m/g9VXdNyxQWgM80PeFubRnBtYwS/O0tfyLmy+lSQf4beXe7GNMi2siaRXOW9zBf0q9TF+u/VZxmBkhCPz1zG3dw+zrKJoDqurY545aGuh18Qx88TZBSyrCBZzK8xf+1PJqEp0ZCaGN3LPGUplLMQ4bKmUVea3wvPcT65X0seLoslobL6bcdo7StbbPR7mij6S7GTOJssuIYljuqMdc7SIxHycebqngfli9THaoMzxfrKUUdaVbPN8w8Rdax4Tu/uwxs/Xs6nrb8uPTXx5kCUPpxmCsuxhzNZeZgPHZ4o3b5j4TqjCoyiKoihKyKMPPIqiKIqihDy3tbSmLpAhUzNNFkV3ntfEfQlIc/55rJhj00htSTFYV8eG+MnVQ473rbShWT00gDzmP8wGdu4zSFbtEVhMflRSmXur3sSBBDbaExHJ3IXN5j2LDHolCQnvYASbHfl7sSgaMpGN3accGwY+QGbS2i2stSwPcmGgjbK220iHXQe45rjL/FbTGBLi5yR4rCxT1tV2sgcmZo6ZeCQBCT1rAjuheP+vmXj8OWTa1EiuoTGXOGwCGTtrmQZ6tMdr4q+X1Js4x0PZRuNom4oRh+Scu/n5fKEAef37kWTeZPdjd5Tkcd6WBX57r49MjfA1MsdGpvi9W7FIrXvGsXvOL5MVkjroMbGnlf524wk20kuwOWbz291+fvIWKGdCEXZop+M9VHHLWI+Tu7CT1hxZhp3zSN/JC2TTvOhlbO7ZS59NOUM/Te9DTo4s5HpnBcl9YOKkif3jWEltZ/muiEhyHlJ5cztjMKcCif9NPxJ6tOP9Tq0HsSqfSMHGiBynv1zF0ZLZQfrvvaNYV6lheMzzcVjeN26RtRI5xRi/9x4JGvG5zC+fmWbe7Simj094yYKN8WNRhTlSU+fiaLc7rtImC4VYr7FfxLrr+CHZPCMHmQfS/PTlhibqumOVOq275tgg0lO/6XrWwrCoW8e9Jr6eyYanW2qYFw+lYGMudjJ3jB1hDPo7qJewc/T/gPtrJvYMUUdT91Gm8QseExc6XvvV4qXeg8XaKnbeVDQdz1fMHJW8ij1XsESbvZaAdXVsGkt2eRdj9oHAKc4/iB3v76HvSzk295ybcVf2JPfixcv0CXcF47p7gj4uIlITy7wQl4712J/+Sc6Vw3jueIO5ZtyNdXXHLNcccGRxN11gGcGZogdMHLlIOUrWsHnbHRl9rkwsz7Ju7lfvhio8iqIoiqKEPPrAoyiKoihKyHNbS2s5E5lZylmRv6XfsSFbDJZTj80K+V73ThOfyiWL4oF5pNi+Isfq+gakKZvkKNnai+x2o5jfiohAinWvcEzpHWTyrC4gm4mIuHqRTVcc+57t9SHBhQlSaXkdVtfuHuyw4yvUxdVlx/tqipEUT7W8YeK15IdNvD8TOd16w0NZs5Ast3nYJCuYLHVgfdg2MvhU2UkT56N4iv0a76Jp7qJMkQlkUYxNYFctjWBF1ORjD6SvsCnVt/L4gbk8bLV5+4iJ/Y4NuvLLacP0eGRNEZFzgY+bOCEBSbWx35HpMIvka4chkVoWfftyHlLrXATldi/2mLgz5UETFzTRnztL6c+1YVi6h07Tt49voR6DxWK9YwO859nQ69VUMqTSkniPT+0FrvGVR7H5DpUy7pYGkeLry7FVY5uwEqYisBv8d9CXJyawm/IHqeeutxhP7vsZZ6fCGcsiIp9ox8aO2+I1cYyLftpVxQaApcvYAMdisQrGlp/nPDG/a+K1JfqmFcm0t9+mT722yPhILmXzxIJabKW2PjbnCyY3ffTTIouyLg1gUdb0U38DOwtNfGYJW+bo97AyCuuwdtsC+Dg3+rAQwjIZa54YR6bsChvAbUnBzp4eZY7zTZLttz/WsembiLQn8A6shUTHZnL9bCbnj6TvTQwwXvo6HO+HuqPHxO6D2EMzkw2UaYLfSoqiT2ZOcfxCO32+49P04bIuyhMsEiqZs0pdzCeNS2QxDxRgk+5Y5np3DTG3jG6lPRYzT5o4/lUsprBd/FbWNBlOae6vmNi9QP3LKn18dCf2We0ByjPz0ub33LUu0TZpK45M5xtcT3QfyzxS7uSesJbE2BnqpP/GxTIflbXSTs0uxzKKrbwjz/Jyzp4k2jLHkWFbnM3ms++GKjyKoiiKooQ8+sCjKIqiKErIow88iqIoiqKEPLddwxP9JjtGju+7YOKxffiSa3+Fp5e6jTUA2/rwdMOWSX0dDD9p4rkBfPJkD97wxSXWyNhe/MT6j3HMzEnWS+xx4ef/3y78vQMXSJsUEVnczRqjCodHf+0s15mwhh/+egZrQZbvwmf0v4D36XsDDzGjgHTc+xJZe3Axl/OcvuIxcR5ZhxIzx8v3JnK4/qDiwadtSibt1mrC0454kXVLOx8g/bprkpcVpkRT8IgjHhNHNrC2p3iBz18RXlC4fPAJE+fN0Abhy6+Z2P0Ia17eGsBzPjK3uT0D4XjCW8L47fvuYX3OP7Q4doK+9TjXU4q3HDFAW0Uv0IZhjpenusepl7xSUmUHMzi+b5T1XNf2s3blodOvOEq9effvn5eJWUf6+YO0x7HT7E7quoP1CRGrrNXIu05/7IlmzUBXPi9q3N7F+oGxFPpNezEpzXvaqPOYeHz+82us/8lwbAVxup16uzd/89TTXsS6n+RGvnNllbGZvgXff8LDmoH0McrXWESq7EzH10380J7PmLhhJzsKf8sxT2VVMMbL4qivmcu0ZVh5j7wflC3SvzwXWIfT9zmuvzWV9nQtsnasuo2/W1ufYL3cVPNpE4/7aeeMiC+ZuPIO1gt1DTAPJEdRj71Wj4lja/jdhQXmh+WMzS/IHT7JnDwRTp/8RLLHxD+M56XNxfOFJp7+BOM3K540dtfXWafXmXHYxCXL9L2zHu5BE2+xTswu8pr47g7WYS25KE+wKG1lO4DnMlhrt82xrcBH15h/Li+TEm5NUo+146z9jOh3bOmQyDYByZeZu8LWGJvh99OWC1fZziU2mXVTVjNrKKN6HW80SGD8iYhkpjDP9ozQB0uFF97WxbC+rnmItqleYhwtBFgv11p30cQ1OWxts3eY/jsq9N+UQZ4zSue5J4z/Jmt5S96gH7wbqvAoiqIoihLy6AOPoiiKoighz20trdESJOvu/aSLlbcgR43swn6oKkQ2HbpCGlleIhbQcAqpshWjpOPFZZFOGDmJjBtw5EmH+ZC4qvv57sgDpEfuWiUdfjYcCVxEZK6FnT1LjmJF5bSQ2ud2Iak9nExa5/QEclxiGHL/XDJSW5+f83jnKdPqtVkTRyYiF2ZGsEPsLR87TJb3If0HE5eNhZT3dccLLR8jJXhmnBR/e5oXct4tyK4vrSAd7mqlfRqKSX+86MJKSu0lfTx9GltxwY3knGohtfauIYdXZiF3Jg2wrYCIyJ0d7JDc+FE+t25gqcSMYv1ci0Z27VqhTeKmaOcsuoVIJNZtZyLS9GoyfW9fPH17/hzWylQH13/tS9gAn5DgkNSM7B+YIF4spmwD1/k8KpdyFlGlUuR4qeTOIWzikWr6hNWFxerK7eH8rdgN3WvfMfFYmMfEhXGMwdxdWIRXnt9sT3Z66JuHSphfFsbpC1c8WCgVLsbdYBnHFI9zzf1RtF+Xi3JkLzhejBlPf5+LJV27LY5xmlrASxwLJr3yftAXx3mnH2TPjIznke8v1GN1fSkKC/C1Ifp77go722bup++XdVHfiwnMgy2Ol1UWpXNM3BC2zF4LS6R7lvk7dxftdMHl2OdDRBLHmTvKHsH6ON7I3J69hFU47ebaPG30Sa9jV/+VrWw/kNL5fRPXltJvAwvMKcNl2JUry1jPb17DoklMYJ4W+dlpzf8UfJUsF3hgDDvPG47ldNLFVg8LcY7tVqqpn5MDjNnqMNpsIBHba9oxblznuHclf42lIKNZtOWxLHbQXlxD74jM5v47meKYTEXk27ewvg5HcI8Lq8c2u/wS9xO7jOt8YZHfrn6Dnd+jBuh3bh/PConptH1vInV0PoqJeXcCttpEC29D7Zx17DT9LqjCoyiKoihKyKMPPIqiKIqihDy3tbSmK9hdd8ffIhedKUIuK11AmnrRKZ25vSaeLUVyfrgLa+jaAJ+nW3w3rZAV6VlFSNRvvVxv4plcyhA7jkZf0Ick2JuweWfe8iMcd+lrZNRk5CFxzwmrynPLyGDImEOOHxrivNuqT5q4eYbr8S3wZsHoJTKQErdhD3RcIxPClYrUeNlxfvIp3jtzUfxG8hGkyYgEJMjMIupvfoKyjmVj1yQf4Tl56gySeyDhUROPOF4MKDaZEzGjZNf0ZWAhVC7TFXffxEIYSMHe6/VttihrsjwmnvgG5R4+hD0Wt5MMwbXn6UuRnbzctX7VYbOlU9bhSGyDRwrIhLp5jd+aqkZSzt5O5kVyLDZD3/NkZwibpL4n4mex5GaqKPPYAeo99huMqYnVehP3R9FmT/VzjZ/x8/ny82RahN+HhF49iX0wUUD7uS5zjdXTyOMjWzh/5jwZlNHHeFGliEhtChk4S1FHTFzusMTSF8hkeiGVtjwQRQbpVA6W3tYIxnvX2/z20Cp9Kj8J2ytthuyt1WTG73IBWTGr2dRpMJlrpn9Nf4RxNx+B/bIyTZ+9vMbcVFbD7vLNNrvfxjteZpvSj20SX4JVMvMcVnVpBbbEN7M9Jv74JazghDS+2zpCvLptc4ZMZRrf75xkXowce9nE4WvMBf0W80vAYsmA3U7fXlykHDHFWOnHW2jntGTK4XZkC4avYZ9lJ2MzLWdsfoltMKi+Rnv0f4x+t9xOOcc7uf8ULTK+YlNos77xe018eZo5Z1c8Y83OpR/0/mvab/E6fTZhms9vhXNvGclz7LI+Q7/2TjVsup6CcMbd+StkhZUss8RkKZH7Zu0YVup0T4+J/dG0sb8UO+zZOezp6GaeJ2qmHUtHHHN/xxaOz/A7MlQzOP+7oQqPoiiKoighjz7wKIqiKIoS8tzW0so7g8zVU4qE/GQSFtCNKST9f92BhNgVQEabcWROXJsjzt7O6v3JbmTP6UFsiKxFVu8v3MNK7TDvNhNPTCID+iaRq93LnF9ExNeJ5XBolJXo83cg/3UskbEzfgkZbSGH8k0VcJ3LbzperHiY+qrzcw3915Egw8uxCVPlWQo3yTGL227bLD83M2Osbo/z8MK9aUHm9I/Vm3i0BPk5622k75R5pNm+PDar2+XYxM3Vi+zY62hDVy3WaG0j8qV1mA0fpyzKNj9DXfRlk4EnItIRSeZUciK2VFY35507zW+vJCHrb8lG+o4eIwtlxo8susWRpTfTTx/LSuD8/XXYKa3DSMR7L5Dlk5XreAlvkLhRSxbV3fNI9NPfImtyTz5ZNGHJ2Kptr5FpU38Mq3Y4hs0lfTZ9OXaStrQcUvTkU4wP3zasq6wJ+nJRKfZk7z7GUNtr39h0Pft91Jcvhd+Y8mKbXHZjaewPeE3cvYCFUGgz5uMzvkscjhTvz6YPVhSROfKsl03MPp3BZpkdb2CHPFDPvBOkPSRFRKQgls3wwi5RZxE7mfPiuh2W2xTtFuP1mngpkTE+doR+MdqDLVEQQb+OLWDsNy1S73c1YXMP+Ljms5mM0080U4+XExgHIiJr/dgamXOM07VsrMK1y//VxAuZZJelevg7PGyY+fJGNVlatePYppKPjTmbhA0SeZl7UHIySyCG9pLdWTd5vwSbm8ksF0h+m37tEbKRtlcxzxy/5XjJ6Q36QamH7Ki0VI4pX+Ae96MY+kfW92jXOT/z2+Q09f/royw7uOTGDmsq4vy1w4w5EZELLvrFbBW/t7rk3KSV8fXyIFlqcUu05cQI/SVKHMso3vKYOLGSemmIoG/udWPztp/k+HCXI622yis/C1V4FEVRFEUJefSBR1EURVGUkOe23slSFpsyJUyROZXcSDbH2G5WubfEs6rc9rxu4rwbyKwnHFkRi92cp8BdYuKMTOT07kSk+6Q+ZLPVEWyoXR5kzDccm2dlJzg21xOR+jxk0+vZ/HZ7LpkQFTe5npS9XE94xwsmPpKAtfL2PmS9gmkyCub6kFArH+Pz16aQqxNXebeTy43E13lz87tMgsXKdjIb4hton5ka5PHEdqRp1zUycrx3Y1eVDfCcXNxGpsUbGVg6CwtkHmQnsCFWiUWf6hqh7t4Y47sfs/lu/wxyesooUqmISMMxbDZ7DfnzVjf95P4lsiFO7mNFv3uMrIfiZMc7hKbINmhqwcrJd1g5FRPYIGv/L5shJtVdM/FEPNd5YNM7wH5XgsFSOH5KWwx9KqOcMvy4sdDEqZX096KPYEvE9WHV9XTST0tisGSvO5zhfacYU9E72WgysI1NAUubOU9SOvZvYiZSf82dWG8iImkvcg3DmZR765LDPu1Dmk9N5FxP+xi/2ZnUdVMyVtRUODZk2I0eEw820zcPZ2AVXLD5bpRjmmxOZIPFImFDzfdKfDkbIL54iTnvszlYhVHLjJGIYsbmj1Y4pjSAxD/XhIWY56Zexgp6TFzTyPgYi/SaeHSu3sTJhWw6W+x439iEMCeET2OZiYgMVTHWTjjerfR4ww9NHPBir9wscWT8tNKXRldp59irjg1Cixn77Vto/8JBh22yn/q60YXFE9deb+KpAL8rclCCQaWjb9qFlPn6PDZc1BmWQmTlM1dEJVO/I17OeT2Hvnmim/MXzjqykh3vQgtEMdcvxJDR+efbmUPzZ7CJSi5gt/0ol3OKiNyzRj1emuW8ryc8Y+LPt7PRZPIa1zy8m7nG5cIy/v+3d2bBbV33GT8gAZIgAAJcARAECVJcJe5aqM3aKFmyZTu2szmZNHHitg/tTCczeehb3/rc9CGdtDNpJk0TeRIntuJVsi1LslZSIiluoriCJEgCXEGCAAEQBPt2fpedWJ42yEPZ8z39hbkE7jnnf/736vvOd86dTZbC/KiNMXtvhfvI1WwufLmCZQFHC8nZkydY/vBZFxL+F0ExPAoKCgoKCgq7HuqFR0FBQUFBQWHX46mSVjQMfW2Is2L8UiV0YkEHksNQPau+9y0iY/VGWQlfUgoNqrPijlmceEfGC0WHZbzH4JFxVpTV9WmZ0KTBMFT3fhsOsugG3y+EEL/LhzY2RoIybu1HWrlewGaAFQu4IoI2Nv26twXVVpj3gYxdS1Bz4zVQ9HHB9Q3znDkTTCKf+JdxoDSYU0Ot/nfo56C+fdMvy3i8g83KchY8MrZ5oFGt6egaj0/jnJj8gOvttV0y3tvL9QvjSHRXQqzCnw1CRX89TnzrCXR9tATZpF6P60QIIdx9SEtLAVK5Kc75Kjei/F7LKFRwdwzqdMJJzmSEkdPcW5zrkjnLBmKfbkK5z6GeidYAMshMM7nWHfkbGV8QqcHFFTb9m8sPynhpCYlRt/xAxmnzJ2S84ef/OX4/GxWezWHe+Tdp754g1wxeQDpMe/yijN3D0PIRA787sQm9fSENibB327ajPZmlSLqhfubLVvyKjItbkQ/Ddcg1X7uPWyzLjKTTqdl4Lz2DubndSN8VJGjzQANOP/c099qw9JGME/Gd0k2qEBug/5KlyB05vYxnoJQ6tzh8Wcbtr1CPYzdpQ9xKH+WOsCRhups6cCUHadFlCXIPSzh10vtpc/UEf+v+JjJp/3+Q+0IIca70LRl7h74nY1uIOfjOC0gTpWvU13kLudeWhbPSV4L89J96pJWjP+JZs9zCOJvLkbEcJTj5Rua4h1hNas7P0sJQh0Nt/l/JwYP7kZDie3g2xTZxn812fy7j7BbqpuZRIdqrWS4RH8aF+qSUGhqa4rfaTyAx33vIM70vm8/dGgdk/u1TO9rzuyTLOfZbmPNn8xi/kSnGv+TvkJ9mu5HoQiPMO8enjMHP/p5anPh1UMZmF/Pg0BZLYTLa+NuHfiSzdeXSUlBQUFBQUFBQLzwKCgoKCgoK/w/wVEmrwwftduE16K+WB9B0d/ZCm5bFoIG7sqFKn2/FITA9AyU+m2RVdWm8WcYRAb07lYEk0WrmOx9ZWfG+8i40a7QWGjM5sFMCCRi57uszuMKGn4EGPutktfnwXVanW8w2GbtnoHstjch1nxug5o6MQOWNaDaBsh5APpt5i0376qpp2+AKVHEqsT7P+60tCydIwzqUqr8W2jw/AnXoWyUX7B3Q4yU1OABWFqCWZzKgYx87oR3rS5AcnklCU/5mAhmjTOOaq01AaV8fxYEkhBCFFtqTvqARixq477gXh0nBAdK9/gq0+d115KdnHLSnoBCaNuCjvxyP+Xypnn4ptmnOdxNoXToL7U8V3uY2RZWVfHy4weaaW88hE+gye2TsHMWFEWtkzvYsMx+32pEkEw/Ij1cWcN/cmEbydGqcP2vzzLviQub+aO85Gedlcr0QQmxacG2E7f8u4wLjd2R8K45MUvIW1Prze3By3UxSm36wgTz5fhm5uV8jsd4qQKpvugsVP1IBXV/xOnm6+glzXGAy+pMx2EzuHF5FDv+Z6W0ZZ6Xzg2eTHhmH3kFiDqXR9+ld1DX7M9Sd2AB9XZjBPDg7z9z/MFuTFydYhrDWhwS0NU79aqvlnoUQ4ifBl2Vce4acvHcXic41EJRxFUq/eLJBjUh0UYP3ViD3+NaRvQvPazZqzOG+vRYcp0nNBqYZ00iAlzUusB+L1GBug7rkOE2ujW0yaQ1z1LiNBp5xb9qod/+whfvYN4RUN605s3LpMc/TH1QFZfypgbl5z8uzqCyCTGSZ5Xn4oJo5pNeTN0IIUWvk2Z9l+a2M3es4RbuLkf8Ti5p2ZpDXwsJSAGcrdflzUlyYm2nzi3FyORYPyrjnEfO6yY3DOCek0f2+AIrhUVBQUFBQUNj1UC88CgoKCgoKCrseT5W0Dmpo6q156NQZC5uS1eRAWccTrACPTeC6iGVCM06Z+Vw/DbXedRgnyPF1XAELD7imtwkKbn8xNPNoC5RgMMbnpvDOM4zyF3FzzJ2Bys76CAltrhFpqWye71rqYhX79nFcKKu/Py1jWxb3bUyHZt1rRKLydrL50pEqZJwnZVB/sW3uLZXINDAOsQTtsQaRX9YT0L2ftXJPzyb+IOPELWjtkSnoS0+xZqNGK33f5mbMdevQml4TuXNI0F/mTOjenCUo3uJGzj8TQoikH1dgcfkvZFwXZYPJwHGo2oJ/ZvzvXeQ+jgaQqwo0G91dX4RetdcwznWDbN4VfcLGdYtFNhkvB6GUjTHyK1WoeQGa+f47ULltteRgbIx+z9HRrsmvcW8Hh5CkJwqZR4Fl5t0LNsbm35Z7ZOwpIlc2NnBjHa3GEXPbpzkja+5TGa+VII0JIcSCoA2lK+Rd4WNkjLLz/M2pBDLkL7fJZYuejcj6PJwZVqw5f2jVDP3evMz/+Ya8yD7528inBs3ml7O5NvHngOkmkpv1OfKuYQUHYXku+Zu00cfOGNcbHiBfhA1IHyNzjHO7gXq0kMEjoK+TeV3yQ2rt+U3m4NUNHJ32aZuMezJ25njpGb534iayS345c9u5HpRxQrMEYHgJyaLmFNKV3885XLVzSDw+GzJmd4R5fXaMNtxeYp5utrG57CknDrJU4ZSRDQAL/WxSG6tgHmXmcc+BbuZmu+k3Mt4eYuxr0xnLrSKev44cJL8PX+Ie/D3MlfICasWdQcb+9GGkw/6H9O2BQuacEEJ4zdyHbwV5M9JCfUmbYt6Ju0ijuhbqQtaz1Hv7Lb6nuE5z/lmAujNQgwu33k8fZVTjgjOFyQNnnDz9IiiGR0FBQUFBQWHXQ73wKCgoKCgoKOx6PFXSqpyFBrxjfl/GVSbcFg2LnFFzPcK5OWcjyEHvx5BuXjfwjqXbhnZ75y5036wbat1ZigtmUkONPl5HYtnIwjV00Aytdflvd1JzZz6Gdu38DKq0/Rj08NgS1PptM9JV3fmgjI0JHEH5dq5Jz2RV+b0ElF11AZskzg8jh9yogKZ7rV9DcY5DX6YS4QoozDQHG3cZrkEpnnyWM8q6b9D3jxIeGbdkca+LTcganlk2ljKMQeWWV7E5Vk8QGSqjAcfAB59Ddx5bZvwfV0KB28d3biTpDUF/7jUwnpfjtKG+nHaOHmuXcfEo32Uyc/21XA2NnEBaTLyJ3LHkJl+EmTZX1eBu+DCgkRziO890SwWy7jMXKjzNMs4dIr/Ca1yztg/pUT/JHPmdQEopjiE/udi7UQxbycfXj0JRv/172rtcBSW+cJvNItdqGKM9tYxr+vBOubneTB71z1EvvEWM08ogedqZjvPRE9Sc6WTAseZdxIHTuoYDzbuFjJHdipPHusrf5tYxZj8PIbe8vgaFnkqsVDMXVtaQ6I6uUke3DEhaj254ZfyDKsbB28K92raQgP09b8r4Wj7fWRpBlrC/yDxNavr66iZ5lKxnng0s4/DqzySPhBCicp65M2bFFWbYg7RWepla229kU9nF6mYZn3fyXOhetsk42k2bHc3IWBnpOCLf/ZbmbLhL9Mu873muz6BfhDgqUoGNceTWXje1ZcFpk7Hpt7jVIq1IvZ55XEc3y6hdxUWM/dYMtXUrCwdc1k2egzlGpMfI5/xWdRN5fcfAWBw0/lTGk+bmHe0xFDOPzAs84/w+arbbjWS8eJ1cLo7ganzUhNy+vElsX6DuFJl4Rs8MMPajBdTfY6vUoG6NnOnW0V9fBMXwKCgoKCgoKOx6qBceBQUFBQUFhV2Pp0pacxbkhLw5VvBbs5AlAqWc2VH1BJpxqQEavEnPJn9PIlDZaUHo5FbLt2W84kcmqM+ByktoXBpboy/LeG+I1dyX7NDp1XeQcIQQYjEXym/GAW3+hzSovXMrULEzolnG5Q/Y3CtQCpUnaqDmTEGov6o+qPiBBujFJq+Na1avyrjbwG+FXLipUonCadxIUwGo6cMFGlkyAD1cN4ebZfogMsigHmniTAdU44PXobj3/yPj9omHvz2iIy+mAsgs3wngjss5wn0uDyBX5BXyW0IIYdV7ZBwOI78Wl/Mb0VJS3HoVh4KrGTr9Xu9+Ge87hgTjW+b8qZPtbETXO46LJHcOCWyrxSvjZwJcP5ZDfqYK0Se4M3Ir6cfrFpwp56w4AqNOXJDRTWhth4GcbV8hl3t9/F/Im4/EsjINzVz6Db7HMkJNMGg2v9sotcl4c4F8n9iAZhdCCLufsdWXMwbTgx4Ze87w295BKPSsQvLuYFyzI2M+bUiGGcvFHGQPzxPknWMNtHPSAi1f6UPqmisgr1OJ0QTfa+4kH681kWuHh5inyWr664fryGxlk3yP8wx5Z3yVfgn2MCfiq9S+yDjjv+7WyN92pKH0Oc4OvJ7xfRl7fZ4d7SnepHZcWGE+DkU4nzDg1PyNnnzYitOGgV9Sa+58hfpf2EpNcddekvFZE/Wi+33OXsvag8wUtdFfMRtSbKqw0oyjc32Rc6jcAfo0rJGTnEXk2qRf87yb1DigNdJ58VHm/uRnPKOTXp45CZ3mPMaDjEVBL2ORm8Pzd8vtkfFUJ7VLCCF0Jp5HdjvScNMoUufKNjmV9TIbs84v8Nv3NctfCvLJ34Uo87e6ks/Lu5tlPKRxX396gmd0wxR912GhJpCZO6EYHgUFBQUFBYVdD/XCo6CgoKCgoLDr8VRJq6gRato4x2r+hTFoxmQMajGtANrQucDmS4MO5KB8EzS4cZtV8WnVGrlhA2nsAz0UZYkZqmy0TeOCuoJMVunkfjI22TBMCCEmo0EZv6hxURk3oAV9Ydw1rSbafKIKOu79eaSxqQ6ofOM2q8cnNWe0fLWvWca/KoaWPWOlj/xPcJ00JL58tfn/Brl+pMWoCap83UzbLjh4Bx7eT7+499KekZ+yMdxAG9JYwYd8PlkBDe4c0sg7B2i/fRyK13KI+9kYxr0WdNNHI/M7Ja0L6eThcDV07qie3zZdZdW/KxOJZyD3VzKOHMBFkhvRnDdm5TtvV0GjvjDAOU4DR6FRpzWbY12uICeP9bIhY6oQP4w7I1uzydj5HHJn2YTMNx5Crki/j6OmqpQ5m2n1yjg/xneW5SMxzZiYs4FOKHHjKv0WOIgzpTZAiRlboj/bpjWHJwkh7rVhC5ux0I/79cjBi2E+X51HumtepV74LPT7xqbmfKAa2uwOkRN3y5FS+j+gDcd11KlmC+6l+zkaySyFiA7wvadC9Kv3VeZI3gJ9v5CGzHC8ELkyXIJUb/PTztoZ+n45j/kRFUgFJeNIjj/Vs3nnkWFkickm5LY3yhizByPILEIIYXpIXhW10q89PUjA5m8iiXS8S404u/myjGe/ggT2uo9acLUbuadvvybnP+YZMVPHhqqvJKnlZYNIo1eaqdmpQnV9l4wXPqK25Ok+kfEtBzUhOqw530qH3JbeTC5bYpxnt9HBxoMVGnnLkMThdWOefG8JsRFgWgRJK5CLzBvMp74XJOgrIYSo2ETSfaxxci5u4AgN9pFTpRkayc3PeD/v6JHxQgu1+KKefpkL8PwObPC8qn8Dl130M/rUoXlGhYc94sugGB4FBQUFBQWFXQ/1wqOgoKCgoKCw6/FUSWv495oV4y6oVatGZkjmQ3/lbUDH+QuRjAp7oZarmqFZtw7y/fOfQLl78qHQYi1QtOUat0TuLBLDqhEKzRqESjXke3e052ESOs+aDZW5FoUeXY9xH9sN0MYLYSj+gnI2GxTrbJiWHIJGrHmVS7yLbCylv2qT8VI59GCeBTlo7TZxKmF0IQE19kJxDx3l97I/QqJJ3+B8lJGg5py0byLjvTQH3X9vmY0n9b3IieXPQzt2bEMz2zWUaE831Ge4ECrXoXEXLVZCVwshxI3bms0DdT0yLh2FLp1qZXxmrPdkbP5c43La4pqsI0iLIRvugUMR2vPYA/1uT5LDmT1c36zZ5LFsD66zVGH2ERJIVuxbMp6zkZuN6zhECno1fadh8asH+D9Pt9UmY/feHhl/PA21fHraK+PQEWhmz14kyaVO5n5mNbJa2hNkrKE83B5CCGFMRz6vuIS7KOQKynglgqTpOs89jbxHXVhbQG4+Xs58vLPIfR8v5PqhfmSVqjyo8pVa3J7WDvL0u1nUo1TitAdH0ZiZ2madoM2PjEhO+j6of3Mtcofzfo+MpypZJnDVjfuyaV6zMeQMkvRn30Ku+u4nzJWOE3x/kY/7uTPEHPJV75T6NjaRVxo1Gymu11PzVju5V+PmX8k4eJh66bjL9Zc91JrDF5HhvSHqtPkCSxIO+ZinfrNNxj0e6kZhH7mQKsR89GmZjvv8wwDuLV3GLRnnGJgvyTbG6aSfv02foIY4G8nxX9yhRj+7Fyn5dCbz7kmYZ9qEBenpwDznxUWbeG5mP7/TQdmTjaM17wobUoYimnlexthMz1G/F7OQnq1uniFWPzn4/gx14YgdufF+i+aMuFtDMjZFeBYHO3H3HjbtdGX/MSiGR0FBQUFBQWHXQ73wKCgoKCgoKOx6PFXS2m+DUho2Qddvm6Ff8zVn1NxyIRkdy4AiC7qJhY+zL2xW3BUbB6C4ZjOQxuwPcYj0TEDTGQ9De5flQt2aCzhnZLaP1e9CCNFeCO0emuQ3dMc5br5+hjaUaJSIf4khxeWGcJ3Z1o7JOKA5u2hfLxSfXrMp14njbhl3LuNAaV1kJf1kFVRhKhGe575HzdCuwW2o3xUdG2LlldBflsJmGZu6oVG7G6FRE/5XZDzx7XdlXDlDm61R6O35TMYnXsh46o4gSY1O4iKp70DGEEIIRwS6dNSHcyrsgl63+viNwhmky8cudB13HZTt0jI5NrWIfFGyhothpYTzYfLzoMRn+pAG27zQtz4HtHyqkON6iX/so+8CP0eWWS7zckk28+hTE2P2KAd6vLTxjow7BxiDikL6eawIGnxrk34bCyPtPayENg+v0ld5do2DKk5/CiHEthnX2b7zbHIaD0FTuzVnzLnucU8D2YyTZz//h3uvi/x90YEUM3WTHG8qxwWUiDNOaQmk1Junz8o4fQhqfSfx/6chtIGMVf0A14o99xsy7myhz0y1SForQcZ/2Ig0XNqMJLL8kDYn8+m7PWZkydA9pIK5YubHxD6uqX3CGIbCSNXNUzsfJZ0N/J6/hHpxwE+/jtQhE29qZLzwNlKkX0cRNpsY55urSLRxI1K6cwFJ674dt1T9NDXowgi/9ZE79WejLfm4z3k/ErPzxTYZ3ximbhRp3KdbHzJ3dBX0aZpmuUhkySPjxiLOIBu/TZ7uKyUnKtMY1/VnqQMrXWwabLuvWZrxLM9lIYSovcGcGn+Jupb3kLwYKkU2O5DgmVjSclvGDzVq8KlZm4yzddSUXivtP2kmDx77aP85VmaIqJn3D1Oa9qzFs+KPQTE8CgoKCgoKCrse6oVHQUFBQUFBYdfjqZJWsCEo45EiqKaCa7gFEqc8Mv5+AtrwYy+Ua/UWLoeJOohgawEbHxkGemT8WTr01d5caNNoMbJS8Rwr3rvKkUkyuFxMGTh/RAgh+ju4100P5+k8dwV5Z6sMGu1XmdCyDWlBfjt2WMbDLij7Y024BaID0OP9mnNQQh0ad005Ul9+LnRnjxV6MJWwGOEUZzO9Mnbfx0VXI6BC/XbNWTlrmtX2To1Ec4O+N7mgTptGcGNdXqOd9liPjJ9zIEPNac4uuuIlXxwGJJdaF/cshBD3XNxT3iDU9+p1zsfReT6W8Sd2qPW2CfKzMolsMuNi07dXBDJu5zBUfvZBcuR6F+O2/wwul9sCOj009OXugf8pXA+QgPzjUMKv1fH5zSno64hgbMwT0L2TryK9bv4YmSC/nLx2aDaXvHYJWbCp3CvjjFkcO28kcHEWZ2qk6hokjCkvcosQQoyvIlduziJdWXKY84FWJPa1Qfp3PkiOzA7y29aaoIwnFnAN2cp/zfcn/1rGsdW3ZHwt+BUZfy2JbDD20jnx50DXXkpx7VE2GPQvIgFtjCJBjOrelvEJt2aOjFyX8eoo8ma2HilON4Xr6mqCGmcqQ5K1Bpnjk//EkgH9IfIl4+ZFGQfa6DshhDgygmQzuY3U//E+XKDOCercYpy2GQOMVXoB9aV0Fgkl08b1wWnue2ydur5dcYp7yOJzp4E6UFnCvEgVokXX+N2g5hyqQerJXxSR//ebuYesDqSl8iPUzce3kL0yR3GxzTUjwTv24Pxaustvxd0aF9sQLlRnMzU3bZnatXoVd6cQQugPnZFxxSQydpUT+dRh6ZFxjocaGlhlLhctM04r2Vyf7uKdYA+3LdLHkclLn7XRhlXk1sVp3hWWHV++iaRieBQUFBQUFBR2PdQLj4KCgoKCgsKux1MlrYISVlg7h5CQ0k+wUnthALqyr4QzTep1/G1Qc87OUDVLrGuu4kwaO4bUo/NCey6GkGG2N9mgaMsFVV40CC3bbfXIOJLc6dLK3wt16FhiJfkVM+6U8hFod3sY+t7YCK2/lMRFleFAAsr08ntrMWSP6dPQjqc0G3rdKoJyvnUJOq7MycZ+QnxPpAozUWTJvAr6Yt7IvQ77/lLG5uR1/nabMXdmIy1sZUM/658gjaXpkZsKrVCWz+Txu28X2GR8KJc+3efleqOe83re3N7p7MlZxpHhmCfHqgrYDDO4Hwr2oh7Xzu0Zzfk+63y+r5z8fHOEzfByPRoXTS452TKHVBDS7O03W8FZXSIH2SRVWD1JP2b6yC9fDHnjnAH5ocNDXznd5GxFDA45eojvtJTYZDz5seaco3Yo5MzHNDivnty/HcYFVhRHFp2+S03QtWucm0KIigc4s9I15+P0P0KWu6jZ7zMahR4/dEAjScYYJ0+MPMoV0OMPGt+QcbAbudnlRuppDjBXEtPUuLowc0Wg2v7JSBvSbKTnRib9/jJj9RB1QIxssHwgnME4/OQYkt7FTeqIoY9xWzxJfxmDyFWNGvkhMUNnHzGwsWW05oqMg5EPZVy2tPOcu5UgeTVjp6OMSeprjpEaPqhHopr2MbaNMe6py8EYGjWuMH0++dKYjswSiZOH/cM4eD6KUaecA8z9VKFmFamvxkMtirQyxlmPqI+uIuTcZBl5t7TGGWaizCbDqThO5INHGcvpazgrc7+BtN2yTU3rGaGG5kbpq0YT82C48Ds72tMRob7sW2I+pgnksals2tBexVIVzwPyKK2O56nLhIQWc7FExLJOXcjpQqoveY/6Mv8a7w0txTz7B1d4R3lG/HEohkdBQUFBQUFh10O98CgoKCgoKCjseui2t7e//CoFBQUFBQUFhf/DUAyPgoKCgoKCwq6HeuFRUFBQUFBQ2PVQLzwKCgoKCgoKux7qhUdBQUFBQUFh10O98CgoKCgoKCjseqgXHgUFBQUFBYVdj/8CWApRFaDo1TIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d17f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
